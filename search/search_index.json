{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Signature Core Nodes Documentation","text":"<p>A powerful collection of custom nodes for ComfyUI that provides essential image processing, data handling, and workflow management capabilities.</p> <p>\ud83d\udcda View Full Documentation</p>"},{"location":"#installation","title":"\ud83d\ude80 Installation","text":"<ol> <li>Navigate to your ComfyUI custom nodes directory:</li> </ol> <pre><code>cd ComfyUI/custom_nodes/\n</code></pre> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/signatureai/signature-core-nodes.git ComfyUI/custom_nodes/signature-core-nodes\n</code></pre> <ol> <li>Install the required dependencies:</li> </ol> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"#node-categories","title":"\ud83d\udce6 Node Categories","text":"<ul> <li>\u26a1 Basic</li> <li>\ud83e\uddf1 Primitives - Basic data type nodes</li> <li>\ud83d\udd22 Numbers - Numerical operations and processing</li> <li>\ud83d\udd24 Text - Text processing and manipulation nodes</li> <li>\ud83d\udcc1 File - File handling operations</li> <li>\ud83d\uddbc\ufe0f Image - Basic image handling nodes</li> <li>\ud83c\udfad Mask - Mask generation and operations</li> <li>\ud83d\uddbc\ufe0f Image Processing - Advanced image processing and manipulation nodes</li> <li>\ud83e\udd16 Models - AI model integration nodes</li> <li>\ud83e\udde0 Logic - Logic operations and control flow</li> <li>\ud83d\udee0\ufe0f Utils - Utility functions</li> <li>\ud83d\udce6 Others</li> <li>\ud83d\udd00 Augmentations - Image augmentation tools</li> <li>\ud83d\udd0c Platform I/O - Platform integration nodes</li> <li>\ud83d\udcca Data - Data conversion and handling</li> <li>\ud83e\uddec Loras - LoRA model handling and integration</li> </ul>"},{"location":"#usage","title":"\ud83d\udcbb Usage","text":"<p>After installation, the Signature Core nodes will be available in your ComfyUI workspace under the \"\ud83d\udd32 Signature Nodes\" category. Each node is designed to be intuitive and includes proper input validation and error handling.</p>"},{"location":"#example-workflow","title":"Example Workflow","text":"<ol> <li>Load an image using <code>ImageFromWeb</code> or <code>ImageFromBase64</code></li> <li>Apply transformations using nodes like <code>ImageTranspose</code> or <code>UpscaleImage</code></li> <li>Process the image using various filter nodes</li> <li>Export the result using <code>PlatformOutput</code> or save directly</li> </ol>"},{"location":"#project-structure","title":"\ud83d\udcc1 Project Structure","text":"<ul> <li><code>nodes/</code> - Node implementations</li> <li><code>web/</code> - Web interface components</li> <li><code>categories.py</code> - Node category definitions</li> <li><code>shared.py</code> - Shared utilities and constants</li> <li><code>platform_io.py</code> - Platform integration</li> <li><code>wrapper.py</code> - Workflow wrapper functionality</li> <li><code>docs/</code> - Documentation files</li> <li><code>scripts/</code> - Development and build scripts</li> </ul>"},{"location":"#development-setup","title":"\ud83d\udee0 Development Setup","text":"<ol> <li>Install development dependencies:</li> </ol> <pre><code>pip install -r dev-requirements.txt\n</code></pre> <ol> <li>Install pre-commit hooks:</li> </ol> <pre><code>pre-commit install\n</code></pre> <p>The project uses pre-commit hooks for:</p> <ul> <li>Code formatting and linting</li> <li>Syntax checking</li> <li>Security checks</li> <li> <p>File consistency</p> </li> <li> <p>Generate documentation:</p> </li> </ul> <pre><code>python scripts/generate_docs.py\n</code></pre>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<p>Documentation is built using MkDocs with the Material theme. To view the documentation locally:</p> <ol> <li>Install MkDocs and dependencies:</li> </ol> <pre><code>pip install mkdocs mkdocs-material\n</code></pre> <ol> <li>Serve the documentation:</li> </ol> <pre><code>mkdocs serve\n</code></pre> <p>The documentation will be available at <code>http://localhost:8000</code>.</p>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Contributions are welcome! Please feel free to submit a Pull Request.</p>"},{"location":"nodes/augmentations/","title":"Augmentations Nodes","text":""},{"location":"nodes/augmentations/#randomcropaugmentation","title":"RandomCropAugmentation","text":"<p>Applies random crop augmentation to images with configurable dimensions and frequency.</p> <p>This node performs random cropping operations on input images. It allows precise control over the crop dimensions through minimum and maximum window sizes, target dimensions, and application probability.</p>"},{"location":"nodes/augmentations/#inputs","title":"Inputs","text":"Group Name Type Default Extras required height <code>INT</code> 1024 min=32, step=32 required width <code>INT</code> 1024 min=32, step=32 required min_window <code>INT</code> 256 step=32 required max_window <code>INT</code> 1024 step=32 required percent <code>FLOAT</code> 1.0 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class RandomCropAugmentation:\n    \"\"\"Applies random crop augmentation to images with configurable dimensions and frequency.\n\n    This node performs random cropping operations on input images. It allows precise control over the\n    crop dimensions through minimum and maximum window sizes, target dimensions, and application\n    probability.\n\n    Args:\n        height (int): Target height for the crop operation. Must be at least 32 and a multiple of 32.\n        width (int): Target width for the crop operation. Must be at least 32 and a multiple of 32.\n        min_window (int): Minimum size of the crop window. Must be a multiple of 32.\n        max_window (int): Maximum size of the crop window. Must be a multiple of 32.\n        percent (float): Probability of applying the crop, from 0.0 to 1.0.\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with. Defaults to None.\n\n    Returns:\n        tuple: Contains a single element:\n            augmentation (AUGMENTATION): The configured crop augmentation operation.\n\n    Raises:\n        ValueError: If any dimension parameters are not multiples of 32.\n        ValueError: If min_window is larger than max_window.\n        ValueError: If percent is not between 0.0 and 1.0.\n\n    Notes:\n        - Window size is randomly selected between min_window and max_window for each operation\n        - Can be chained with other augmentations through the augmentation parameter\n        - All dimension parameters must be multiples of 32 for proper operation\n        - Setting percent to 1.0 ensures the crop is always applied\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"height\": (\"INT\", {\"default\": 1024, \"min\": 32, \"step\": 32}),\n                \"width\": (\"INT\", {\"default\": 1024, \"min\": 32, \"step\": 32}),\n                \"min_window\": (\"INT\", {\"default\": 256, \"step\": 32}),\n                \"max_window\": (\"INT\", {\"default\": 1024, \"step\": 32}),\n                \"percent\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(\n        self,\n        **kwargs,\n    ):\n        height = kwargs.get(\"height\") or 1024\n        width = kwargs.get(\"width\") or 1024\n        min_window = kwargs.get(\"min_window\") or 256\n        max_window = kwargs.get(\"max_window\") or 1024\n        percent = kwargs.get(\"percent\") or 1.0\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = random_crop_augmentation(height, width, min_window, max_window, percent, augmentation)\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#flipaugmentation","title":"FlipAugmentation","text":"<p>Applies horizontal or vertical flip augmentation to images with configurable probability.</p> <p>This node performs random flip transformations on input images. It supports both horizontal and vertical flip operations with adjustable probability of application.</p>"},{"location":"nodes/augmentations/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required flip <code>LIST</code> horizontal required percent <code>FLOAT</code> 0.5 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_1","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class FlipAugmentation:\n    \"\"\"Applies horizontal or vertical flip augmentation to images with configurable probability.\n\n    This node performs random flip transformations on input images. It supports both horizontal and\n    vertical flip operations with adjustable probability of application.\n\n    Args:\n        flip (str): Direction of flip operation, either:\n            - \"horizontal\": Flips image left to right\n            - \"vertical\": Flips image top to bottom\n        percent (float): Probability of applying the flip, from 0.0 to 1.0.\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with. Defaults to None.\n\n    Returns:\n        tuple: Contains a single element:\n            augmentation (AUGMENTATION): The configured flip augmentation operation.\n\n    Raises:\n        ValueError: If flip direction is not \"horizontal\" or \"vertical\".\n        ValueError: If percent is not between 0.0 and 1.0.\n\n    Notes:\n        - Flip direction cannot be changed after initialization\n        - Setting percent to 0.5 applies the flip to approximately half of all samples\n        - Can be chained with other augmentations through the augmentation parameter\n        - Transformations are applied consistently when used with ComposeAugmentation\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"flip\": ([\"horizontal\", \"vertical\"], {\"default\": \"horizontal\"}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.5, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        flip = kwargs.get(\"flip\") or \"horizontal\"\n        percent = kwargs.get(\"percent\") or 0.5\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = flip_augmentation(flip, percent, augmentation)\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#composeaugmentation","title":"ComposeAugmentation","text":"<p>Combines and applies multiple augmentation operations with consistent random transformations.</p> <p>This node orchestrates the application of multiple augmentation operations to images and masks. It provides control over sample generation and reproducibility through seed management.</p>"},{"location":"nodes/augmentations/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required augmentation <code>AUGMENTATION</code> required samples <code>INT</code> 1 min=1 required seed <code>INT</code> max=10000000000000000 optional image <code>IMAGE</code> None optional mask <code>MASK</code> None"},{"location":"nodes/augmentations/#returns_2","title":"Returns","text":"Name Type image <code>IMAGE</code> mask <code>MASK</code> Source code in augmentations.py <pre><code>class ComposeAugmentation:\n    \"\"\"Combines and applies multiple augmentation operations with consistent random transformations.\n\n    This node orchestrates the application of multiple augmentation operations to images and masks. It\n    provides control over sample generation and reproducibility through seed management.\n\n    Args:\n        augmentation (AUGMENTATION): The augmentation operation or chain to apply.\n        samples (int): Number of augmented versions to generate. Must be &gt;= 1.\n        seed (int): Random seed for reproducible results. Use -1 for random seeding.\n            Valid range: -1 to 10000000000000000.\n        image (IMAGE, optional): Input image to augment. Defaults to None.\n        mask (MASK, optional): Input mask to augment. Defaults to None.\n\n    Returns:\n        tuple: Contains two elements:\n            images (List[IMAGE]): List of augmented versions of the input image.\n            masks (List[MASK]): List of augmented versions of the input mask.\n\n    Raises:\n        ValueError: If neither image nor mask is provided.\n        ValueError: If samples is less than 1.\n        ValueError: If seed is outside valid range.\n\n    Notes:\n        - At least one of image or mask must be provided\n        - All augmentations are applied consistently to both image and mask\n        - Output is always returned as lists, even when samples=1\n        - Using a fixed seed ensures reproducible augmentations\n        - Supports chaining multiple augmentations through the augmentation parameter\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"augmentation\": (\"AUGMENTATION\",),\n                \"samples\": (\"INT\", {\"default\": 1, \"min\": 1}),\n                \"seed\": (\"INT\", {\"default\": -1, \"min\": -1, \"max\": 10000000000000000}),\n            },\n            \"optional\": {\n                \"image\": (\"IMAGE\", {\"default\": None}),\n                \"mask\": (\"MASK\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\n        \"IMAGE\",\n        \"MASK\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n    OUTPUT_IS_LIST = (\n        True,\n        True,\n    )\n\n    def execute(\n        self,\n        **kwargs,\n    ):\n        augmentation = kwargs.get(\"augmentation\") or []\n        samples = kwargs.get(\"samples\") or 1\n        image = kwargs.get(\"image\")\n        mask = kwargs.get(\"mask\")\n        seed = kwargs.get(\"seed\") or -1\n\n        # Create a dummy image if only mask is provided\n        if image is None and mask is not None:\n            image = torch.zeros_like(mask)\n\n        image_tensor = TensorImage.from_BWHC(image) if isinstance(image, torch.Tensor) else None\n        mask_tensor = TensorImage.from_BWHC(mask) if isinstance(mask, torch.Tensor) else None\n\n        total_images, total_masks = compose_augmentation(\n            augmentation=augmentation,\n            samples=samples,\n            image_tensor=image_tensor,\n            mask_tensor=mask_tensor,\n            seed=seed,\n        )\n\n        if total_images is None:\n            total_images = []\n        if total_masks is None:\n            total_masks = []\n        node_image = [image.get_BWHC() for image in total_images]\n        node_mask = [mask.get_BWHC() for mask in total_masks]\n        return (\n            node_image,\n            node_mask,\n        )\n</code></pre>"},{"location":"nodes/augmentations/#brightnesscontrastaugmentation","title":"BrightnessContrastAugmentation","text":"<p>Applies brightness and contrast adjustments to images.</p> <p>This node provides controls for adjusting image brightness and contrast with configurable limits and probability of application.</p>"},{"location":"nodes/augmentations/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required brightness_limit <code>FLOAT</code> 0.2 min=0.0, max=1.0 required contrast_limit <code>FLOAT</code> 0.2 min=0.0, max=1.0 required percent <code>FLOAT</code> 0.5 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_3","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class BrightnessContrastAugmentation:\n    \"\"\"Applies brightness and contrast adjustments to images.\n\n    This node provides controls for adjusting image brightness and contrast with configurable\n    limits and probability of application.\n\n    Args:\n        brightness_limit (float): Maximum brightness adjustment range (0.0-1.0)\n        contrast_limit (float): Maximum contrast adjustment range (0.0-1.0)\n        percent (float): Probability of applying the augmentation (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Brightness adjustments are applied as multiplicative factors\n        - Contrast adjustments modify image histogram spread\n        - Can be chained with other augmentations\n        - Actual adjustment values are randomly sampled within limits\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"brightness_limit\": (\"FLOAT\", {\"default\": 0.2, \"min\": 0.0, \"max\": 1.0}),\n                \"contrast_limit\": (\"FLOAT\", {\"default\": 0.2, \"min\": 0.0, \"max\": 1.0}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.5, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        brightness_limit = kwargs.get(\"brightness_limit\") or 0.2\n        contrast_limit = kwargs.get(\"contrast_limit\") or 0.2\n        percent = kwargs.get(\"percent\") or 0.5\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = brightness_contrast_augmentation(\n            brightness_limit=brightness_limit,\n            contrast_limit=contrast_limit,\n            percent=percent,\n            augmentation=augmentation,\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#rotationaugmentation","title":"RotationAugmentation","text":"<p>Rotates images by random angles within specified limits.</p> <p>This node performs random rotation augmentation with configurable angle limits and application probability.</p>"},{"location":"nodes/augmentations/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required limit <code>INT</code> 45 min=0, max=180 required percent <code>FLOAT</code> 0.5 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_4","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class RotationAugmentation:\n    \"\"\"Rotates images by random angles within specified limits.\n\n    This node performs random rotation augmentation with configurable angle limits and\n    application probability.\n\n    Args:\n        limit (int): Maximum rotation angle in degrees (0-180)\n        percent (float): Probability of applying the rotation (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Rotation angles are randomly sampled between -limit and +limit\n        - Empty areas after rotation are filled with black\n        - Can be chained with other augmentations\n        - Original aspect ratio is preserved\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"limit\": (\"INT\", {\"default\": 45, \"min\": 0, \"max\": 180}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.5, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        limit = kwargs.get(\"limit\") or 45\n        percent = kwargs.get(\"percent\") or 0.5\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = rotation_augmentation(limit=limit, percent=percent, augmentation=augmentation)\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#bluraugmentation","title":"BlurAugmentation","text":"<p>Applies various types of blur effects to images.</p> <p>This node provides multiple blur algorithms with configurable parameters for image softening effects.</p>"},{"location":"nodes/augmentations/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required blur_type <code>LIST</code> gaussian required blur_limit_min <code>INT</code> 3 min=3, step=3 required blur_limit_max <code>INT</code> 87 min=3, step=3 required percent <code>FLOAT</code> 0.3 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_5","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class BlurAugmentation:\n    \"\"\"Applies various types of blur effects to images.\n\n    This node provides multiple blur algorithms with configurable parameters for image\n    softening effects.\n\n    Args:\n        blur_type (str): Type of blur to apply:\n            - \"gaussian\": Gaussian blur\n            - \"motion\": Motion blur\n            - \"median\": Median filter blur\n        blur_limit_min (int): Minimum blur kernel size (must be multiple of 3)\n        blur_limit_max (int): Maximum blur kernel size (must be multiple of 3)\n        percent (float): Probability of applying the blur (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Kernel size is randomly selected between min and max limits\n        - Different blur types produce distinct softening effects\n        - Larger kernel sizes create stronger blur effects\n        - Can be chained with other augmentations\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"blur_type\": ([\"gaussian\", \"motion\", \"median\"], {\"default\": \"gaussian\"}),\n                \"blur_limit_min\": (\"INT\", {\"default\": 3, \"min\": 3, \"step\": 3}),\n                \"blur_limit_max\": (\"INT\", {\"default\": 87, \"min\": 3, \"step\": 3}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.3, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        blur_type = kwargs.get(\"blur_type\") or \"gaussian\"\n        blur_limit = (kwargs.get(\"blur_limit_min\", 3), kwargs.get(\"blur_limit_max\", 7))\n        percent = kwargs.get(\"percent\") or 0.3\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = blur_augmentation(\n            blur_type=blur_type, blur_limit=blur_limit, percent=percent, augmentation=augmentation\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#qualityaugmentation","title":"QualityAugmentation","text":"<p>Simulates image quality degradation through compression or downscaling.</p> <p>This node provides options to reduce image quality in ways that simulate real-world quality loss scenarios.</p>"},{"location":"nodes/augmentations/#inputs_6","title":"Inputs","text":"Group Name Type Default Extras required quality_type <code>LIST</code> compression required quality_limit <code>INT</code> 60 min=1, max=100 required percent <code>FLOAT</code> 0.2 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_6","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class QualityAugmentation:\n    \"\"\"Simulates image quality degradation through compression or downscaling.\n\n    This node provides options to reduce image quality in ways that simulate real-world\n    quality loss scenarios.\n\n    Args:\n        quality_type (str): Type of quality reduction:\n            - \"compression\": JPEG-like compression artifacts\n            - \"downscale\": Resolution reduction and upscaling\n        quality_limit (int): Quality parameter (1-100, lower = more degradation)\n        percent (float): Probability of applying the effect (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Compression type simulates JPEG artifacts\n        - Downscale type reduces and restores resolution\n        - Lower quality limits produce more visible artifacts\n        - Can be chained with other augmentations\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"quality_type\": ([\"compression\", \"downscale\"], {\"default\": \"compression\"}),\n                \"quality_limit\": (\"INT\", {\"default\": 60, \"min\": 1, \"max\": 100}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.2, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        quality_type = kwargs.get(\"quality_type\") or \"compression\"\n        quality_limit = kwargs.get(\"quality_limit\") or 60\n        percent = kwargs.get(\"percent\") or 0.2\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = quality_augmentation(\n            quality_type=quality_type, quality_limit=quality_limit, percent=percent, augmentation=augmentation\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#distortionaugmentation","title":"DistortionAugmentation","text":"<p>Applies geometric distortion effects to images.</p> <p>This node provides various types of geometric distortion with configurable severity and application probability.</p>"},{"location":"nodes/augmentations/#inputs_7","title":"Inputs","text":"Group Name Type Default Extras required distortion_type <code>LIST</code> optical required severity <code>INT</code> 1 min=1, max=5 required percent <code>FLOAT</code> 0.3 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_7","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class DistortionAugmentation:\n    \"\"\"Applies geometric distortion effects to images.\n\n    This node provides various types of geometric distortion with configurable severity\n    and application probability.\n\n    Args:\n        distortion_type (str): Type of distortion to apply:\n            - \"optical\": Lens-like distortion\n            - \"grid\": Grid-based warping\n            - \"elastic\": Elastic deformation\n        severity (int): Intensity of the distortion effect (1-5)\n        percent (float): Probability of applying the effect (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Each distortion type produces unique geometric deformations\n        - Higher severity values create stronger distortion effects\n        - Can be chained with other augmentations\n        - Maintains overall image structure while adding local deformations\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"distortion_type\": ([\"optical\", \"grid\", \"elastic\"], {\"default\": \"optical\"}),\n                \"severity\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 5}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.3, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        distortion_type = kwargs.get(\"distortion_type\") or \"optical\"\n        severity = kwargs.get(\"severity\") or 1\n        percent = kwargs.get(\"percent\") or 0.3\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = distortion_augmentation(\n            distortion_type=distortion_type, severity=severity, percent=percent, augmentation=augmentation\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#shiftscaleaugmentation","title":"ShiftScaleAugmentation","text":"<p>Applies random shifting, scaling, and rotation transformations.</p> <p>This node combines multiple geometric transformations with configurable ranges and probability.</p>"},{"location":"nodes/augmentations/#inputs_8","title":"Inputs","text":"Group Name Type Default Extras required shift_limit <code>FLOAT</code> 0.1 min=0.0, max=1.0 required scale_limit <code>FLOAT</code> 0.2 min=0.0, max=1.0 required rotate_limit <code>INT</code> 45 min=0, max=180 required percent <code>FLOAT</code> 0.3 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_8","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class ShiftScaleAugmentation:\n    \"\"\"Applies random shifting, scaling, and rotation transformations.\n\n    This node combines multiple geometric transformations with configurable ranges\n    and probability.\n\n    Args:\n        shift_limit (float): Maximum shift as fraction of image size (0.0-1.0)\n        scale_limit (float): Maximum scale factor change (0.0-1.0)\n        rotate_limit (int): Maximum rotation angle in degrees (0-180)\n        percent (float): Probability of applying transformations (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Shift moves image content within frame\n        - Scale changes overall image size\n        - Rotation angles are randomly sampled\n        - Can be chained with other augmentations\n        - All transformations are applied together when selected\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"shift_limit\": (\"FLOAT\", {\"default\": 0.1, \"min\": 0.0, \"max\": 1.0}),\n                \"scale_limit\": (\"FLOAT\", {\"default\": 0.2, \"min\": 0.0, \"max\": 1.0}),\n                \"rotate_limit\": (\"INT\", {\"default\": 45, \"min\": 0, \"max\": 180}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.3, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        shift_limit = kwargs.get(\"shift_limit\") or 0.1\n        scale_limit = kwargs.get(\"scale_limit\") or 0.2\n        rotate_limit = kwargs.get(\"rotate_limit\") or 45\n        percent = kwargs.get(\"percent\") or 0.3\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = shift_scale_augmentation(\n            shift_limit=shift_limit,\n            scale_limit=scale_limit,\n            rotate_limit=rotate_limit,\n            percent=percent,\n            augmentation=augmentation,\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#cutoutaugmentation","title":"CutoutAugmentation","text":"<p>Creates random rectangular cutouts in images.</p> <p>This node randomly removes rectangular regions from images by filling them with black, useful for regularization and robustness training.</p>"},{"location":"nodes/augmentations/#inputs_9","title":"Inputs","text":"Group Name Type Default Extras required num_holes <code>INT</code> 8 min=1, max=20 required max_size <code>INT</code> 30 min=1, max=100 required percent <code>FLOAT</code> 0.3 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_9","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class CutoutAugmentation:\n    \"\"\"Creates random rectangular cutouts in images.\n\n    This node randomly removes rectangular regions from images by filling them with black,\n    useful for regularization and robustness training.\n\n    Args:\n        num_holes (int): Number of cutout regions to create (1-20)\n        max_size (int): Maximum size of cutout regions in pixels (1-100)\n        percent (float): Probability of applying cutouts (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Cutout positions are randomly selected\n        - Each cutout region is independently sized\n        - Regions are filled with black (zero) values\n        - Can be chained with other augmentations\n        - Useful for preventing overfitting\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"num_holes\": (\"INT\", {\"default\": 8, \"min\": 1, \"max\": 20}),\n                \"max_size\": (\"INT\", {\"default\": 30, \"min\": 1, \"max\": 100}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.3, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        num_holes = kwargs.get(\"num_holes\") or 8\n        max_size = kwargs.get(\"max_size\") or 30\n        percent = kwargs.get(\"percent\") or 0.3\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = cutout_augmentation(\n            num_holes=num_holes, max_size=max_size, percent=percent, augmentation=augmentation\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#gridaugmentation","title":"GridAugmentation","text":"<p>Applies grid-based transformations to images.</p> <p>This node provides grid-based image modifications including shuffling and dropout effects.</p>"},{"location":"nodes/augmentations/#inputs_10","title":"Inputs","text":"Group Name Type Default Extras required grid_type <code>LIST</code> shuffle required grid_size <code>INT</code> 3 min=2, max=10 required percent <code>FLOAT</code> 0.3 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_10","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class GridAugmentation:\n    \"\"\"Applies grid-based transformations to images.\n\n    This node provides grid-based image modifications including shuffling and dropout\n    effects.\n\n    Args:\n        grid_type (str): Type of grid transformation:\n            - \"shuffle\": Randomly permute grid cells\n            - \"dropout\": Randomly remove grid cells\n        grid_size (int): Number of grid divisions (2-10)\n        percent (float): Probability of applying the effect (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Image is divided into grid_size x grid_size cells\n        - Shuffle randomly reorders grid cells\n        - Dropout replaces cells with black\n        - Can be chained with other augmentations\n        - Maintains overall image structure while adding local variations\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"grid_type\": ([\"shuffle\", \"dropout\"], {\"default\": \"shuffle\"}),\n                \"grid_size\": (\"INT\", {\"default\": 3, \"min\": 2, \"max\": 10}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.3, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        grid_type = kwargs.get(\"grid_type\") or \"shuffle\"\n        grid_size = kwargs.get(\"grid_size\") or 3\n        percent = kwargs.get(\"percent\") or 0.3\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = grid_augmentation(\n            grid_type=grid_type, grid_size=grid_size, percent=percent, augmentation=augmentation\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/augmentations/#perspectiveaugmentation","title":"PerspectiveAugmentation","text":"<p>Applies perspective transformation effects to images.</p> <p>This node creates perspective distortion effects that simulate viewing angle changes, with configurable strength and probability.</p>"},{"location":"nodes/augmentations/#inputs_11","title":"Inputs","text":"Group Name Type Default Extras required scale <code>FLOAT</code> 0.05 min=0.01, max=0.5 required keep_size <code>BOOLEAN</code> True required percent <code>FLOAT</code> 0.3 min=0.0, max=1.0 optional augmentation <code>AUGMENTATION</code> None"},{"location":"nodes/augmentations/#returns_11","title":"Returns","text":"Name Type augmentation <code>AUGMENTATION</code> Source code in augmentations.py <pre><code>class PerspectiveAugmentation:\n    \"\"\"Applies perspective transformation effects to images.\n\n    This node creates perspective distortion effects that simulate viewing angle changes,\n    with configurable strength and probability.\n\n    Args:\n        scale (float): Strength of perspective effect (0.01-0.5)\n        keep_size (bool): Whether to maintain original image size\n        percent (float): Probability of applying the effect (0.0-1.0)\n        augmentation (AUGMENTATION, optional): Existing augmentation to chain with\n\n    Returns:\n        tuple[AUGMENTATION]: Single-element tuple containing the configured augmentation\n\n    Notes:\n        - Scale controls the intensity of perspective change\n        - keep_size=True maintains original dimensions\n        - keep_size=False may change image size\n        - Can be chained with other augmentations\n        - Simulates realistic viewing angle variations\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"scale\": (\"FLOAT\", {\"default\": 0.05, \"min\": 0.01, \"max\": 0.5}),\n                \"keep_size\": (\"BOOLEAN\", {\"default\": True}),\n                \"percent\": (\"FLOAT\", {\"default\": 0.3, \"min\": 0.0, \"max\": 1.0}),\n            },\n            \"optional\": {\n                \"augmentation\": (\"AUGMENTATION\", {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (\"AUGMENTATION\",)\n    RETURN_NAMES = (\"augmentation\",)\n    FUNCTION = \"execute\"\n    CATEGORY = AUGMENTATION_CAT\n\n    def execute(self, **kwargs):\n        scale = kwargs.get(\"scale\") or 0.05\n        keep_size = kwargs.get(\"keep_size\", True)\n        percent = kwargs.get(\"percent\") or 0.3\n        augmentation = kwargs.get(\"augmentation\")\n        augmentation = perspective_augmentation(\n            scale=scale, keep_size=keep_size, percent=percent, augmentation=augmentation\n        )\n        return (augmentation,)\n</code></pre>"},{"location":"nodes/data/","title":"Data Nodes","text":""},{"location":"nodes/data/#json2dict","title":"Json2Dict","text":"<p>Converts JSON strings to Python dictionaries for workflow integration.</p> <p>A node that takes JSON-formatted strings and parses them into Python dictionaries, enabling seamless data integration within the workflow. Handles nested JSON structures and validates input format.</p>"},{"location":"nodes/data/#inputs","title":"Inputs","text":"Group Name Type Default Extras required json_str <code>STRING</code> forceInput=True"},{"location":"nodes/data/#returns","title":"Returns","text":"Name Type dict <code>DICT</code> Source code in data.py <pre><code>class Json2Dict:\n    \"\"\"Converts JSON strings to Python dictionaries for workflow integration.\n\n    A node that takes JSON-formatted strings and parses them into Python dictionaries, enabling\n    seamless data integration within the workflow. Handles nested JSON structures and validates\n    input format.\n\n    Args:\n        json_str (str): The JSON-formatted input string to parse.\n            Must be a valid JSON string conforming to standard JSON syntax.\n            Can represent simple key-value pairs or complex nested structures.\n\n    Returns:\n        tuple[dict]: A single-element tuple containing:\n            - dict: The parsed Python dictionary representing the JSON structure.\n                   Preserves all nested objects, arrays, and primitive values.\n\n    Raises:\n        ValueError: When json_str is not a string type.\n        json.JSONDecodeError: When the input string contains invalid JSON syntax.\n\n    Notes:\n        - Accepts any valid JSON format including objects, arrays, and primitive values\n        - Empty JSON objects ('{}') are valid inputs and return empty dictionaries\n        - Preserves all JSON data types: objects, arrays, strings, numbers, booleans, null\n        - Does not support JSON streaming or parsing multiple JSON objects\n        - Unicode characters are properly handled and preserved\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"json_str\": (\"STRING\", {\"default\": \"\", \"forceInput\": True}),\n            },\n        }\n\n    RETURN_TYPES = (\"DICT\",)\n    FUNCTION = \"execute\"\n    CLASS_ID = \"json_dict\"\n    CATEGORY = DATA_CAT\n\n    def execute(self, **kwargs):\n        json_str = kwargs.get(\"json_str\")\n        if not isinstance(json_str, str):\n            raise ValueError(\"Json string must be a string\")\n        json_dict = json.loads(json_str)\n        return (json_dict,)\n</code></pre>"},{"location":"nodes/data/#dict2json","title":"Dict2Json","text":"<p>Converts Python dictionaries to JSON strings for data interchange.</p> <p>A node that serializes Python dictionaries into JSON-formatted strings, facilitating data export and communication with external systems that require JSON format.</p>"},{"location":"nodes/data/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required dict <code>DICT</code>"},{"location":"nodes/data/#returns_1","title":"Returns","text":"Name Type string <code>STRING</code> Source code in data.py <pre><code>class Dict2Json:\n    \"\"\"Converts Python dictionaries to JSON strings for data interchange.\n\n    A node that serializes Python dictionaries into JSON-formatted strings, facilitating data\n    export and communication with external systems that require JSON format.\n\n    Args:\n        dict (dict): The Python dictionary to serialize.\n            Can contain nested dictionaries, lists, and primitive Python types.\n            All values must be JSON-serializable (dict, list, str, int, float, bool, None).\n\n    Returns:\n        tuple[str]: A single-element tuple containing:\n            - str: The JSON-formatted string representation of the input dictionary.\n                  Follows standard JSON syntax and escaping rules.\n\n    Raises:\n        TypeError: When dict contains values that cannot be serialized to JSON.\n        ValueError: When dict is not a dictionary type.\n\n    Notes:\n        - All dictionary keys are converted to strings in the output JSON\n        - Complex Python objects (datetime, custom classes) must be pre-converted to basic types\n        - Output is compact JSON without extra whitespace or formatting\n        - Handles nested structures of any depth\n        - Unicode characters are properly escaped in the output\n        - Circular references are not supported and will raise TypeError\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"dict\": (\"DICT\",),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CLASS_ID = \"dict_json\"\n    CATEGORY = DATA_CAT\n\n    def execute(self, **kwargs):\n        json_dict = kwargs.get(\"dict\")\n        json_str = json.dumps(json_dict)\n        return (json_str,)\n</code></pre>"},{"location":"nodes/data/#getimagelistitem","title":"GetImageListItem","text":"<p>Extracts a single image from an image list by index.</p> <p>A node designed for batch image processing that allows selective access to individual images within a collection, enabling targeted processing of specific images in a sequence.</p>"},{"location":"nodes/data/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required images <code>IMAGE</code> required index <code>INT</code> 0"},{"location":"nodes/data/#returns_2","title":"Returns","text":"Name Type i <code>I</code> m <code>M</code> a <code>A</code> g <code>G</code> e <code>E</code> Source code in data.py <pre><code>class GetImageListItem:\n    \"\"\"Extracts a single image from an image list by index.\n\n    A node designed for batch image processing that allows selective access to individual images\n    within a collection, enabling targeted processing of specific images in a sequence.\n\n    Args:\n        images (list[Image]): The list of image objects to select from.\n            Must be a valid list containing compatible image objects.\n            Can be any length, but must not be empty.\n        index (int): The zero-based index of the desired image.\n            Must be a non-negative integer within the list bounds.\n            Defaults to 0 (first image).\n\n    Returns:\n        tuple[Image]: A single-element tuple containing:\n            - Image: The selected image object from the specified index position.\n\n    Raises:\n        ValueError: When index is not an integer or images is not a list.\n        IndexError: When index is outside the valid range for the image list.\n        TypeError: When images list contains invalid image objects.\n\n    Notes:\n        - Uses zero-based indexing (0 = first image)\n        - Does not support negative indices\n        - Returns a single image even from multi-image batches\n        - Preserves the original image data without modifications\n        - Thread-safe for concurrent access\n        - Memory efficient as it references rather than copies the image\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"images\": (\"IMAGE\",),\n                \"index\": (\"INT\", {\"default\": 0}),\n            },\n        }\n\n    RETURN_TYPES = \"IMAGE\"\n    RETURN_NAMES = \"image\"\n    FUNCTION = \"execute\"\n    CATEGORY = DATA_CAT\n\n    def execute(self, **kwargs):\n        images = kwargs.get(\"images\")\n        index = kwargs.get(\"index\")\n        if not isinstance(index, int):\n            raise ValueError(\"Index must be an integer\")\n        if not isinstance(images, list):\n            raise ValueError(\"Images must be a list\")\n        images = images[index]\n        index = kwargs.get(\"index\")\n        image = images[index]\n        return (image,)\n</code></pre>"},{"location":"nodes/data/#getlistitem","title":"GetListItem","text":"<p>Retrieves and types items from any list by index position.</p> <p>A versatile node that provides access to list elements while also determining their Python type, enabling dynamic type handling and conditional processing in workflows.</p>"},{"location":"nodes/data/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required list <code>LIST</code> required index <code>INT</code> 0 Source code in data.py <pre><code>class GetListItem:\n    \"\"\"Retrieves and types items from any list by index position.\n\n    A versatile node that provides access to list elements while also determining their Python\n    type, enabling dynamic type handling and conditional processing in workflows.\n\n    Args:\n        list (list): The source list to extract items from.\n            Can contain elements of any type, including mixed types.\n            Must be a valid Python list, not empty.\n        index (int): The zero-based index of the desired item.\n            Must be a non-negative integer within the list bounds.\n            Defaults to 0 (first item).\n\n    Returns:\n        tuple[Any, str]: A tuple containing:\n            - Any: The retrieved item from the specified index position.\n            - str: The Python type name of the retrieved item (e.g., 'str', 'int', 'dict').\n\n    Raises:\n        ValueError: When index is not an integer or list parameter is not a list.\n        IndexError: When index is outside the valid range for the list.\n\n    Notes:\n        - Supports lists containing any Python type, including custom classes\n        - Type name is derived from the object's __class__.__name__\n        - Does not support negative indices\n        - Thread-safe for concurrent access\n        - Preserves original data without modifications\n        - Handles nested data structures (lists within lists, dictionaries, etc.)\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"list\": (\"LIST\",),\n                \"index\": (\"INT\", {\"default\": 0}),\n            },\n        }\n\n    RETURN_TYPES = (any_type, \"STRING\")\n    RETURN_NAMES = (\"item\", \"value_type\")\n    FUNCTION = \"execute\"\n    CATEGORY = DATA_CAT\n\n    def execute(self, **kwargs):\n        list_obj = kwargs.get(\"list\")\n        index = kwargs.get(\"index\")\n        if not isinstance(index, int):\n            raise ValueError(\"Index must be an integer\")\n        if not isinstance(list_obj, list):\n            raise ValueError(\"Input must be a list\")\n        item = list_obj[index]\n        item_type = type(item).__name__\n        return (item, item_type)\n</code></pre>"},{"location":"nodes/data/#getdictvalue","title":"GetDictValue","text":"<p>Retrieves and types dictionary values using string keys.</p> <p>A node that provides key-based access to dictionary values while determining their Python type, enabling dynamic type handling and conditional processing in workflows.</p>"},{"location":"nodes/data/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required dict <code>DICT</code> required key <code>STRING</code> Source code in data.py <pre><code>class GetDictValue:\n    \"\"\"Retrieves and types dictionary values using string keys.\n\n    A node that provides key-based access to dictionary values while determining their Python\n    type, enabling dynamic type handling and conditional processing in workflows.\n\n    Args:\n        dict (dict): The source dictionary to extract values from.\n            Must be a valid Python dictionary.\n            Can contain values of any type and nested structures.\n        key (str): The lookup key for value retrieval.\n            Must be a string type.\n            Case-sensitive and must match exactly.\n            Defaults to empty string.\n\n    Returns:\n        tuple[Any, str]: A tuple containing:\n            - Any: The value associated with the specified key.\n            - str: The Python type name of the retrieved value (e.g., 'str', 'int', 'dict').\n\n    Raises:\n        ValueError: When key is not a string or dict parameter is not a dictionary.\n        KeyError: When the specified key doesn't exist in the dictionary.\n\n    Notes:\n        - Supports dictionaries containing any Python type, including custom classes\n        - Type name is derived from the object's __class__.__name__\n        - Returns None for missing keys instead of raising KeyError\n        - Thread-safe for concurrent access\n        - Preserves original data without modifications\n        - Handles nested data structures (dictionaries within dictionaries, lists, etc.)\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"dict\": (\"DICT\",),\n                \"key\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (any_type, \"STRING\")\n    RETURN_NAMES = (\"value\", \"value_type\")\n    FUNCTION = \"execute\"\n    CATEGORY = DATA_CAT\n\n    def execute(self, **kwargs):\n        dict_obj = kwargs.get(\"dict\")\n        key = kwargs.get(\"key\")\n        if not isinstance(key, str):\n            raise ValueError(\"Key must be a string\")\n        if not isinstance(dict_obj, dict):\n            raise ValueError(\"Dict must be a dictionary\")\n        value = dict_obj.get(key)\n        value_type = type(value).__name__\n        return (value, value_type)\n</code></pre>"},{"location":"nodes/file/","title":"File Nodes","text":""},{"location":"nodes/file/#imagefromweb","title":"ImageFromWeb","text":"<p>Fetches and converts web images to ComfyUI-compatible tensors.</p> <p>Downloads an image from a URL and processes it into ComfyUI's expected tensor format. Handles both RGB and RGBA images with automatic mask generation for transparency.</p>"},{"location":"nodes/file/#inputs","title":"Inputs","text":"Group Name Type Default Extras required url <code>STRING</code> URL HERE"},{"location":"nodes/file/#returns","title":"Returns","text":"Name Type image <code>IMAGE</code> mask <code>MASK</code> Source code in file.py <pre><code>class ImageFromWeb:\n    \"\"\"Fetches and converts web images to ComfyUI-compatible tensors.\n\n    Downloads an image from a URL and processes it into ComfyUI's expected tensor format. Handles both RGB\n    and RGBA images with automatic mask generation for transparency.\n\n    Args:\n        url (str): Direct URL to the image file (PNG, JPG, JPEG, WebP).\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor]:\n            - image: BWHC format tensor, normalized to [0,1] range\n            - mask: BWHC format tensor for transparency/alpha channel\n\n    Raises:\n        ValueError: If URL is invalid, inaccessible, or not a string\n        HTTPError: If image download fails\n        IOError: If image format is unsupported\n\n    Notes:\n        - Automatically converts images to float32 format\n        - RGB images get a mask of ones\n        - RGBA images use alpha channel as mask\n        - Supports standard web image formats\n        - Image dimensions are preserved\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\"required\": {\"url\": (\"STRING\", {\"default\": \"URL HERE\"})}}\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"execute\"\n    CATEGORY = FILE_CAT\n\n    def execute(self, **kwargs):\n        url = kwargs.get(\"url\")\n        if not isinstance(url, str):\n            raise ValueError(\"URL must be a string\")\n        img_arr = TensorImage.from_web(url)\n        return image_array_to_tensor(img_arr)\n</code></pre>"},{"location":"nodes/file/#imagefrombase64","title":"ImageFromBase64","text":"<p>Converts base64 image strings to ComfyUI-compatible tensors.</p> <p>Processes base64-encoded image data into tensor format suitable for ComfyUI operations. Handles both RGB and RGBA images with proper mask generation.</p>"},{"location":"nodes/file/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required base64 <code>STRING</code> BASE64 HERE"},{"location":"nodes/file/#returns_1","title":"Returns","text":"Name Type image <code>IMAGE</code> mask <code>MASK</code> Source code in file.py <pre><code>class ImageFromBase64:\n    \"\"\"Converts base64 image strings to ComfyUI-compatible tensors.\n\n    Processes base64-encoded image data into tensor format suitable for ComfyUI operations. Handles\n    both RGB and RGBA images with proper mask generation.\n\n    Args:\n        base64 (str): Raw base64-encoded image string without data URL prefix.\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor]:\n            - image: BWHC format tensor, normalized to [0,1] range\n            - mask: BWHC format tensor for transparency/alpha channel\n\n    Raises:\n        ValueError: If base64 string is invalid or not a string\n        IOError: If decoded image format is unsupported\n        binascii.Error: If base64 decoding fails\n\n    Notes:\n        - Converts decoded images to float32 format\n        - RGB images get a mask of ones\n        - RGBA images use alpha channel as mask\n        - Supports common image formats (PNG, JPG, JPEG)\n        - Original image dimensions are preserved\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\"required\": {\"base64\": (\"STRING\", {\"default\": \"BASE64 HERE\"})}}\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"execute\"\n    CATEGORY = FILE_CAT\n\n    def execute(self, **kwargs):\n        base64 = kwargs.get(\"base64\")\n        if not isinstance(base64, str):\n            raise ValueError(\"Base64 must be a string\")\n        img_arr = TensorImage.from_base64(base64)\n        return image_array_to_tensor(img_arr)\n</code></pre>"},{"location":"nodes/file/#base64fromimage","title":"Base64FromImage","text":"<p>Converts ComfyUI image tensors to base64-encoded strings.</p> <p>Transforms image tensors from ComfyUI's format into base64-encoded strings, suitable for web transmission or storage in text format.</p>"},{"location":"nodes/file/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/file/#returns_2","title":"Returns","text":"Name Type string <code>STRING</code> Source code in file.py <pre><code>class Base64FromImage:\n    \"\"\"Converts ComfyUI image tensors to base64-encoded strings.\n\n    Transforms image tensors from ComfyUI's format into base64-encoded strings, suitable for web\n    transmission or storage in text format.\n\n    Args:\n        image (torch.Tensor): BWHC format tensor with values in [0,1] range.\n\n    Returns:\n        tuple[str]:\n            - base64_str: PNG-encoded image as base64 string without data URL prefix\n\n    Raises:\n        ValueError: If input is not a tensor or has invalid format\n        RuntimeError: If tensor conversion or encoding fails\n\n    Notes:\n        - Output is always PNG encoded\n        - Preserves alpha channel if present\n        - No data URL prefix in output\n        - Maintains original image quality\n        - Suitable for web APIs and storage\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\"required\": {\"image\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = FILE_CAT\n    OUTPUT_NODE = True\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n        images = TensorImage.from_BWHC(image)\n        output = images.get_base64()\n        return (output,)\n</code></pre>"},{"location":"nodes/file/#fileloader","title":"FileLoader","text":"<p>Processes string input into ComfyUI-compatible file data.</p> <p>Converts JSON-formatted string data into file references with proper paths for ComfyUI processing. Handles both single files and multiple files separated by '&amp;&amp;'.</p>"},{"location":"nodes/file/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required value <code>STRING</code>"},{"location":"nodes/file/#returns_3","title":"Returns","text":"Name Type file <code>FILE</code> Source code in file.py <pre><code>class FileLoader:\n    \"\"\"Processes string input into ComfyUI-compatible file data.\n\n    Converts JSON-formatted string data into file references with proper paths for ComfyUI processing.\n    Handles both single files and multiple files separated by '&amp;&amp;'.\n\n    Args:\n        value (str): JSON-formatted string containing file data.\n\n    Returns:\n        tuple[list]:\n            - files: List of dictionaries with file data and updated paths\n\n    Raises:\n        ValueError: If input is not a string\n        json.JSONDecodeError: If JSON parsing fails\n        KeyError: If required file data fields are missing\n\n    Notes:\n        - Automatically prepends ComfyUI input folder path\n        - Supports multiple files via '&amp;&amp;' separator\n        - Preserves original file metadata\n        - Updates file paths for ComfyUI compatibility\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"FILE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = FILE_CAT\n\n    def execute(self, **kwargs):\n        value = kwargs.get(\"value\")\n        if not isinstance(value, str):\n            raise ValueError(\"Value must be a string\")\n        data = value.split(\"&amp;&amp;\") if \"&amp;&amp;\" in value else [value]\n        input_folder = os.path.join(BASE_COMFY_DIR, \"input\")\n        for i, _ in enumerate(data):\n            json_str = data[i]\n            data[i] = json.loads(json_str)\n            item = data[i]\n            if isinstance(item, dict):\n                name = item.get(\"name\", None)\n                if name is None:\n                    continue\n                item[\"name\"] = os.path.join(input_folder, name)\n                data[i] = item\n\n        return (data,)\n</code></pre>"},{"location":"nodes/file/#folderloader","title":"FolderLoader","text":"<p>Processes folder paths into ComfyUI-compatible file data.</p> <p>Converts folder path information into properly formatted file references for ComfyUI processing. Supports both single and multiple folder paths.</p>"},{"location":"nodes/file/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required value <code>STRING</code>"},{"location":"nodes/file/#returns_4","title":"Returns","text":"Name Type file <code>FILE</code> Source code in file.py <pre><code>class FolderLoader:\n    \"\"\"Processes folder paths into ComfyUI-compatible file data.\n\n    Converts folder path information into properly formatted file references for ComfyUI processing.\n    Supports both single and multiple folder paths.\n\n    Args:\n        value (str): JSON-formatted string containing folder path data.\n\n    Returns:\n        tuple[list]:\n            - files: List of dictionaries with file data and updated paths\n\n    Raises:\n        ValueError: If input is not a string\n        json.JSONDecodeError: If JSON parsing fails\n        KeyError: If required folder data fields are missing\n\n    Notes:\n        - Automatically prepends ComfyUI input folder path\n        - Supports multiple folders via '&amp;&amp;' separator\n        - Maintains folder structure information\n        - Updates all paths for ComfyUI compatibility\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"FILE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = FILE_CAT\n\n    def execute(self, **kwargs):\n        value = kwargs.get(\"value\")\n        if not isinstance(value, str):\n            raise ValueError(\"Value must be a string\")\n        data = value.split(\"&amp;&amp;\") if \"&amp;&amp;\" in value else [value]\n        input_folder = os.path.join(BASE_COMFY_DIR, \"input\")\n        for i, _ in enumerate(data):\n            json_str = data[i]\n            data[i] = json.loads(json_str)\n            item = data[i]\n            if isinstance(item, dict):\n                name = item.get(\"name\", None)\n                if name is None:\n                    continue\n                item[\"name\"] = os.path.join(input_folder, name)\n                data[i] = item\n        return (data,)\n</code></pre>"},{"location":"nodes/file/#file2imagelist","title":"File2ImageList","text":"<p>Converts file references to a list of image tensors.</p> <p>Processes a list of file references, extracting and converting supported image files into ComfyUI-compatible tensor format.</p>"},{"location":"nodes/file/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required files <code>FILE</code>"},{"location":"nodes/file/#returns_5","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in file.py <pre><code>class File2ImageList:\n    \"\"\"Converts file references to a list of image tensors.\n\n    Processes a list of file references, extracting and converting supported image files into\n    ComfyUI-compatible tensor format.\n\n    Args:\n        files (list): List of file dictionaries with type and path information.\n\n    Returns:\n        tuple[list[torch.Tensor]]:\n            - images: List of BWHC format tensors from valid image files\n\n    Raises:\n        ValueError: If input is not a list\n        IOError: If image loading fails\n        RuntimeError: If tensor conversion fails\n\n    Notes:\n        - Supports PNG, JPG, JPEG, TIFF, BMP formats\n        - Skips non-image files\n        - Maintains original image properties\n        - Returns empty list if no valid images\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"files\": (\"FILE\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = FILE_CAT\n    CLASS_ID = \"file_image_list\"\n    OUTPUT_IS_LIST = (True,)\n\n    def execute(self, **kwargs):\n        files = kwargs.get(\"files\")\n        if not isinstance(files, list):\n            raise ValueError(\"Files must be a list\")\n        images_list = []\n        for file in files:\n            mimetype = file[\"type\"]\n            extension = file[\"name\"].lower().split(\".\")[-1]\n            possible_extensions = [\"png\", \"jpg\", \"jpeg\", \"tiff\", \"tif\", \"bmp\"]\n            if mimetype.startswith(\"image\") and extension in possible_extensions:\n                images_list.append(TensorImage.from_local(file[\"name\"]).get_BWHC())\n\n        return (images_list,)\n</code></pre>"},{"location":"nodes/file/#file2list","title":"File2List","text":"<p>Converts file input to a standardized list format.</p> <p>Processes file input data into a consistent list format for further ComfyUI operations.</p>"},{"location":"nodes/file/#inputs_6","title":"Inputs","text":"Group Name Type Default Extras required files <code>FILE</code>"},{"location":"nodes/file/#returns_6","title":"Returns","text":"Name Type list <code>LIST</code> Source code in file.py <pre><code>class File2List:\n    \"\"\"Converts file input to a standardized list format.\n\n    Processes file input data into a consistent list format for further ComfyUI operations.\n\n    Args:\n        files (list): List of file dictionaries.\n\n    Returns:\n        tuple[list]:\n            - files: Processed list of file data\n\n    Raises:\n        ValueError: If input is not a list\n\n    Notes:\n        - Preserves original file metadata\n        - Maintains file order\n        - No file validation performed\n        - Suitable for further processing\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"files\": (\"FILE\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"LIST\",)\n    FUNCTION = \"execute\"\n    CLASS_ID = \"file_list\"\n    CATEGORY = FILE_CAT\n\n    def execute(self, **kwargs):\n        files = kwargs.get(\"files\")\n        if not isinstance(files, list):\n            raise ValueError(\"Files must be a list\")\n        return (files,)\n</code></pre>"},{"location":"nodes/file/#rotate","title":"Rotate","text":"<p>Rotates an image and mask by a specified angle.</p> <p>This node provides functionality to rotate images and masks while optionally adjusting the output size to fit the entire rotated content.</p> Source code in file.py <pre><code>class Rotate:\n    \"\"\"Rotates an image and mask by a specified angle.\n\n    This node provides functionality to rotate images and masks while optionally adjusting the output\n    size to fit the entire rotated content.\n\n    Args:\n        image (torch.Tensor, optional): Input image in BWHC format\n        mask (torch.Tensor, optional): Input mask in BWHC format\n        angle (float): Rotation angle in degrees (0-360)\n        zoom_to_fit (bool): Whether to zoom to fit rotated content (default: False)\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor]: Tuple containing:\n            - Rotated image in BWHC format\n            - Rotated mask in BWHC format\n\n    Notes:\n        - At least one of image or mask must be provided\n        - Rotation is performed counterclockwise\n        - When zoom_to_fit is False, corners may be clipped\n        - When zoom_to_fit is True, output may be larger\n        - Empty areas after rotation are filled with black\n        - Maintains aspect ratio of input\n    \"\"\"\n</code></pre>"},{"location":"nodes/file/#maskgaussianblur","title":"MaskGaussianBlur","text":"<p>Applies Gaussian blur to a mask.</p> <p>This node performs Gaussian blur on mask inputs with configurable radius, sigma and iteration parameters. Useful for softening mask edges or creating smooth transitions.</p> Source code in file.py <pre><code>class MaskGaussianBlur:\n    \"\"\"Applies Gaussian blur to a mask.\n\n    This node performs Gaussian blur on mask inputs with configurable radius, sigma and iteration\n    parameters. Useful for softening mask edges or creating smooth transitions.\n\n    Args:\n        image (torch.Tensor): Input mask in BWHC format\n        radius (int): Blur radius in pixels. Default: 13\n            Larger values create wider blur effects\n        sigma (float): Blur strength/standard deviation. Default: 10.5\n            Controls the falloff of the blur effect\n        iterations (int): Number of blur passes to apply. Default: 1\n            Multiple passes can create stronger blur effects\n        only_outline (bool): Whether to blur only the outline. Default: False\n            When True, preserves solid areas and only blurs edges\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - Blurred mask in BWHC format\n\n    Notes:\n        - Input should be a single-channel mask\n        - Output maintains the same dimensions as input\n        - Multiple iterations can create smoother results\n        - Larger radius and sigma values produce stronger blur\n        - Edge-only mode is useful for creating soft borders\n    \"\"\"\n</code></pre>"},{"location":"nodes/image/","title":"Image Nodes","text":""},{"location":"nodes/image/#imagebasecolor","title":"ImageBaseColor","text":"<p>Creates a solid color image with specified dimensions.</p> <p>This node generates a uniform color image using a hex color code. The output is a tensor in BWHC format (Batch, Width, Height, Channels) with the specified dimensions.</p>"},{"location":"nodes/image/#inputs","title":"Inputs","text":"Group Name Type Default Extras required hex_color <code>STRING</code> #FFFFFF required width <code>INT</code> 1024 required height <code>INT</code> 1024"},{"location":"nodes/image/#returns","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageBaseColor:\n    \"\"\"Creates a solid color image with specified dimensions.\n\n    This node generates a uniform color image using a hex color code. The output is a tensor in BWHC\n    format (Batch, Width, Height, Channels) with the specified dimensions.\n\n    Args:\n        hex_color (str): Hex color code in format \"#RRGGBB\" (e.g., \"#FFFFFF\" for white)\n        width (int): Width of the output image in pixels\n        height (int): Height of the output image in pixels\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - tensor: Image in BWHC format with shape (1, height, width, 3)\n\n    Raises:\n        ValueError: If width or height are not integers\n        ValueError: If hex_color is not a string\n        ValueError: If hex_color is not in valid \"#RRGGBB\" format\n\n    Notes:\n        - The output tensor values are normalized to range [0, 1]\n        - Alpha channel is not supported\n        - The batch dimension is always 1\n        - RGB values are extracted from hex color and converted to float32\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"hex_color\": (\"STRING\", {\"default\": \"#FFFFFF\"}),\n                \"width\": (\"INT\", {\"default\": 1024}),\n                \"height\": (\"INT\", {\"default\": 1024}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n    CLASS_ID = \"image_base_color\"\n\n    def execute(self, **kwargs):\n        hex_color = kwargs.get(\"hex_color\")\n        width = kwargs.get(\"width\")\n        height = kwargs.get(\"height\")\n        if not isinstance(width, int):\n            raise ValueError(\"Width must be an integer\")\n        if not isinstance(height, int):\n            raise ValueError(\"Height must be an integer\")\n        if not isinstance(hex_color, str):\n            raise ValueError(\"Hex color must be a string\")\n        hex_color = hex_color.lstrip(\"#\")\n        r, g, b = tuple(int(hex_color[i : i + 2], 16) for i in (0, 2, 4))\n\n        # Create a tensor with the specified color\n        color_tensor = torch.tensor([r, g, b], dtype=torch.float32) / 255.0\n\n        # Reshape to (3, 1, 1) and expand to (3, H, W)\n        color_tensor = color_tensor.view(3, 1, 1).expand(3, height, width)\n\n        # Repeat for the batch size\n        batch_tensor = color_tensor.unsqueeze(0).expand(1, -1, -1, -1)\n\n        output = TensorImage(batch_tensor).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/image/#imagegaussianblur","title":"ImageGaussianBlur","text":"<p>Applies Gaussian blur filter to an input image.</p> <p>This node performs Gaussian blur using a configurable kernel size and sigma value. Multiple passes can be applied for stronger blur effects. The blur is applied uniformly across all color channels.</p>"},{"location":"nodes/image/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required radius <code>INT</code> 13 required sigma <code>FLOAT</code> 10.5 required interations <code>INT</code> 1"},{"location":"nodes/image/#returns_1","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageGaussianBlur:\n    \"\"\"Applies Gaussian blur filter to an input image.\n\n    This node performs Gaussian blur using a configurable kernel size and sigma value. Multiple passes\n    can be applied for stronger blur effects. The blur is applied uniformly across all color channels.\n\n    Args:\n        image (torch.Tensor): Input image tensor in BWHC format\n        radius (int): Blur kernel radius in pixels (kernel size = 2 * radius + 1)\n        sigma (float): Standard deviation for Gaussian kernel, controls blur strength\n        iterations (int): Number of times to apply the blur filter sequentially\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - tensor: Blurred image in BWHC format with same shape as input\n\n    Raises:\n        ValueError: If image is not a torch.Tensor\n        ValueError: If radius is not an integer\n        ValueError: If sigma is not a float\n        ValueError: If iterations is not an integer\n\n    Notes:\n        - Larger radius and sigma values produce stronger blur effects\n        - Multiple iterations can create smoother results but increase processing time\n        - Input image dimensions and batch size are preserved in output\n        - Processing is done on GPU if input tensor is on GPU\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"radius\": (\"INT\", {\"default\": 13}),\n                \"sigma\": (\"FLOAT\", {\"default\": 10.5}),\n                \"interations\": (\"INT\", {\"default\": 1}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n        radius = kwargs.get(\"radius\")\n        if not isinstance(radius, int):\n            raise ValueError(\"Radius must be an integer\")\n        sigma = kwargs.get(\"sigma\")\n        if not isinstance(sigma, float):\n            raise ValueError(\"Sigma must be a float\")\n        interations = kwargs.get(\"interations\")\n        if not isinstance(interations, int):\n            raise ValueError(\"Interations must be an integer\")\n        tensor_image = TensorImage.from_BWHC(image)\n        output = gaussian_blur2d(tensor_image, radius, sigma, interations).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/image/#imageunsharpmask","title":"ImageUnsharpMask","text":"<p>Enhances image sharpness using unsharp mask technique.</p> <p>This node applies an unsharp mask filter to enhance edge details in the image. It works by subtracting a blurred version of the image from the original, creating a sharpening effect.</p>"},{"location":"nodes/image/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required radius <code>INT</code> 3 required sigma <code>FLOAT</code> 1.5 required interations <code>INT</code> 1"},{"location":"nodes/image/#returns_2","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageUnsharpMask:\n    \"\"\"Enhances image sharpness using unsharp mask technique.\n\n    This node applies an unsharp mask filter to enhance edge details in the image. It works by\n    subtracting a blurred version of the image from the original, creating a sharpening effect.\n\n    Args:\n        image (torch.Tensor): Input image in BWHC format\n        radius (int): Size of the blur kernel used in the unsharp mask\n        sigma (float): Strength of the blur in the unsharp mask calculation\n        iterations (int): Number of times to apply the sharpening effect\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - tensor: Sharpened image in BWHC format with same shape as input\n\n    Raises:\n        ValueError: If image is not a torch.Tensor\n        ValueError: If radius is not an integer\n        ValueError: If sigma is not a float\n        ValueError: If iterations is not an integer\n\n    Notes:\n        - Higher sigma values create stronger sharpening effects\n        - Multiple iterations can create more pronounced sharpening but may introduce artifacts\n        - The process preserves the original image dimensions and color range\n        - Works on all color channels independently\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"radius\": (\"INT\", {\"default\": 3}),\n                \"sigma\": (\"FLOAT\", {\"default\": 1.5}),\n                \"interations\": (\"INT\", {\"default\": 1}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n        radius = kwargs.get(\"radius\")\n        if not isinstance(radius, int):\n            raise ValueError(\"Radius must be an integer\")\n        sigma = kwargs.get(\"sigma\")\n        if not isinstance(sigma, float):\n            raise ValueError(\"Sigma must be a float\")\n        interations = kwargs.get(\"interations\")\n        if not isinstance(interations, int):\n            raise ValueError(\"Interations must be an integer\")\n        tensor_image = TensorImage.from_BWHC(image)\n        output = unsharp_mask(tensor_image, radius, sigma, interations).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/image/#imagesoftlight","title":"ImageSoftLight","text":"<p>Applies soft light blend mode between two images.</p> <p>Implements the soft light blending mode similar to photo editing software. The effect creates a subtle, soft lighting effect based on the interaction between the top and bottom layers.</p>"},{"location":"nodes/image/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required top <code>IMAGE</code> required bottom <code>IMAGE</code>"},{"location":"nodes/image/#returns_3","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageSoftLight:\n    \"\"\"Applies soft light blend mode between two images.\n\n    Implements the soft light blending mode similar to photo editing software. The effect creates a\n    subtle, soft lighting effect based on the interaction between the top and bottom layers.\n\n    Args:\n        top (torch.Tensor): Top layer image in BWHC format, acts as the blend layer\n        bottom (torch.Tensor): Bottom layer image in BWHC format, acts as the base layer\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - tensor: Blended image in BWHC format with same shape as inputs\n\n    Raises:\n        ValueError: If top is not a torch.Tensor\n        ValueError: If bottom is not a torch.Tensor\n        ValueError: If input tensors have different shapes\n\n    Notes:\n        - Both input images must have the same dimensions\n        - The blend preserves the original image dimensions and color range\n        - The effect is similar to soft light blend mode in photo editing software\n        - Processing is done on GPU if input tensors are on GPU\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"top\": (\"IMAGE\",),\n                \"bottom\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n\n    def execute(self, **kwargs):\n        top = kwargs.get(\"top\")\n        bottom = kwargs.get(\"bottom\")\n        if not isinstance(top, torch.Tensor):\n            raise ValueError(\"Top must be a torch.Tensor\")\n        if not isinstance(bottom, torch.Tensor):\n            raise ValueError(\"Bottom must be a torch.Tensor\")\n        top_tensor = TensorImage.from_BWHC(top)\n        bottom_tensor = TensorImage.from_BWHC(bottom)\n        output = image_soft_light(top_tensor, bottom_tensor).get_BWHC()\n\n        return (output,)\n</code></pre>"},{"location":"nodes/image/#imageaverage","title":"ImageAverage","text":"<p>Calculates the average color of an input image.</p> <p>Computes the mean color values across all pixels in the image, resulting in a uniform color image representing the average color of the input.</p>"},{"location":"nodes/image/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/image/#returns_4","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageAverage:\n    \"\"\"Calculates the average color of an input image.\n\n    Computes the mean color values across all pixels in the image, resulting in a uniform color\n    image representing the average color of the input.\n\n    Args:\n        image (torch.Tensor): Input image in BWHC format to calculate average from\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - tensor: Uniform color image in BWHC format with same shape as input\n\n    Raises:\n        ValueError: If image is not a torch.Tensor\n\n    Notes:\n        - Output maintains the same dimensions as input but with uniform color\n        - Calculation is performed per color channel\n        - Useful for color analysis or creating color-matched solid backgrounds\n        - Preserves the original batch size\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n        step = TensorImage.from_BWHC(image)\n        output = color_average(step).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/image/#imagesubtract","title":"ImageSubtract","text":"<p>Computes the absolute difference between two images.</p> <p>Performs pixel-wise subtraction between two images and takes the absolute value of the result, useful for comparing images or creating difference maps.</p>"},{"location":"nodes/image/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required image_0 <code>IMAGE</code> required image_1 <code>IMAGE</code>"},{"location":"nodes/image/#returns_5","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageSubtract:\n    \"\"\"Computes the absolute difference between two images.\n\n    Performs pixel-wise subtraction between two images and takes the absolute value of the result,\n    useful for comparing images or creating difference maps.\n\n    Args:\n        image_0 (torch.Tensor): First image in BWHC format\n        image_1 (torch.Tensor): Second image in BWHC format to subtract from first image\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - tensor: Difference image in BWHC format with same shape as inputs\n\n    Raises:\n        ValueError: If image_0 is not a torch.Tensor\n        ValueError: If image_1 is not a torch.Tensor\n        ValueError: If input tensors have different shapes\n\n    Notes:\n        - Both input images must have the same dimensions\n        - Output values represent absolute differences between corresponding pixels\n        - Useful for change detection or image comparison\n        - Result is always positive due to absolute value operation\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image_0\": (\"IMAGE\",),\n                \"image_1\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n\n    def execute(self, **kwargs):\n        image_0 = kwargs.get(\"image_0\")\n        image_1 = kwargs.get(\"image_1\")\n        if not isinstance(image_0, torch.Tensor):\n            raise ValueError(\"Image 0 must be a torch.Tensor\")\n        if not isinstance(image_1, torch.Tensor):\n            raise ValueError(\"Image 1 must be a torch.Tensor\")\n        image_0_tensor = TensorImage.from_BWHC(image_0)\n        image_1_tensor = TensorImage.from_BWHC(image_1)\n        image_tensor = torch.abs(image_0_tensor - image_1_tensor)\n        output = TensorImage(image_tensor).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/image/#imagetranspose","title":"ImageTranspose","text":"<p>Transforms and composites an overlay image onto a base image.</p> <p>Provides comprehensive image composition capabilities including resizing, positioning, rotation, and edge feathering of an overlay image onto a base image.</p>"},{"location":"nodes/image/#inputs_6","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required image_overlay <code>IMAGE</code> required width <code>INT</code> max=48000, step=1 required height <code>INT</code> max=48000, step=1 required X <code>INT</code> 0 min=0, max=48000, step=1 required Y <code>INT</code> 0 min=0, max=48000, step=1 required rotation <code>INT</code> 0 max=360, step=1 required feathering <code>INT</code> 0 min=0, max=100, step=1"},{"location":"nodes/image/#returns_6","title":"Returns","text":"Name Type image <code>IMAGE</code> image <code>IMAGE</code> Source code in image.py <pre><code>class ImageTranspose:\n    \"\"\"Transforms and composites an overlay image onto a base image.\n\n    Provides comprehensive image composition capabilities including resizing, positioning, rotation,\n    and edge feathering of an overlay image onto a base image.\n\n    Args:\n        image (torch.Tensor): Base image in BWHC format\n        image_overlay (torch.Tensor): Overlay image in BWHC format\n        width (int): Target width for overlay (-1 for original size)\n        height (int): Target height for overlay (-1 for original size)\n        X (int): Horizontal offset in pixels from left edge\n        Y (int): Vertical offset in pixels from top edge\n        rotation (int): Rotation angle in degrees (-360 to 360)\n        feathering (int): Edge feathering radius in pixels (0-100)\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor]: Two-element tuple containing:\n            - tensor: Composited image in RGB format\n            - tensor: Composited image in RGBA format with transparency\n\n    Raises:\n        ValueError: If any input parameters are not of correct type\n        ValueError: If rotation is outside valid range\n        ValueError: If feathering is outside valid range\n\n    Notes:\n        - Supports both RGB and RGBA overlay images\n        - Automatically handles padding and cropping\n        - Feathering creates smooth edges around the overlay\n        - All transformations preserve aspect ratio when specified\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"image_overlay\": (\"IMAGE\",),\n                \"width\": (\"INT\", {\"default\": -1, \"min\": -1, \"max\": 48000, \"step\": 1}),\n                \"height\": (\"INT\", {\"default\": -1, \"min\": -1, \"max\": 48000, \"step\": 1}),\n                \"X\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 48000, \"step\": 1}),\n                \"Y\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 48000, \"step\": 1}),\n                \"rotation\": (\"INT\", {\"default\": 0, \"min\": -360, \"max\": 360, \"step\": 1}),\n                \"feathering\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 100, \"step\": 1}),\n            },\n        }\n\n    RETURN_TYPES = (\n        \"IMAGE\",\n        \"IMAGE\",\n    )\n    RETURN_NAMES = (\n        \"rgb\",\n        \"rgba\",\n    )\n    FUNCTION = \"execute\"\n\n    CATEGORY = IMAGE_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n        image_overlay = kwargs.get(\"image_overlay\")\n        if not isinstance(image_overlay, torch.Tensor):\n            raise ValueError(\"Image overlay must be a torch.Tensor\")\n        width = kwargs.get(\"width\")\n        if not isinstance(width, int):\n            raise ValueError(\"Width must be an integer\")\n        height = kwargs.get(\"height\")\n        if not isinstance(height, int):\n            raise ValueError(\"Height must be an integer\")\n        x = kwargs.get(\"X\")\n        if not isinstance(x, int):\n            raise ValueError(\"X must be an integer\")\n        y = kwargs.get(\"Y\")\n        if not isinstance(y, int):\n            raise ValueError(\"Y must be an integer\")\n        rotation = kwargs.get(\"rotation\")\n        if not isinstance(rotation, int):\n            raise ValueError(\"Rotation must be an integer\")\n        feathering = kwargs.get(\"feathering\")\n        if not isinstance(feathering, int):\n            raise ValueError(\"Feathering must be an integer\")\n\n        base_image = TensorImage.from_BWHC(image)\n        overlay_image = TensorImage.from_BWHC(image_overlay)\n\n        if width == -1:\n            width = overlay_image.shape[3]\n        if height == -1:\n            height = overlay_image.shape[2]\n\n        device = base_image.device\n        overlay_image = overlay_image.to(device)\n\n        # Resize overlay image\n        overlay_image = transform.resize(overlay_image, (height, width))\n\n        if rotation != 0:\n            angle = torch.tensor(rotation, dtype=torch.float32, device=device)\n            center = torch.tensor([width / 2, height / 2], dtype=torch.float32, device=device)\n            overlay_image = transform.rotate(overlay_image, angle, center=center)\n\n        # Create mask (handle both RGB and RGBA cases)\n        if overlay_image.shape[1] == 4:\n            mask = overlay_image[:, 3:4, :, :]\n        else:\n            mask = torch.ones((1, 1, height, width), device=device)\n\n        # Pad overlay image and mask\n        pad_left = x\n        pad_top = y\n        pad_right = max(0, base_image.shape[3] - overlay_image.shape[3] - x)\n        pad_bottom = max(0, base_image.shape[2] - overlay_image.shape[2] - y)\n\n        overlay_image = torch.nn.functional.pad(overlay_image, (pad_left, pad_right, pad_top, pad_bottom))\n        mask = torch.nn.functional.pad(mask, (pad_left, pad_right, pad_top, pad_bottom))\n\n        # Resize to match base image\n        overlay_image = transform.resize(overlay_image, base_image.shape[2:])\n        mask = transform.resize(mask, base_image.shape[2:])\n\n        if feathering &gt; 0:\n            kernel_size = 2 * feathering + 1\n            feather_kernel = torch.ones((1, 1, kernel_size, kernel_size), device=device) / (kernel_size**2)\n            mask = torch.nn.functional.conv2d(mask, feather_kernel, padding=feathering)\n\n        # Blend images\n        result = base_image * (1 - mask) + overlay_image[:, :3, :, :] * mask\n\n        result = TensorImage(result).get_BWHC()\n\n        rgb = result\n        rgba = torch.cat([rgb, mask.permute(0, 2, 3, 1)], dim=3)\n\n        return (rgb, rgba)\n</code></pre>"},{"location":"nodes/image/#imagelist2batch","title":"ImageList2Batch","text":"<p>Converts a list of individual images into a batched tensor.</p> <p>Combines multiple images into a single batched tensor, handling different input sizes through various resize modes. Supports multiple interpolation methods for optimal quality.</p>"},{"location":"nodes/image/#inputs_7","title":"Inputs","text":"Group Name Type Default Extras required images <code>IMAGE</code> required mode <code>LIST</code> required interpolation <code>LIST</code>"},{"location":"nodes/image/#returns_7","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageList2Batch:\n    \"\"\"Converts a list of individual images into a batched tensor.\n\n    Combines multiple images into a single batched tensor, handling different input sizes through\n    various resize modes. Supports multiple interpolation methods for optimal quality.\n\n    Args:\n        images (list[torch.Tensor]): List of input images in BWHC format\n        mode (str): Resize mode for handling different image sizes:\n            - 'STRETCH': Stretches images to match largest dimensions\n            - 'FIT': Fits images within largest dimensions, maintaining aspect ratio\n            - 'FILL': Fills to largest dimensions, maintaining aspect ratio with cropping\n            - 'ASPECT': Preserves aspect ratio with padding\n        interpolation (str): Interpolation method for resizing:\n            - 'bilinear': Smooth interpolation suitable for most cases\n            - 'nearest': Nearest neighbor, best for pixel art\n            - 'bicubic': High-quality interpolation\n            - 'area': Best for downscaling\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - tensor: Batched images in BWHC format\n\n    Raises:\n        ValueError: If images is not a list\n        ValueError: If mode is not a valid option\n        ValueError: If interpolation is not a valid option\n\n    Notes:\n        - All images in output batch will have same dimensions\n        - Original image qualities are preserved as much as possible\n        - Memory efficient processing for large batches\n        - GPU acceleration is automatically used when available\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"images\": (\"IMAGE\",),\n                \"mode\": ([\"STRETCH\", \"FIT\", \"FILL\", \"ASPECT\"],),\n                \"interpolation\": ([\"bilinear\", \"nearest\", \"bicubic\", \"area\"],),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n    INPUT_IS_LIST = True\n    CLASS_ID = \"image_list_batch\"\n\n    def execute(self, **kwargs):\n        images = kwargs.get(\"images\")\n        mode = kwargs.get(\"mode\") or \"FIT\"\n        interpolation = kwargs.get(\"interpolation\") or \"bilinear\"\n        if not isinstance(images, list):\n            raise ValueError(\"Images must be a list\")\n        if isinstance(mode, list) and len(mode) == 1:\n            mode = mode[0]\n        if isinstance(interpolation, list) and len(interpolation) == 1:\n            interpolation = interpolation[0]\n\n        if not isinstance(mode, str):\n            raise ValueError(\"Mode must be a string\")\n        if not isinstance(interpolation, str):\n            raise ValueError(\"Interpolation must be a string\")\n\n        # Check if all images have the same shape\n        shapes = [img.shape for img in images]\n        if len(set(shapes)) == 1:\n            # All images have the same shape, no need to resize\n            return (torch.stack(images),)\n\n        # Images have different shapes, proceed with resizing\n        max_height = max(img.shape[1] for img in images)\n        max_width = max(img.shape[2] for img in images)\n\n        resized_images = []\n        for img in images:\n            tensor_img = TensorImage.from_BWHC(img)\n            resized_img = resize(tensor_img, max_width, max_height, mode=mode, interpolation=interpolation)\n            resized_images.append(resized_img.get_BWHC().squeeze(0))\n\n        return (torch.stack(resized_images),)\n</code></pre>"},{"location":"nodes/image/#imagebatch2list","title":"ImageBatch2List","text":"<p>Splits a batched tensor of images into individual images.</p> <p>Converts a batch of images stored in a single tensor into a list of separate image tensors, useful for processing images individually after batch operations.</p>"},{"location":"nodes/image/#inputs_8","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/image/#returns_8","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image.py <pre><code>class ImageBatch2List:\n    \"\"\"Splits a batched tensor of images into individual images.\n\n    Converts a batch of images stored in a single tensor into a list of separate image tensors,\n    useful for processing images individually after batch operations.\n\n    Args:\n        image (torch.Tensor): Batched input images in BWHC format\n\n    Returns:\n        tuple[list[torch.Tensor]]: Single-element tuple containing:\n            - list: Individual images, each in BWHC format with batch size 1\n\n    Raises:\n        ValueError: If image is not a torch.Tensor\n\n    Notes:\n        - Each output image maintains original dimensions and channels\n        - Output images have batch dimension of 1\n        - Useful for post-processing individual images after batch operations\n        - Memory efficient as it uses views when possible\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\"required\": {\"image\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n    CLASS_ID = \"image_batch_list\"\n    OUTPUT_IS_LIST = (True,)\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n\n        image_list = [img.unsqueeze(0) for img in image]\n        return (image_list,)\n</code></pre>"},{"location":"nodes/image/#getimageshape","title":"GetImageShape","text":"<p>Analyzes and returns the dimensions of an input image.</p> <p>Extracts and returns detailed shape information from an input image tensor, providing both individual dimensions and a formatted string representation.</p>"},{"location":"nodes/image/#inputs_9","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/image/#returns_9","title":"Returns","text":"Name Type int <code>INT</code> int <code>INT</code> int <code>INT</code> int <code>INT</code> string <code>STRING</code> Source code in image.py <pre><code>class GetImageShape:\n    \"\"\"Analyzes and returns the dimensions of an input image.\n\n    Extracts and returns detailed shape information from an input image tensor, providing both\n    individual dimensions and a formatted string representation.\n\n    Args:\n        image (torch.Tensor): Input image in BWHC format to analyze\n\n    Returns:\n        tuple[int, int, int, int, str]: Five-element tuple containing:\n            - int: Batch size (B dimension)\n            - int: Width in pixels\n            - int: Height in pixels\n            - int: Number of channels (typically 3 for RGB, 4 for RGBA)\n            - str: Formatted string showing complete shape (B,W,H,C)\n\n    Raises:\n        ValueError: If image is not a torch.Tensor\n        ValueError: If image does not have exactly 4 dimensions\n\n    Notes:\n        - Useful for debugging and dynamic processing\n        - Shape string provides human-readable format\n        - Can handle both RGB and RGBA images\n        - Validates correct tensor format\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n            },\n        }\n\n    RETURN_TYPES = (\"INT\", \"INT\", \"INT\", \"INT\", \"STRING\")\n    RETURN_NAMES = (\"batch\", \"width\", \"height\", \"channels\", \"debug\")\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_CAT\n    CLASS_ID = \"get_image_size\"\n\n    def execute(self, image):\n        return (image.shape[0], image.shape[2], image.shape[1], image.shape[3], str(image.shape))\n</code></pre>"},{"location":"nodes/image_processing/","title":"Image Processing Nodes","text":""},{"location":"nodes/image_processing/#autocrop","title":"AutoCrop","text":"<p>Automatically crops an image based on a mask content.</p> <p>This node detects non-zero regions in a mask and crops both the image and mask to those regions, with optional padding. Useful for removing empty space around subjects or focusing on specific masked areas.</p>"},{"location":"nodes/image_processing/#inputs","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required mask <code>MASK</code> required mask_threshold <code>FLOAT</code> 0.1 min=0.0, max=1.0, step=0.01 required left_padding <code>INT</code> 0 required right_padding <code>INT</code> 0 required top_padding <code>INT</code> 0 required bottom_padding <code>INT</code> 0"},{"location":"nodes/image_processing/#returns","title":"Returns","text":"Name Type image <code>IMAGE</code> mask <code>MASK</code> int <code>INT</code> int <code>INT</code> int <code>INT</code> int <code>INT</code> Source code in image_processing.py <pre><code>class AutoCrop:\n    \"\"\"Automatically crops an image based on a mask content.\n\n    This node detects non-zero regions in a mask and crops both the image and mask\n    to those regions, with optional padding. Useful for removing empty space around\n    subjects or focusing on specific masked areas.\n\n    Args:\n        image (torch.Tensor): Input image tensor in BWHC format with values in range [0, 1]\n        mask (torch.Tensor): Input mask tensor in BWHC format with values in range [0, 1]\n        mask_threshold (float): Minimum mask value to consider as content (0.0-1.0)\n        left_padding (int): Additional pixels to include on the left side\n        right_padding (int): Additional pixels to include on the right side\n        top_padding (int): Additional pixels to include on the top\n        bottom_padding (int): Additional pixels to include on the bottom\n\n    Returns:\n        tuple:\n            - cropped_image (torch.Tensor): Cropped image in BWHC format\n            - cropped_mask (torch.Tensor): Cropped mask in BWHC format\n            - x (int): X-coordinate of crop start in original image\n            - y (int): Y-coordinate of crop start in original image\n            - width (int): Width of cropped region\n            - height (int): Height of cropped region\n\n    Raises:\n        ValueError: If mask and image dimensions don't match\n        RuntimeError: If no content is found in mask above threshold\n\n    Notes:\n        - Input tensors should be in BWHC format (Batch, Width, Height, Channels)\n        - Mask should be single-channel\n        - All padding values must be non-negative\n        - If mask is empty above threshold, may return minimal crop\n        - Coordinates are returned relative to original image\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"mask\": (\"MASK\",),\n                \"mask_threshold\": (\"FLOAT\", {\"default\": 0.1, \"min\": 0.00, \"max\": 1.00, \"step\": 0.01}),\n                \"left_padding\": (\"INT\", {\"default\": 0}),\n                \"right_padding\": (\"INT\", {\"default\": 0}),\n                \"top_padding\": (\"INT\", {\"default\": 0}),\n                \"bottom_padding\": (\"INT\", {\"default\": 0}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\", \"INT\", \"INT\", \"INT\", \"INT\")\n    RETURN_NAMES = (\"cropped_image\", \"cropped_mask\", \"x\", \"y\", \"width\", \"height\")\n\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_PROCESSING_CAT\n\n    def execute(self, **kwargs):\n        img_tensor = TensorImage.from_BWHC(kwargs[\"image\"])\n        mask_tensor = TensorImage.from_BWHC(kwargs[\"mask\"])\n        if img_tensor.shape[1] != 3:\n            img_tensor = rgba_to_rgb(img_tensor)\n\n        padding = (\n            kwargs[\"left_padding\"],\n            kwargs[\"right_padding\"],\n            kwargs[\"top_padding\"],\n            kwargs[\"bottom_padding\"],\n        )\n        img_result, mask_result, min_x, min_y, width, height = auto_crop(\n            img_tensor, mask_tensor, mask_threshold=kwargs[\"mask_threshold\"], padding=padding\n        )\n        output_img = TensorImage(img_result).get_BWHC()\n        output_mask = TensorImage(mask_result).get_BWHC()\n\n        return (output_img, output_mask, min_x, min_y, width, height)\n</code></pre>"},{"location":"nodes/image_processing/#rescale","title":"Rescale","text":"<p>Rescales images and masks by a specified factor while preserving aspect ratio.</p> <p>Provides flexible rescaling of images and masks with support for various interpolation methods and optional antialiasing. Useful for uniform scaling operations where maintaining aspect ratio is important.</p>"},{"location":"nodes/image_processing/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras optional image <code>IMAGE</code> None optional mask <code>MASK</code> None optional factor <code>FLOAT</code> 2.0 min=0.01, max=100.0, step=0.01 optional interpolation <code>LIST</code> optional antialias <code>BOOLEAN</code> True"},{"location":"nodes/image_processing/#returns_1","title":"Returns","text":"Name Type image <code>IMAGE</code> mask <code>MASK</code> Source code in image_processing.py <pre><code>class Rescale:\n    \"\"\"Rescales images and masks by a specified factor while preserving aspect ratio.\n\n    Provides flexible rescaling of images and masks with support for various interpolation\n    methods and optional antialiasing. Useful for uniform scaling operations where\n    maintaining aspect ratio is important.\n\n    Args:\n        image (torch.Tensor, optional): Input image in BWHC format with values in range [0, 1]\n        mask (torch.Tensor, optional): Input mask in BWHC format with values in range [0, 1]\n        factor (float): Scale multiplier (0.01-100.0)\n        interpolation (str): Resampling method to use:\n            - \"nearest\": Nearest neighbor (sharp, blocky)\n            - \"nearest-exact\": Nearest neighbor without rounding\n            - \"bilinear\": Linear interpolation (smooth)\n            - \"bicubic\": Cubic interpolation (smoother)\n            - \"box\": Box sampling (good for downscaling)\n            - \"hamming\": Hamming windowed sampling\n            - \"lanczos\": Lanczos resampling (sharp, fewer artifacts)\n        antialias (bool): Whether to apply antialiasing when downscaling\n\n    Returns:\n        tuple:\n            - image (torch.Tensor): Rescaled image in BWHC format\n            - mask (torch.Tensor): Rescaled mask in BWHC format\n\n    Raises:\n        ValueError: If neither image nor mask is provided\n        ValueError: If invalid interpolation method specified\n        RuntimeError: If input tensors have invalid dimensions\n\n    Notes:\n        - At least one of image or mask must be provided\n        - Output maintains the same number of channels as input\n        - Antialiasing is recommended when downscaling to prevent artifacts\n        - All interpolation methods preserve the value range [0, 1]\n        - Memory usage scales quadratically with factor\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {},\n            \"optional\": {\n                \"image\": (\"IMAGE\", {\"default\": None}),\n                \"mask\": (\"MASK\", {\"default\": None}),\n                \"factor\": (\"FLOAT\", {\"default\": 2.0, \"min\": 0.01, \"max\": 100.0, \"step\": 0.01}),\n                \"interpolation\": (\n                    [\"nearest\", \"nearest-exact\", \"bilinear\", \"bicubic\", \"box\", \"hamming\", \"lanczos\"],\n                ),\n                \"antialias\": (\"BOOLEAN\", {\"default\": True}),\n            },\n        }\n\n    RETURN_TYPES = (\n        \"IMAGE\",\n        \"MASK\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_PROCESSING_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        mask = kwargs.get(\"mask\")\n        if not isinstance(image, torch.Tensor) and not isinstance(mask, torch.Tensor):\n            raise ValueError(\"Either image or mask must be provided\")\n\n        input_image = (\n            TensorImage.from_BWHC(image)\n            if isinstance(image, torch.Tensor)\n            else TensorImage(torch.zeros((1, 3, 1, 1)))\n        )\n        input_mask = (\n            TensorImage.from_BWHC(mask)\n            if isinstance(mask, torch.Tensor)\n            else TensorImage(torch.zeros((1, 1, 1, 1)))\n        )\n        output_image = rescale(\n            input_image,\n            kwargs.get(\"factor\", 2.0),\n            kwargs.get(\"interpolation\", \"nearest\"),\n            kwargs.get(\"antialias\", True),\n        ).get_BWHC()\n        output_mask = rescale(\n            input_mask,\n            kwargs.get(\"factor\", 2.0),\n            kwargs.get(\"interpolation\", \"nearest\"),\n            kwargs.get(\"antialias\", True),\n        ).get_BWHC()\n\n        return (\n            output_image,\n            output_mask,\n        )\n</code></pre>"},{"location":"nodes/image_processing/#resize","title":"Resize","text":"<p>Resizes images and masks to specific dimensions with multiple sizing modes.</p> <p>A versatile resizing node that supports multiple modes for handling aspect ratio and provides fine control over interpolation methods. Suitable for preparing images for specific size requirements while maintaining quality.</p>"},{"location":"nodes/image_processing/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras optional image <code>IMAGE</code> None optional mask <code>MASK</code> None optional width <code>INT</code> 1024 min=32, step=2, max=40960 optional height <code>INT</code> 1024 min=32, step=2, max=40960 optional mode <code>LIST</code> optional interpolation <code>LIST</code> optional antialias <code>BOOLEAN</code> True"},{"location":"nodes/image_processing/#returns_2","title":"Returns","text":"Name Type image <code>IMAGE</code> mask <code>MASK</code> Source code in image_processing.py <pre><code>class Resize:\n    \"\"\"Resizes images and masks to specific dimensions with multiple sizing modes.\n\n    A versatile resizing node that supports multiple modes for handling aspect ratio\n    and provides fine control over interpolation methods. Suitable for preparing\n    images for specific size requirements while maintaining quality.\n\n    Args:\n        image (torch.Tensor, optional): Input image in BWHC format with values in range [0, 1]\n        mask (torch.Tensor, optional): Input mask in BWHC format with values in range [0, 1]\n        width (int): Target width in pixels (32-40960)\n        height (int): Target height in pixels (32-40960)\n        mode (str): How to handle aspect ratio:\n            - \"STRETCH\": Force to exact dimensions, may distort\n            - \"FIT\": Fit within dimensions, may be smaller\n            - \"FILL\": Fill dimensions, may crop\n            - \"ASPECT\": Preserve aspect ratio, fit longest side\n        interpolation (str): Resampling method:\n            - \"bilinear\": Linear interpolation (smooth)\n            - \"nearest\": Nearest neighbor (sharp)\n            - \"bicubic\": Cubic interpolation (smoother)\n            - \"area\": Area averaging (good for downscaling)\n        antialias (bool): Whether to apply antialiasing when downscaling\n\n    Returns:\n        tuple:\n            - image (torch.Tensor): Resized image in BWHC format\n            - mask (torch.Tensor): Resized mask in BWHC format\n\n    Raises:\n        ValueError: If neither image nor mask is provided\n        ValueError: If dimensions are out of valid range\n        ValueError: If invalid mode or interpolation method\n        RuntimeError: If input tensors have invalid dimensions\n\n    Notes:\n        - At least one of image or mask must be provided\n        - Output maintains the same number of channels as input\n        - STRETCH mode may distort image proportions\n        - FIT mode ensures no cropping but may not fill target size\n        - FILL mode ensures target size but may crop content\n        - ASPECT mode preserves proportions using longest edge\n        - Antialiasing recommended when downscaling\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {},\n            \"optional\": {\n                \"image\": (\"IMAGE\", {\"default\": None}),\n                \"mask\": (\"MASK\", {\"default\": None}),\n                \"width\": (\"INT\", {\"default\": 1024, \"min\": 32, \"step\": 2, \"max\": 40960}),\n                \"height\": (\"INT\", {\"default\": 1024, \"min\": 32, \"step\": 2, \"max\": 40960}),\n                \"mode\": ([\"STRETCH\", \"FIT\", \"FILL\", \"ASPECT\"],),\n                \"interpolation\": ([\"bilinear\", \"nearest\", \"bicubic\", \"area\"],),\n                \"antialias\": (\n                    \"BOOLEAN\",\n                    {\"default\": True},\n                ),\n            },\n        }\n\n    RETURN_TYPES = (\n        \"IMAGE\",\n        \"MASK\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_PROCESSING_CAT\n\n    def execute(self, **kwargs):\n        width = kwargs.get(\"width\", 1024)\n        height = kwargs.get(\"height\", 1024)\n        mode = kwargs.get(\"mode\", \"default\")\n        interpolation = kwargs.get(\"interpolation\", \"nearest\")\n        antialias = kwargs.get(\"antialias\", True)\n        image = kwargs.get(\"image\", None)\n        mask = kwargs.get(\"mask\", None)\n\n        input_image = (\n            TensorImage.from_BWHC(image)\n            if isinstance(image, torch.Tensor)\n            else TensorImage(torch.zeros((1, 3, width, height)))\n        )\n        input_mask = (\n            TensorImage.from_BWHC(mask)\n            if isinstance(mask, torch.Tensor)\n            else TensorImage(torch.zeros((1, 1, width, height)))\n        )\n        output_image = resize(input_image, width, height, mode, interpolation, antialias).get_BWHC()\n        output_mask = resize(input_mask, width, height, mode, interpolation, antialias).get_BWHC()\n\n        return (\n            output_image,\n            output_mask,\n        )\n</code></pre>"},{"location":"nodes/image_processing/#rotate","title":"Rotate","text":"<p>Rotates images and masks by a specified angle with optional zoom adjustment.</p> <p>Performs rotation of images and masks with control over whether to zoom to fit the entire rotated content. Useful for reorienting content while managing the trade-off between content preservation and output size.</p>"},{"location":"nodes/image_processing/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras optional image <code>IMAGE</code> None optional mask <code>MASK</code> None optional angle <code>FLOAT</code> 0.0 min=0, max=360.0, step=1.0 optional zoom_to_fit <code>BOOLEAN</code> False"},{"location":"nodes/image_processing/#returns_3","title":"Returns","text":"Name Type image <code>IMAGE</code> mask <code>MASK</code> Source code in image_processing.py <pre><code>class Rotate:\n    \"\"\"Rotates images and masks by a specified angle with optional zoom adjustment.\n\n    Performs rotation of images and masks with control over whether to zoom to fit\n    the entire rotated content. Useful for reorienting content while managing the\n    trade-off between content preservation and output size.\n\n    Args:\n        image (torch.Tensor, optional): Input image in BWHC format with values in range [0, 1]\n        mask (torch.Tensor, optional): Input mask in BWHC format with values in range [0, 1]\n        angle (float): Rotation angle in degrees (0-360)\n        zoom_to_fit (bool): Whether to zoom out to show all rotated content\n\n    Returns:\n        tuple:\n            - image (torch.Tensor): Rotated image in BWHC format\n            - mask (torch.Tensor): Rotated mask in BWHC format\n\n    Raises:\n        ValueError: If neither image nor mask is provided\n        ValueError: If angle is outside valid range\n        RuntimeError: If input tensors have invalid dimensions\n\n    Notes:\n        - At least one of image or mask must be provided\n        - Rotation is performed counterclockwise\n        - When zoom_to_fit is False, corners may be clipped\n        - When zoom_to_fit is True, output may be larger\n        - Interpolation is bilinear for smooth results\n        - Empty areas after rotation are filled with black\n        - Maintains aspect ratio of input\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {},\n            \"optional\": {\n                \"image\": (\"IMAGE\", {\"default\": None}),\n                \"mask\": (\"MASK\", {\"default\": None}),\n                \"angle\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0, \"max\": 360.0, \"step\": 1.0}),\n                \"zoom_to_fit\": (\"BOOLEAN\", {\"default\": False}),\n            },\n        }\n\n    RETURN_TYPES = (\n        \"IMAGE\",\n        \"MASK\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_PROCESSING_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\", None)\n        mask = kwargs.get(\"mask\", None)\n        angle = kwargs.get(\"angle\", 0.0)\n        zoom_to_fit = kwargs.get(\"zoom_to_fit\", False)\n\n        input_image = (\n            TensorImage.from_BWHC(image)\n            if isinstance(image, torch.Tensor)\n            else TensorImage(torch.zeros((1, 3, 1, 1)))\n        )\n        input_mask = (\n            TensorImage.from_BWHC(mask)\n            if isinstance(mask, torch.Tensor)\n            else TensorImage(torch.zeros((1, 1, 1, 1)))\n        )\n        output_image = rotate(input_image, angle, zoom_to_fit).get_BWHC()\n        output_mask = rotate(input_mask, angle, zoom_to_fit).get_BWHC()\n\n        return (\n            output_image,\n            output_mask,\n        )\n</code></pre>"},{"location":"nodes/image_processing/#cutout","title":"Cutout","text":"<p>Creates masked cutouts from images with both RGB and RGBA outputs.</p> <p>Extracts portions of an image based on a mask, providing both RGB and RGBA versions of the result. Useful for isolating subjects or creating transparent cutouts for compositing.</p>"},{"location":"nodes/image_processing/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required mask <code>MASK</code>"},{"location":"nodes/image_processing/#returns_4","title":"Returns","text":"Name Type image <code>IMAGE</code> image <code>IMAGE</code> Source code in image_processing.py <pre><code>class Cutout:\n    \"\"\"Creates masked cutouts from images with both RGB and RGBA outputs.\n\n    Extracts portions of an image based on a mask, providing both RGB and RGBA\n    versions of the result. Useful for isolating subjects or creating transparent\n    cutouts for compositing.\n\n    Args:\n        image (torch.Tensor): Input image in BWHC format with values in range [0, 1]\n        mask (torch.Tensor): Binary or continuous mask in BWHC format with values in range [0, 1]\n\n    Returns:\n        tuple:\n            - rgb (torch.Tensor): Masked image in RGB format (BWHC)\n            - rgba (torch.Tensor): Masked image in RGBA format (BWHC)\n\n    Raises:\n        ValueError: If either image or mask is not provided\n        ValueError: If input tensors have mismatched dimensions\n        RuntimeError: If input tensors have invalid dimensions\n\n    Notes:\n        - Mask values determine transparency in RGBA output\n        - RGB output has masked areas filled with black\n        - RGBA output preserves partial mask values as alpha\n        - Input image must be 3 channels (RGB)\n        - Input mask must be 1 channel\n        - Output maintains original image resolution\n        - All non-zero mask values are considered for cutout\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"mask\": (\"MASK\",),\n            },\n        }\n\n    RETURN_TYPES = (\"IMAGE\", \"IMAGE\")\n    RETURN_NAMES = (\"rgb\", \"rgba\")\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_PROCESSING_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        mask = kwargs.get(\"mask\")\n\n        if not isinstance(image, torch.Tensor) or not isinstance(mask, torch.Tensor):\n            raise ValueError(\"Either image or mask must be provided\")\n\n        tensor_image = TensorImage.from_BWHC(image)\n        tensor_mask = TensorImage.from_BWHC(mask, image.device)\n\n        image_rgb, image_rgba = cutout(tensor_image, tensor_mask)\n\n        out_image_rgb = TensorImage(image_rgb).get_BWHC()\n        out_image_rgba = TensorImage(image_rgba).get_BWHC()\n\n        return (\n            out_image_rgb,\n            out_image_rgba,\n        )\n</code></pre>"},{"location":"nodes/image_processing/#upscaleimage","title":"UpscaleImage","text":"<p>AI-powered image upscaling with tiled processing and flexible scaling modes.</p> <p>A comprehensive image upscaling node that leverages AI models for high-quality image enlargement. Supports both factor-based rescaling and target size resizing while efficiently managing GPU memory through tiled processing. Compatible with various AI upscaling models and includes multiple resampling methods for final adjustments.</p>"},{"location":"nodes/image_processing/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required upscale_model <code>&lt;ast.Call object at 0x7f1c09080f10&gt;</code> required mode <code>LIST</code> required rescale_factor <code>FLOAT</code> 2 min=0.01, max=100.0, step=0.01 required resize_size <code>INT</code> 1024 min=1, max=48000, step=1 required resampling_method <code>&lt;ast.Name object at 0x7f1c09083a30&gt;</code> required tiled_size <code>INT</code> 512 min=128, max=2048, step=128"},{"location":"nodes/image_processing/#returns_5","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in image_processing.py <pre><code>class UpscaleImage:\n    \"\"\"AI-powered image upscaling with tiled processing and flexible scaling modes.\n\n    A comprehensive image upscaling node that leverages AI models for high-quality image enlargement.\n    Supports both factor-based rescaling and target size resizing while efficiently managing GPU\n    memory through tiled processing. Compatible with various AI upscaling models and includes\n    multiple resampling methods for final adjustments.\n\n    Args:\n        image (torch.Tensor): Input image tensor in BCHW format with values in range [0, 1].\n        upscale_model (str): Filename of the AI upscaling model to use.\n        mode (str): Scaling mode, either:\n            - \"rescale\": Scale relative to original size by a factor\n            - \"resize\": Scale to a specific target size\n        rescale_factor (float, optional): Scaling multiplier when using \"rescale\" mode.\n            Defaults to 2.0.\n        resize_size (int, optional): Target size in pixels for longest edge when using \"resize\" mode.\n            Defaults to 1024.\n        resampling_method (str, optional): Final resampling method for precise size adjustment.\n            Options: \"bilinear\", \"nearest\", \"bicubic\", \"area\". Defaults to \"bilinear\".\n        tiled_size (int, optional): Size of processing tiles in pixels. Larger tiles use more GPU memory.\n            Defaults to 512.\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing:\n            - image (torch.Tensor): Upscaled image in BCHW format with values in range [0, 1]\n\n    Raises:\n        ValueError: If the upscale model is invalid or incompatible\n        RuntimeError: If GPU memory is insufficient even with minimum tile size\n        TypeError: If input tensors are of incorrect type\n\n    Notes:\n        - Models are loaded from the \"upscale_models\" directory\n        - Processing is done in tiles to manage GPU memory efficiently\n        - For large upscaling factors, multiple passes may be performed\n        - The aspect ratio is always preserved in \"resize\" mode\n        - If GPU memory is insufficient, tile size is automatically reduced\n        - Tiled processing may show slight seams with some models\n        - Final output is always clamped to [0, 1] range\n        - Model scale factor is automatically detected and respected\n        - Progress bar shows processing status for large images\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        resampling_methods = [\"bilinear\", \"nearest\", \"bicubic\", \"area\"]\n\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"upscale_model\": (folder_paths.get_filename_list(\"upscale_models\"),),\n                \"mode\": ([\"rescale\", \"resize\"],),\n                \"rescale_factor\": (\"FLOAT\", {\"default\": 2, \"min\": 0.01, \"max\": 100.0, \"step\": 0.01}),\n                \"resize_size\": (\"INT\", {\"default\": 1024, \"min\": 1, \"max\": 48000, \"step\": 1}),\n                \"resampling_method\": (resampling_methods,),\n                \"tiled_size\": (\"INT\", {\"default\": 512, \"min\": 128, \"max\": 2048, \"step\": 128}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    RETURN_NAMES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = IMAGE_PROCESSING_CAT\n\n    def load_model(self, model_name):\n        model_path = folder_paths.get_full_path(\"upscale_models\", model_name)\n        sd = comfy.utils.load_torch_file(model_path, safe_load=True)\n        if \"module.layers.0.residual_group.blocks.0.norm1.weight\" in sd:\n            sd = comfy.utils.state_dict_prefix_replace(sd, {\"module.\": \"\"})\n        out = ModelLoader().load_from_state_dict(sd).eval()\n\n        if not isinstance(out, ImageModelDescriptor):\n            raise ValueError(\"Upscale model must be a single-image model.\")\n\n        return out\n\n    def upscale_with_model(self, **kwargs) -&gt; torch.Tensor:\n        upscale_model = kwargs.get(\"upscale_model\")\n        image = kwargs.get(\"image\")\n        device = kwargs.get(\"device\")\n        tile = kwargs.get(\"tile\", 512)\n        overlap = kwargs.get(\"overlap\", 32)\n\n        if upscale_model is None:\n            raise ValueError(\"upscale_model is required\")\n        if image is None:\n            raise ValueError(\"image is required\")\n        if device is None:\n            raise ValueError(\"device is required\")\n        if not isinstance(tile, int):\n            raise ValueError(\"tile must be an integer\")\n        if not isinstance(overlap, int):\n            raise ValueError(\"overlap must be an integer\")\n        if not hasattr(upscale_model, \"model\"):\n            raise ValueError(\"upscale_model must have a model attribute\")\n        if not hasattr(upscale_model, \"scale\"):\n            raise ValueError(\"upscale_model must have a scale attribute\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"image must be a torch.Tensor\")\n\n        memory_required = model_management.module_size(upscale_model.model)\n        memory_required += (tile * tile * 3) * image.element_size() * max(upscale_model.scale, 1.0) * 384.0\n        memory_required += image.nelement() * image.element_size()\n        model_management.free_memory(memory_required, device)\n        in_img = image.movedim(-1, -3).to(device)\n\n        s = None\n        oom = True\n        while oom:\n            try:\n                steps = in_img.shape[0] * comfy.utils.get_tiled_scale_steps(\n                    in_img.shape[3], in_img.shape[2], tile_x=tile, tile_y=tile, overlap=overlap\n                )\n                pbar = comfy.utils.ProgressBar(steps)\n                s = comfy.utils.tiled_scale(\n                    in_img,\n                    lambda a: upscale_model(a),\n                    tile_x=tile,\n                    tile_y=tile,\n                    overlap=overlap,\n                    upscale_amount=upscale_model.scale,\n                    pbar=pbar,\n                )\n                oom = False\n            except model_management.OOM_EXCEPTION as e:\n                tile //= 2\n                if tile &lt; 128:\n                    raise e\n\n        if not isinstance(s, torch.Tensor):\n            raise ValueError(\"Upscaling failed\")\n        s = torch.clamp(s.movedim(-3, -1), min=0, max=1.0)  # type: ignore\n        return s\n\n    def execute(self, image, upscale_model, **kwargs):\n        # Load upscale model\n        up_model = self.load_model(upscale_model)\n        device = model_management.get_torch_device()\n        up_model.to(device)\n\n        # Get kwargs with defaults\n        mode = kwargs.get(\"mode\", \"rescale\")\n        resampling_method = kwargs.get(\"resampling_method\", \"bilinear\")\n        rescale_factor = kwargs.get(\"rescale_factor\", 2)\n        resize_size = kwargs.get(\"resize_size\", 1024)\n        tiled_size = kwargs.get(\"tiled_size\", 512)\n\n        # target size\n        _, H, W, _ = image.shape\n        target_size = resize_size if mode == \"resize\" else max(H, W) * rescale_factor\n        current_size = max(H, W)\n        up_image = image\n        while current_size &lt; target_size:\n            step = self.upscale_with_model(\n                upscale_model=up_model, image=up_image, device=device, tile=tiled_size\n            )\n            del up_image\n            up_image = step.to(\"cpu\")\n            _, H, W, _ = up_image.shape\n            current_size = max(H, W)\n\n        up_model.to(\"cpu\")\n        tensor_image = TensorImage.from_BWHC(up_image)\n\n        if mode == \"resize\":\n            up_image = resize(\n                tensor_image, resize_size, resize_size, \"ASPECT\", resampling_method, True\n            ).get_BWHC()\n        else:\n            # get the max size of the upscaled image\n            _, _, H, W = tensor_image.shape\n            upscaled_max_size = max(H, W)\n\n            original_image = TensorImage.from_BWHC(image)\n            _, _, ori_H, ori_W = original_image.shape\n            original_max_size = max(ori_H, ori_W)\n\n            # rescale_factor is the factor to multiply the original max size\n            original_target_size = rescale_factor * original_max_size\n            scale_factor = original_target_size / upscaled_max_size\n\n            up_image = rescale(tensor_image, scale_factor, resampling_method, True).get_BWHC()\n\n        return (up_image,)\n</code></pre>"},{"location":"nodes/logic/","title":"Logic Nodes","text":""},{"location":"nodes/logic/#switch","title":"Switch","text":"<p>Switches between two input values based on a boolean condition.</p> <p>A logic gate that selects between two inputs of any type based on a boolean condition. When the condition is True, it returns the 'true' value; otherwise, it returns the 'false' value. This node is useful for creating conditional workflows and dynamic value selection.</p>"},{"location":"nodes/logic/#inputs","title":"Inputs","text":"Group Name Type Default Extras required condition <code>BOOLEAN</code> True required on_true <code>&lt;ast.Name object at 0x7f1c090836d0&gt;</code> required on_false <code>&lt;ast.Name object at 0x7f1c09083d60&gt;</code> Source code in logic.py <pre><code>class Switch:\n    \"\"\"Switches between two input values based on a boolean condition.\n\n    A logic gate that selects between two inputs of any type based on a boolean condition. When the\n    condition is True, it returns the 'true' value; otherwise, it returns the 'false' value. This node\n    is useful for creating conditional workflows and dynamic value selection.\n\n    Args:\n        condition (bool): The boolean condition that determines which value to return.\n            Defaults to False if not provided.\n        on_true (Any): The value to return when the condition is True. Can be of any type.\n        on_false (Any): The value to return when the condition is False. Can be of any type.\n\n    Returns:\n        tuple[Any]: A single-element tuple containing either the 'true' or 'false' value based on\n            the condition.\n\n    Notes:\n        - The node accepts inputs of any type, making it versatile for different data types\n        - Both 'on_true' and 'on_false' values must be provided\n        - The condition is automatically cast to boolean, with None being treated as False\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"condition\": (\"BOOLEAN\", {\"default\": True}),\n                \"on_true\": (any_type,),\n                \"on_false\": (any_type,),\n            }\n        }\n\n    RETURN_TYPES = (any_type,)\n    RETURN_NAMES = (\"output\",)\n    FUNCTION = \"execute\"\n    CATEGORY = LOGIC_CAT\n\n    def check_lazy_status(self, condition, on_true=None, on_false=None):\n\n        if condition and on_true is None:\n            on_true = [\"on_true\"]\n            if isinstance(on_true, ExecutionBlocker):\n                on_true = on_true.message  # type: ignore\n            return on_true\n        if not condition and on_false is None:\n            on_false = [\"on_false\"]\n            if isinstance(on_false, ExecutionBlocker):\n                on_false = on_false.message  # type: ignore\n            return on_false\n        return None\n\n    def execute(self, **kwargs):\n        return (kwargs[\"on_true\"] if kwargs[\"condition\"] else kwargs[\"on_false\"],)\n</code></pre>"},{"location":"nodes/logic/#blocker","title":"Blocker","text":"<p>Controls flow execution based on a boolean condition.</p> <p>A utility node that blocks or allows execution flow based on a boolean flag. When the continue flag is False, it blocks execution by returning an ExecutionBlocker. When True, it passes through the input value unchanged.</p>"},{"location":"nodes/logic/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required continue <code>BOOLEAN</code> False required in <code>&lt;ast.Name object at 0x7f1c090837c0&gt;</code> None Source code in logic.py <pre><code>class Blocker:\n    \"\"\"Controls flow execution based on a boolean condition.\n\n    A utility node that blocks or allows execution flow based on a boolean flag. When the continue\n    flag is False, it blocks execution by returning an ExecutionBlocker. When True, it passes through\n    the input value unchanged.\n\n    Args:\n        continue (bool): Flag to control execution flow. When False, blocks execution.\n        in (Any): The input value to pass through when execution is allowed.\n\n    Returns:\n        tuple[Any]: A single-element tuple containing either:\n            - The input value if continue is True\n            - An ExecutionBlocker if continue is False\n\n    Notes:\n        - Useful for conditional workflow execution\n        - Can be used to create branches in execution flow\n        - The ExecutionBlocker prevents downstream nodes from executing\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"continue\": (\"BOOLEAN\", {\"default\": False}),\n                \"in\": (any_type, {\"default\": None}),\n            },\n        }\n\n    RETURN_TYPES = (any_type,)\n    RETURN_NAMES = (\"out\",)\n    CATEGORY = LABS_CAT\n    FUNCTION = \"execute\"\n\n    def execute(self, **kwargs):\n        return (kwargs[\"in\"] if kwargs[\"continue\"] else ExecutionBlocker(None),)\n</code></pre>"},{"location":"nodes/logic/#compare","title":"Compare","text":"<p>Compares two input values based on a specified comparison operation.</p> <p>A logic gate that evaluates a comparison between two inputs of any type. The comparison is determined by the specified operation, which can include equality, inequality, and relational comparisons. This node is useful for implementing conditional logic based on the relationship between two values.</p>"},{"location":"nodes/logic/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required a <code>&lt;ast.Name object at 0x7f1c09083160&gt;</code> required b <code>&lt;ast.Name object at 0x7f1c09081ae0&gt;</code> required comparison <code>&lt;ast.Name object at 0x7f1c09082ad0&gt;</code> a == b"},{"location":"nodes/logic/#returns","title":"Returns","text":"Name Type boolean <code>BOOLEAN</code> Source code in logic.py <pre><code>class Compare:\n    \"\"\"Compares two input values based on a specified comparison operation.\n\n    A logic gate that evaluates a comparison between two inputs of any type. The comparison is determined\n    by the specified operation, which can include equality, inequality, and relational comparisons. This\n    node is useful for implementing conditional logic based on the relationship between two values.\n\n    Args:\n        a (Any): The first value to compare. Can be of any type.\n        b (Any): The second value to compare. Can be of any type.\n        comparison (str): The comparison operation to perform. Defaults to \"a == b\".\n            Available options include:\n            - \"a == b\": Checks if a is equal to b.\n            - \"a != b\": Checks if a is not equal to b.\n            - \"a &lt; b\": Checks if a is less than b.\n            - \"a &gt; b\": Checks if a is greater than b.\n            - \"a &lt;= b\": Checks if a is less than or equal to b.\n            - \"a &gt;= b\": Checks if a is greater than or equal to b.\n\n    Returns:\n        tuple[bool]: A single-element tuple containing the result of the comparison as a boolean value.\n\n    Notes:\n        - The node accepts inputs of any type, making it versatile for different data types.\n        - If the inputs are tensors, lists, or tuples,\n          the comparison will be evaluated based on their shapes or lengths.\n        - The output will be cast to a boolean value.\n    \"\"\"\n\n    COMPARE_FUNCTIONS = {\n        \"a == b\": lambda a, b: a == b,\n        \"a != b\": lambda a, b: a != b,\n        \"a &lt; b\": lambda a, b: a &lt; b,\n        \"a &gt; b\": lambda a, b: a &gt; b,\n        \"a &lt;= b\": lambda a, b: a &lt;= b,\n        \"a &gt;= b\": lambda a, b: a &gt;= b,\n    }\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        compare_functions = list(cls.COMPARE_FUNCTIONS.keys())\n        return {\n            \"required\": {\n                \"a\": (any_type,),\n                \"b\": (any_type,),\n                \"comparison\": (compare_functions, {\"default\": \"a == b\"}),\n            }\n        }\n\n    RETURN_TYPES = (\"BOOLEAN\",)\n    RETURN_NAMES = (\"result\",)\n    FUNCTION = \"execute\"\n    CATEGORY = LOGIC_CAT\n\n    def execute(self, **kwargs):\n        input_a = kwargs.get(\"a\")\n        input_b = kwargs.get(\"b\")\n        comparison = kwargs.get(\"comparison\") or \"a == b\"\n\n        try:\n            output = self.COMPARE_FUNCTIONS[comparison](input_a, input_b)\n        except Exception as e:\n            if isinstance(input_a, torch.Tensor) and isinstance(input_b, torch.Tensor):\n                output = self.COMPARE_FUNCTIONS[comparison](input_a.shape, input_b.shape)\n            elif isinstance(input_a, (list, tuple)) and isinstance(input_b, (list, tuple)):\n                output = self.COMPARE_FUNCTIONS[comparison](len(input_a), len(input_b))\n            else:\n                raise e\n\n        if isinstance(output, torch.Tensor):\n            output = output.all().item()\n        elif isinstance(output, (list, tuple)):\n            output = all(output)\n\n        return (bool(output),)\n</code></pre>"},{"location":"nodes/logic/#loopstart","title":"LoopStart","text":"<p>Initiates a loop with optional initial values for each iteration.</p> <p>A control node that starts a loop, allowing for a specified number of iterations. It can accept optional initial values for each iteration, which can be used within the loop. This node is useful for creating iterative workflows where the same set of operations is performed multiple times.</p> Source code in logic.py <pre><code>class LoopStart:\n    \"\"\"Initiates a loop with optional initial values for each iteration.\n\n    A control node that starts a loop, allowing for a specified number of iterations. It can accept\n    optional initial values for each iteration, which can be used within the loop. This node is useful\n    for creating iterative workflows where the same set of operations is performed multiple times.\n\n    Args:\n        init_value (Any): The initial value for the first iteration. Can be of any type.\n\n    Returns:\n        tuple[tuple]: A tuple containing a flow control signal and the initial values for each iteration.\n\n    Notes:\n        - The number of initial values can be adjusted by changing the MAX_FLOW_NUM constant.\n        - Each initial value can be of any type, providing flexibility for different workflows.\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        inputs = {\n            \"optional\": {},\n        }\n        for i in range(MAX_FLOW_NUM):\n            inputs[\"optional\"][f\"init_value_{i}\"] = (any_type,)\n        return inputs\n\n    RETURN_TYPES = ByPassTypeTuple(tuple([\"FLOW_CONTROL\"] + [any_type] * MAX_FLOW_NUM))\n    RETURN_NAMES = ByPassTypeTuple(tuple([\"flow\"] + [f\"value_{i}\" for i in range(MAX_FLOW_NUM)]))\n    FUNCTION = \"execute\"\n\n    CATEGORY = LABS_CAT + \"/Loops\"\n\n    def execute(self, **kwargs):\n        values = []\n        for i in range(MAX_FLOW_NUM):\n            values.append(kwargs.get(f\"init_value_{i}\", None))\n        return tuple([\"stub\"] + values)\n</code></pre>"},{"location":"nodes/logic/#loopend","title":"LoopEnd","text":"<p>Ends a loop and returns the final values after the loop execution.</p> <p>A control node that signifies the end of a loop initiated by a <code>LoopStart</code> node. It processes the flow control signal and can return the final values from the loop iterations. This node is useful for managing the completion of iterative workflows and retrieving results after looping.</p> Source code in logic.py <pre><code>class LoopEnd:\n    \"\"\"Ends a loop and returns the final values after the loop execution.\n\n    A control node that signifies the end of a loop initiated by a `LoopStart` node. It processes the\n    flow control signal and can return the final values from the loop iterations. This node is useful\n    for managing the completion of iterative workflows and retrieving results after looping.\n\n    Args:\n        flow (FLOW_CONTROL): The flow control signal indicating the current state of the loop.\n        end_loop (bool): A boolean flag that indicates whether to end the loop. If True, the loop will terminate.\n        dynprompt (DYNPROMPT, optional): Dynamic prompt information for the node.\n        unique_id (UNIQUE_ID, optional): A unique identifier for the loop instance.\n\n    Returns:\n        tuple: A tuple containing the final values from the loop iterations.\n\n    Notes:\n        - The loop can be terminated based on the `end_loop` flag,\n          allowing for flexible control over the iteration process.\n        - The number of returned values corresponds to the number of initial values provided in the `LoopStart`.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        inputs = {\n            \"required\": {\n                \"flow\": (\"FLOW_CONTROL\", {\"rawLink\": True}),\n                \"end_loop\": (\"BOOLEAN\", {}),\n            },\n            \"optional\": {},\n            \"hidden\": {\n                \"dynprompt\": \"DYNPROMPT\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n        for i in range(MAX_FLOW_NUM):\n            inputs[\"optional\"][f\"init_value_{i}\"] = (any_type,)\n        return inputs\n\n    RETURN_TYPES = ByPassTypeTuple(tuple([any_type] * MAX_FLOW_NUM))\n    RETURN_NAMES = ByPassTypeTuple(tuple(f\"value_{i}\" for i in range(MAX_FLOW_NUM)))\n    FUNCTION = \"execute\"\n\n    CATEGORY = LABS_CAT + \"/Loops\"\n\n    def explore_dependencies(self, node_id, dynprompt, upstream):\n        node_info = dynprompt.get_node(node_id)\n        if \"inputs\" not in node_info:\n            return\n        for _, v in node_info[\"inputs\"].items():\n            if is_link(v):\n                parent_id = v[0]\n                if parent_id not in upstream:\n                    upstream[parent_id] = []\n                    self.explore_dependencies(parent_id, dynprompt, upstream)\n                upstream[parent_id].append(node_id)\n\n    def collect_contained(self, node_id, upstream, contained):\n        if node_id not in upstream:\n            return\n        for child_id in upstream[node_id]:\n            if child_id not in contained:\n                contained[child_id] = True\n                self.collect_contained(child_id, upstream, contained)\n\n    def execute(self, flow, end_loop, dynprompt=None, unique_id=None, **kwargs):\n        if end_loop:\n            # We're done with the loop\n            values = []\n            for i in range(MAX_FLOW_NUM):\n                values.append(kwargs.get(f\"init_value_{i}\", None))\n            return tuple(values)\n\n        # We want to loop\n        if dynprompt is not None:\n            _ = dynprompt.get_node(unique_id)\n        upstream = {}\n        # Get the list of all nodes between the open and close nodes\n        self.explore_dependencies(unique_id, dynprompt, upstream)\n\n        contained = {}\n        open_node = flow[0]\n        self.collect_contained(open_node, upstream, contained)\n        contained[unique_id] = True\n        contained[open_node] = True\n\n        graph = GraphBuilder()\n        for node_id in contained:\n            if dynprompt is not None:\n                original_node = dynprompt.get_node(node_id)\n                node = graph.node(original_node[\"class_type\"], \"Recurse\" if node_id == unique_id else node_id)\n                node.set_override_display_id(node_id)\n        for node_id in contained:\n            if dynprompt is not None:\n                original_node = dynprompt.get_node(node_id)\n                node = graph.lookup_node(\"Recurse\" if node_id == unique_id else node_id)\n                for k, v in original_node[\"inputs\"].items():\n                    if is_link(v) and v[0] in contained:\n                        parent = graph.lookup_node(v[0])\n                        node.set_input(k, parent.out(v[1]))\n                    else:\n                        node.set_input(k, v)\n\n        new_open = graph.lookup_node(open_node)\n        for i in range(MAX_FLOW_NUM):\n            key = f\"init_value_{i}\"\n            new_open.set_input(key, kwargs.get(key, None))\n        my_clone = graph.lookup_node(\"Recurse\")\n        result = map(lambda x: my_clone.out(x), range(MAX_FLOW_NUM))\n        return {\n            \"result\": tuple(result),\n            \"expand\": graph.finalize(),\n        }\n</code></pre>"},{"location":"nodes/lora/","title":"Lora Nodes","text":""},{"location":"nodes/lora/#applylorastack","title":"ApplyLoraStack","text":"<p>Applies multiple LoRA models sequentially to a base model and CLIP in ComfyUI.</p> <p>This node takes a base model, CLIP, and a stack of LoRA models as input. It applies each LoRA in the stack sequentially using specified weights for both model and CLIP components.</p>"},{"location":"nodes/lora/#inputs","title":"Inputs","text":"Group Name Type Default Extras required model <code>MODEL</code> required clip <code>CLIP</code> required lora_stack <code>LORA_STACK</code>"},{"location":"nodes/lora/#returns","title":"Returns","text":"Name Type model <code>MODEL</code> clip <code>CLIP</code> Source code in lora.py <pre><code>class ApplyLoraStack:\n    \"\"\"Applies multiple LoRA models sequentially to a base model and CLIP in ComfyUI.\n\n    This node takes a base model, CLIP, and a stack of LoRA models as input. It applies each LoRA\n    in the stack sequentially using specified weights for both model and CLIP components.\n\n    Args:\n        model (MODEL): The base Stable Diffusion model to modify\n        clip (CLIP): The CLIP model to modify\n        lora_stack (LORA_STACK): A list of tuples containing (lora_name, model_weight, clip_weight)\n\n    Returns:\n        tuple:\n            - MODEL: The modified Stable Diffusion model with all LoRAs applied\n            - CLIP: The modified CLIP model with all LoRAs applied\n\n    Notes:\n        - LoRAs are applied in sequence, with each modification building on previous changes\n        - If lora_stack is None, returns the original model and CLIP unchanged\n        - Uses ComfyUI's built-in LoRA loading and application mechanisms\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"model\": (\"MODEL\",),\n                \"clip\": (\"CLIP\",),\n                \"lora_stack\": (\"LORA_STACK\",),\n            }\n        }\n\n    RETURN_TYPES = (\n        \"MODEL\",\n        \"CLIP\",\n    )\n    RETURN_NAMES = (\n        \"MODEL\",\n        \"CLIP\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = LORA_CAT\n\n    def execute(\n        self,\n        **kwargs,\n    ):\n        model = kwargs.get(\"model\")\n        clip = kwargs.get(\"clip\")\n        lora_stack = kwargs.get(\"lora_stack\")\n        loras = []\n        if lora_stack is None:\n            return (\n                model,\n                clip,\n            )\n\n        model_lora = model\n        clip_lora = clip\n        loras.extend(lora_stack)\n\n        for lora in loras:\n            lora_name, strength_model, strength_clip = lora\n\n            lora_path = folder_paths.get_full_path(\"loras\", lora_name)\n            lora = utils.load_torch_file(lora_path, safe_load=True)\n\n            model_lora, clip_lora = sd.load_lora_for_models(\n                model_lora, clip_lora, lora, strength_model, strength_clip\n            )\n\n        return (\n            model_lora,\n            clip_lora,\n        )\n</code></pre>"},{"location":"nodes/lora/#lorastacker","title":"LoraStacker","text":"<p>Manages multiple LoRA models with configurable weights and modes.</p> <p>This node provides an interface for stacking multiple LoRA models with independent weight controls and two operating modes for simple or advanced weight management.</p>"},{"location":"nodes/lora/#returns_1","title":"Returns","text":"Name Type lora_stack <code>LORA_STACK</code> Source code in lora.py <pre><code>class LoraStacker:\n    \"\"\"Manages multiple LoRA models with configurable weights and modes.\n\n    This node provides an interface for stacking multiple LoRA models with independent\n    weight controls and two operating modes for simple or advanced weight management.\n\n    Args:\n        num_slots (str): Number of LoRA slots to enable (1-10)\n        mode (str): Weight control mode:\n            - \"Simple\": Single weight per LoRA\n            - \"Advanced\": Separate model and CLIP weights\n        switch_1..10 (str): \"On\"/\"Off\" toggle for each LoRA slot\n        lora_name_1..10 (str): Name of LoRA model for each slot\n        weight_1..10 (float): Weight value for simple mode (-10.0 to 10.0)\n        model_weight_1..10 (float): Model weight for advanced mode (-10.0 to 10.0)\n        clip_weight_1..10 (float): CLIP weight for advanced mode (-10.0 to 10.0)\n        lora_stack (LORA_STACK, optional): Existing stack to extend\n\n    Returns:\n        tuple[LORA_STACK]: Single-element tuple containing list of configured LoRAs\n\n    Notes:\n        - Each slot can be independently enabled/disabled\n        - Simple mode uses same weight for model and CLIP\n        - Advanced mode allows separate model and CLIP weights\n        - Weights can be negative for inverse effects\n        - Can extend existing LORA_STACK\n        - Disabled or empty slots are skipped\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        loras = [\"None\"] + folder_paths.get_filename_list(\"loras\")\n\n        inputs = {\n            \"required\": {\n                \"num_slots\": ([str(i) for i in range(1, 11)], {\"default\": \"1\"}),\n                \"mode\": ([\"Simple\", \"Advanced\"],),\n            },\n            \"optional\": {\"lora_stack\": (\"LORA_STACK\",)},\n        }\n\n        for i in range(1, 11):\n            inputs[\"optional\"].update(\n                {\n                    f\"switch_{i}\": ([\"On\", \"Off\"],),\n                    f\"lora_name_{i}\": (loras,),\n                    f\"weight_{i}\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                    f\"model_weight_{i}\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                    f\"clip_weight_{i}\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                }\n            )\n\n        return inputs\n\n    RETURN_TYPES = (\"LORA_STACK\",)\n    RETURN_NAMES = (\"lora_stack\",)\n    FUNCTION = \"execute\"\n    CATEGORY = LABS_CAT\n    CLASS_ID = \"lora_stacker\"\n\n    def execute(self, **kwargs):\n        num_slots = int(kwargs.get(\"num_slots\", 3))\n        mode = kwargs.get(\"mode\", \"Simple\")\n        lora_stack = kwargs.get(\"lora_stack\")\n\n        lora_list: list = []\n        if lora_stack is not None:\n            lora_list.extend([l for l in lora_stack if l[0] is not None and l[0] != \"\"])\n\n        for i in range(1, num_slots + 1):\n            switch = kwargs.get(f\"switch_{i}\")\n            lora_name = kwargs.get(f\"lora_name_{i}\") or \"None\"\n\n            if lora_name is not None and lora_name != \"None\" and switch == \"On\":\n                if mode == \"Simple\":\n                    weight = float(kwargs.get(f\"weight_{i}\") or 1.0)\n                    lora_list.extend([(lora_name, weight, weight)])\n                else:\n                    model_weight = float(kwargs.get(f\"model_weight_{i}\") or 1.0)\n                    clip_weight = float(kwargs.get(f\"clip_weight_{i}\") or 1.0)\n                    lora_list.extend([(lora_name, model_weight, clip_weight)])\n\n        return (lora_list,)\n</code></pre>"},{"location":"nodes/lora/#lorastack","title":"LoraStack","text":"<p>Creates a configurable stack of up to 3 LoRA models with adjustable weights.</p> <p>Provides a user interface to enable/disable and configure up to three LoRA models with independent weights for both model and CLIP components. Can extend an existing LORA_STACK.</p>"},{"location":"nodes/lora/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required switch_1 <code>LIST</code> required lora_name_1 <code>&lt;ast.Name object at 0x7f1c0902ce50&gt;</code> required model_weight_1 <code>FLOAT</code> 1.0 max=10.0, step=0.01 required clip_weight_1 <code>FLOAT</code> 1.0 max=10.0, step=0.01 required switch_2 <code>LIST</code> required lora_name_2 <code>&lt;ast.Name object at 0x7f1c0902f1c0&gt;</code> required model_weight_2 <code>FLOAT</code> 1.0 max=10.0, step=0.01 required clip_weight_2 <code>FLOAT</code> 1.0 max=10.0, step=0.01 required switch_3 <code>LIST</code> required lora_name_3 <code>&lt;ast.Name object at 0x7f1c0902d360&gt;</code> required model_weight_3 <code>FLOAT</code> 1.0 max=10.0, step=0.01 required clip_weight_3 <code>FLOAT</code> 1.0 max=10.0, step=0.01 optional lora_stack <code>LORA_STACK</code>"},{"location":"nodes/lora/#returns_2","title":"Returns","text":"Name Type lora_stack <code>LORA_STACK</code> Source code in lora.py <pre><code>class LoraStacker:\n    \"\"\"Manages multiple LoRA models with configurable weights and modes.\n\n    This node provides an interface for stacking multiple LoRA models with independent\n    weight controls and two operating modes for simple or advanced weight management.\n\n    Args:\n        num_slots (str): Number of LoRA slots to enable (1-10)\n        mode (str): Weight control mode:\n            - \"Simple\": Single weight per LoRA\n            - \"Advanced\": Separate model and CLIP weights\n        switch_1..10 (str): \"On\"/\"Off\" toggle for each LoRA slot\n        lora_name_1..10 (str): Name of LoRA model for each slot\n        weight_1..10 (float): Weight value for simple mode (-10.0 to 10.0)\n        model_weight_1..10 (float): Model weight for advanced mode (-10.0 to 10.0)\n        clip_weight_1..10 (float): CLIP weight for advanced mode (-10.0 to 10.0)\n        lora_stack (LORA_STACK, optional): Existing stack to extend\n\n    Returns:\n        tuple[LORA_STACK]: Single-element tuple containing list of configured LoRAs\n\n    Notes:\n        - Each slot can be independently enabled/disabled\n        - Simple mode uses same weight for model and CLIP\n        - Advanced mode allows separate model and CLIP weights\n        - Weights can be negative for inverse effects\n        - Can extend existing LORA_STACK\n        - Disabled or empty slots are skipped\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        loras = [\"None\"] + folder_paths.get_filename_list(\"loras\")\n\n        inputs = {\n            \"required\": {\n                \"num_slots\": ([str(i) for i in range(1, 11)], {\"default\": \"1\"}),\n                \"mode\": ([\"Simple\", \"Advanced\"],),\n            },\n            \"optional\": {\"lora_stack\": (\"LORA_STACK\",)},\n        }\n\n        for i in range(1, 11):\n            inputs[\"optional\"].update(\n                {\n                    f\"switch_{i}\": ([\"On\", \"Off\"],),\n                    f\"lora_name_{i}\": (loras,),\n                    f\"weight_{i}\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                    f\"model_weight_{i}\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                    f\"clip_weight_{i}\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                }\n            )\n\n        return inputs\n\n    RETURN_TYPES = (\"LORA_STACK\",)\n    RETURN_NAMES = (\"lora_stack\",)\n    FUNCTION = \"execute\"\n    CATEGORY = LABS_CAT\n    CLASS_ID = \"lora_stacker\"\n\n    def execute(self, **kwargs):\n        num_slots = int(kwargs.get(\"num_slots\", 3))\n        mode = kwargs.get(\"mode\", \"Simple\")\n        lora_stack = kwargs.get(\"lora_stack\")\n\n        lora_list: list = []\n        if lora_stack is not None:\n            lora_list.extend([l for l in lora_stack if l[0] is not None and l[0] != \"\"])\n\n        for i in range(1, num_slots + 1):\n            switch = kwargs.get(f\"switch_{i}\")\n            lora_name = kwargs.get(f\"lora_name_{i}\") or \"None\"\n\n            if lora_name is not None and lora_name != \"None\" and switch == \"On\":\n                if mode == \"Simple\":\n                    weight = float(kwargs.get(f\"weight_{i}\") or 1.0)\n                    lora_list.extend([(lora_name, weight, weight)])\n                else:\n                    model_weight = float(kwargs.get(f\"model_weight_{i}\") or 1.0)\n                    clip_weight = float(kwargs.get(f\"clip_weight_{i}\") or 1.0)\n                    lora_list.extend([(lora_name, model_weight, clip_weight)])\n\n        return (lora_list,)\n\n\nclass LoraStack:\n    \"\"\"Creates a configurable stack of up to 3 LoRA models with adjustable weights.\n\n    Provides a user interface to enable/disable and configure up to three LoRA models with independent\n    weights for both model and CLIP components. Can extend an existing LORA_STACK.\n\n    Args:\n        switch_1/2/3 (str): \"On\" or \"Off\" to enable/disable each LoRA\n        lora_name_1/2/3 (str): Names of LoRA models to use\n        model_weight_1/2/3 (float): Weight multipliers for model component (-10.0 to 10.0)\n        clip_weight_1/2/3 (float): Weight multipliers for CLIP component (-10.0 to 10.0)\n        lora_stack (LORA_STACK, optional): Existing stack to extend\n\n    Returns:\n        tuple:\n            - LORA_STACK: List of tuples (lora_name, model_weight, clip_weight)\n\n    Notes:\n        - Each LoRA can be independently enabled/disabled\n        - Weights can be negative for inverse effects\n        - Only enabled LoRAs with valid names (not \"None\") are included in output\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        loras = [\"None\"] + folder_paths.get_filename_list(\"loras\")\n\n        return {\n            \"required\": {\n                \"switch_1\": ([\"Off\", \"On\"],),\n                \"lora_name_1\": (loras,),\n                \"model_weight_1\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                \"clip_weight_1\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                \"switch_2\": ([\"Off\", \"On\"],),\n                \"lora_name_2\": (loras,),\n                \"model_weight_2\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                \"clip_weight_2\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                \"switch_3\": ([\"Off\", \"On\"],),\n                \"lora_name_3\": (loras,),\n                \"model_weight_3\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n                \"clip_weight_3\": (\"FLOAT\", {\"default\": 1.0, \"min\": -10.0, \"max\": 10.0, \"step\": 0.01}),\n            },\n            \"optional\": {\"lora_stack\": (\"LORA_STACK\",)},\n        }\n\n    RETURN_TYPES = (\"LORA_STACK\",)\n    RETURN_NAMES = (\"lora_stack\",)\n    FUNCTION = \"execute\"\n    CATEGORY = LORA_CAT\n    CLASS_NAME = \"LoraStack(OLD)\"\n    DEPRECATED = True\n\n    def execute(\n        self,\n        **kwargs,\n    ):\n        switch_1 = kwargs.get(\"switch_1\")\n        lora_name_1 = kwargs.get(\"lora_name_1\")\n        model_weight_1 = kwargs.get(\"model_weight_1\")\n        clip_weight_1 = kwargs.get(\"clip_weight_1\")\n        switch_2 = kwargs.get(\"switch_2\")\n        lora_name_2 = kwargs.get(\"lora_name_2\")\n        model_weight_2 = kwargs.get(\"model_weight_2\")\n        clip_weight_2 = kwargs.get(\"clip_weight_2\")\n        switch_3 = kwargs.get(\"switch_3\")\n        lora_name_3 = kwargs.get(\"lora_name_3\")\n        model_weight_3 = kwargs.get(\"model_weight_3\")\n        clip_weight_3 = kwargs.get(\"clip_weight_3\")\n        lora_stack = kwargs.get(\"lora_stack\")\n\n        lora_list: list = []\n        if lora_stack is not None:\n            lora_list.extend([l for l in lora_stack if l[0] != \"None\"])\n\n        if lora_name_1 != \"None\" and switch_1 == \"On\":\n            lora_list.extend([(lora_name_1, model_weight_1, clip_weight_1)]),  # type: ignore\n\n        if lora_name_2 != \"None\" and switch_2 == \"On\":\n            lora_list.extend([(lora_name_2, model_weight_2, clip_weight_2)]),  # type: ignore\n\n        if lora_name_3 != \"None\" and switch_3 == \"On\":\n            lora_list.extend([(lora_name_3, model_weight_3, clip_weight_3)]),  # type: ignore\n\n        return (lora_list,)\n</code></pre>"},{"location":"nodes/lora/#dict2lorastack","title":"Dict2LoraStack","text":"<p>Converts a list of LoRA configuration dictionaries into a LORA_STACK format.</p> <p>Transforms a list of dictionaries containing LoRA configurations into the tuple format required for LORA_STACK operations. Can optionally extend an existing stack.</p>"},{"location":"nodes/lora/#returns_3","title":"Returns","text":"Name Type lora_stack <code>LORA_STACK</code> Source code in lora.py <pre><code>class Dict2LoraStack:\n    \"\"\"Converts a list of LoRA configuration dictionaries into a LORA_STACK format.\n\n    Transforms a list of dictionaries containing LoRA configurations into the tuple format required\n    for LORA_STACK operations. Can optionally extend an existing stack.\n\n    Args:\n        lora_dicts (LIST): List of dictionaries, each containing:\n            - lora_name (str): Name of the LoRA model\n            - lora_weight (float): Weight to apply to both model and CLIP\n        lora_stack (LORA_STACK, optional): Existing stack to extend\n\n    Returns:\n        tuple:\n            - LORA_STACK: List of tuples (lora_name, model_weight, clip_weight)\n\n    Raises:\n        ValueError: If lora_dicts is not a list\n\n    Notes:\n        - Uses same weight for both model and CLIP components\n        - Filters out any \"None\" entries when extending existing stack\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        inputs = {\n            \"required\": {\n                \"lora_dicts\": (\"LIST\",),\n            },\n            \"optional\": {\"lora_stack\": (\"LORA_STACK\",)},\n        }\n\n        inputs[\"optional\"] = {\"lora_stack\": (\"LORA_STACK\",)}\n        return inputs\n\n    RETURN_TYPES = (\"LORA_STACK\",)\n    RETURN_NAMES = (\"lora_stack\",)\n    FUNCTION = \"execute\"\n    CATEGORY = LORA_CAT\n    CLASS_ID = \"dict_to_lora_stack\"\n\n    def execute(self, **kwargs):\n        lora_dicts = kwargs.get(\"lora_dicts\")\n        if not isinstance(lora_dicts, list):\n            raise ValueError(\"Lora dicts must be a list\")\n        lora_stack = kwargs.get(\"lora_stack\")\n        loras = [None for _ in lora_dicts]\n\n        for idx, lora_dict in enumerate(lora_dicts):\n            loras[idx] = (lora_dict[\"lora_name\"], lora_dict[\"lora_weight\"], lora_dict[\"lora_weight\"])  # type: ignore\n\n        # If lora_stack is not None, extend the loras list with lora_stack\n        if lora_stack is not None:\n            loras.extend([l for l in lora_stack if l[0] != \"None\"])\n\n        return (loras,)\n</code></pre>"},{"location":"nodes/lora/#saveloracaptions","title":"SaveLoraCaptions","text":"<p>Saves images and captions in a format suitable for LoRA training.</p> <p>Creates a structured dataset directory containing images and their corresponding caption files, with support for multiple captions and optional text modifications.</p>"},{"location":"nodes/lora/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required dataset_name <code>STRING</code> required repeats <code>INT</code> 5 min=1 required images <code>IMAGE</code> required labels <code>STRING</code> forceInput=True optional prefix <code>STRING</code> optional suffix <code>STRING</code>"},{"location":"nodes/lora/#returns_4","title":"Returns","text":"Name Type string <code>STRING</code> Source code in lora.py <pre><code>class SaveLoraCaptions:\n    \"\"\"Saves images and captions in a format suitable for LoRA training.\n\n    Creates a structured dataset directory containing images and their corresponding caption files,\n    with support for multiple captions and optional text modifications.\n\n    Args:\n        dataset_name (str): Name for the dataset folder\n        repeats (int): Number of times to repeat the dataset (min: 1)\n        images (IMAGE): Tensor containing the images to save\n        labels (str): Caption text, multiple captions separated by newlines\n        prefix (str, optional): Text to add before each caption\n        suffix (str, optional): Text to add after each caption\n\n    Returns:\n        tuple:\n            - str: Path to the created dataset folder\n\n    Raises:\n        ValueError: If any input parameters are of incorrect type\n\n    Notes:\n        - Creates folder structure: comfy/loras_datasets/dataset_name_uuid/repeats_dataset_name/\n        - Saves images as PNG files with corresponding .txt caption files\n        - Supports multiple captions via newline separation\n        - Includes UUID in folder name for uniqueness\n        - Creates parent directories if they don't exist\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"dataset_name\": (\"STRING\", {\"default\": \"\"}),\n                \"repeats\": (\"INT\", {\"default\": 5, \"min\": 1}),\n                \"images\": (\"IMAGE\",),\n                \"labels\": (\"STRING\", {\"forceInput\": True}),\n            },\n            \"optional\": {\n                \"prefix\": (\"STRING\", {\"default\": \"\"}),\n                \"suffix\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"folder_path\",)\n    OUTPUT_NODE = True\n    FUNCTION = \"execute\"\n    CATEGORY = LORA_CAT\n\n    def execute(\n        self,\n        **kwargs,\n    ):\n        dataset_name = kwargs.get(\"dataset_name\")\n        if not isinstance(dataset_name, str):\n            raise ValueError(\"Dataset name must be a string\")\n        repeats = kwargs.get(\"repeats\")\n        if not isinstance(repeats, int):\n            raise ValueError(\"Repeats must be an integer\")\n        images = kwargs.get(\"images\")\n        if not isinstance(images, torch.Tensor):\n            raise ValueError(\"Images must be a torch.Tensor\")\n        labels = kwargs.get(\"labels\")\n        if not isinstance(labels, str):\n            raise ValueError(\"Labels must be a string\")\n        prefix = kwargs.get(\"prefix\")\n        if not isinstance(prefix, str):\n            raise ValueError(\"Prefix must be a string\")\n        suffix = kwargs.get(\"suffix\")\n        if not isinstance(suffix, str):\n            raise ValueError(\"Suffix must be a string\")\n\n        labels_list = labels.split(\"\\n\") if \"\\n\" in labels else [labels]\n\n        root_folder = os.path.join(BASE_COMFY_DIR, \"loras_datasets\")\n        if not os.path.exists(root_folder):\n            os.mkdir(root_folder)\n\n        uuid = uuid7str()\n        dataset_folder = os.path.join(root_folder, f\"{dataset_name}_{uuid}\")\n        if not os.path.exists(dataset_folder):\n            os.mkdir(dataset_folder)\n        images_folder = os.path.join(dataset_folder, f\"{repeats}_{dataset_name}\")\n        if not os.path.exists(images_folder):\n            os.mkdir(images_folder)\n\n        tensor_images = TensorImage.from_BWHC(images)\n        for i, img in enumerate(tensor_images):\n            # timestamp to be added to the image name\n\n            TensorImage(img).save(os.path.join(images_folder, f\"{dataset_name}_{i}.png\"))\n            # write txt label with the same name of the image\n            with open(os.path.join(images_folder, f\"{dataset_name}_{i}.txt\"), \"w\") as f:\n                label = prefix + labels_list[i % len(labels_list)] + suffix\n                f.write(label)\n\n        return (dataset_folder,)\n</code></pre>"},{"location":"nodes/mask/","title":"Mask Nodes","text":""},{"location":"nodes/mask/#basemask","title":"BaseMask","text":"<p>Creates a basic binary mask with specified dimensions.</p> <p>A utility class that generates a simple binary mask (black or white) with user-defined dimensions. The mask is returned in BWHC (Batch, Width, Height, Channel) format.</p>"},{"location":"nodes/mask/#inputs","title":"Inputs","text":"Group Name Type Default Extras required color <code>LIST</code> required width <code>INT</code> 1024 min=1, step=1 required height <code>INT</code> 1024 min=1, step=1"},{"location":"nodes/mask/#returns","title":"Returns","text":"Name Type mask <code>MASK</code> Source code in mask.py <pre><code>class BaseMask:\n    \"\"\"Creates a basic binary mask with specified dimensions.\n\n    A utility class that generates a simple binary mask (black or white) with user-defined dimensions.\n    The mask is returned in BWHC (Batch, Width, Height, Channel) format.\n\n    Args:\n        color (str): The mask color. Options:\n            - \"white\": Creates a mask filled with ones\n            - \"black\": Creates a mask filled with zeros\n        width (int): Width of the output mask in pixels. Default: 1024\n        height (int): Height of the output mask in pixels. Default: 1024\n\n    Returns:\n        tuple[torch.Tensor]: A single-element tuple containing the binary mask tensor in BWHC format\n\n    Raises:\n        None\n\n    Notes:\n        - The output mask will have dimensions (1, 1, height, width) before BWHC conversion\n        - All values in the mask are either 0 (black) or 1 (white)\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"color\": ([\"white\", \"black\"],),\n                \"width\": (\"INT\", {\"default\": 1024, \"min\": 1, \"max\": MAX_INT, \"step\": 1}),\n                \"height\": (\"INT\", {\"default\": 1024, \"min\": 1, \"max\": MAX_INT, \"step\": 1}),\n            }\n        }\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, **kwargs):\n        color = kwargs.get(\"color\") or \"white\"\n        width = kwargs.get(\"width\") or 1024\n        height = kwargs.get(\"height\") or 1024\n        if color == \"white\":\n            mask = torch.ones(1, 1, height, width)\n        else:\n            mask = torch.zeros(1, 1, height, width)\n        mask = TensorImage(mask).get_BWHC()\n        return (mask,)\n</code></pre>"},{"location":"nodes/mask/#maskmorphology","title":"MaskMorphology","text":"<p>Applies morphological operations to transform mask shapes and boundaries.</p> <p>Provides various morphological operations to modify mask shapes through kernel-based transformations. Supports multiple iterations for stronger effects.</p>"},{"location":"nodes/mask/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required mask <code>MASK</code> required operation <code>LIST</code> required kernel_size <code>INT</code> 1 min=1, step=2 required iterations <code>INT</code> 5 min=1, step=1"},{"location":"nodes/mask/#returns_1","title":"Returns","text":"Name Type mask <code>MASK</code> Source code in mask.py <pre><code>class MaskMorphology:\n    \"\"\"Applies morphological operations to transform mask shapes and boundaries.\n\n    Provides various morphological operations to modify mask shapes through kernel-based transformations.\n    Supports multiple iterations for stronger effects.\n\n    Args:\n        mask (torch.Tensor): Input mask tensor in BWHC format\n        operation (str): Morphological operation to apply. Options:\n            - \"dilation\": Expands mask regions\n            - \"erosion\": Shrinks mask regions\n            - \"opening\": Erosion followed by dilation\n            - \"closing\": Dilation followed by erosion\n            - \"gradient\": Difference between dilation and erosion\n            - \"top_hat\": Difference between input and opening\n            - \"bottom_hat\": Difference between closing and input\n        kernel_size (int): Size of the morphological kernel. Default: 1\n        iterations (int): Number of times to apply the operation. Default: 5\n\n    Returns:\n        tuple[torch.Tensor]: A single-element tuple containing the processed mask in BWHC format\n\n    Raises:\n        ValueError: If mask is not a valid torch.Tensor or if operation is invalid\n\n    Notes:\n        - Larger kernel sizes and more iterations result in stronger morphological effects\n        - Operations are performed using the TensorImage wrapper class for format consistency\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"mask\": (\"MASK\",),\n                \"operation\": (\n                    [\n                        \"dilation\",\n                        \"erosion\",\n                        \"opening\",\n                        \"closing\",\n                        \"gradient\",\n                        \"top_hat\",\n                        \"bottom_hat\",\n                    ],\n                ),\n                \"kernel_size\": (\n                    \"INT\",\n                    {\"default\": 1, \"min\": 1, \"max\": MAX_INT, \"step\": 2},\n                ),\n                \"iterations\": (\n                    \"INT\",\n                    {\"default\": 5, \"min\": 1, \"max\": MAX_INT, \"step\": 1},\n                ),\n            }\n        }\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, **kwargs):\n        mask = kwargs.get(\"mask\")\n        if not isinstance(mask, torch.Tensor):\n            raise ValueError(\"Mask must be a tensor\")\n        kernel = kwargs.get(\"kernel_size\")\n        iterations = kwargs.get(\"iterations\")\n        operation = kwargs.get(\"operation\")\n        step = TensorImage.from_BWHC(mask)\n\n        if operation == \"dilation\":\n            output = dilation(image=step, kernel_size=kernel, iterations=iterations)\n        elif operation == \"erosion\":\n            output = erosion(image=step, kernel_size=kernel, iterations=iterations)\n        elif operation == \"opening\":\n            output = opening(image=step, kernel_size=kernel, iterations=iterations)\n        elif operation == \"closing\":\n            output = closing(image=step, kernel_size=kernel, iterations=iterations)\n        elif operation == \"gradient\":\n            output = gradient(image=step, kernel_size=kernel, iterations=iterations)\n        elif operation == \"top_hat\":\n            output = top_hat(image=step, kernel_size=kernel, iterations=iterations)\n        elif operation == \"bottom_hat\":\n            output = bottom_hat(image=step, kernel_size=kernel, iterations=iterations)\n        else:\n            raise ValueError(\"Invalid operation\")\n        return (output.get_BWHC(),)\n</code></pre>"},{"location":"nodes/mask/#maskbitwise","title":"MaskBitwise","text":"<p>Performs bitwise logical operations between two binary masks.</p> <p>Converts masks to 8-bit format and applies various bitwise operations, useful for combining or comparing mask regions.</p>"},{"location":"nodes/mask/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required mask_1 <code>MASK</code> required mask_2 <code>MASK</code> required mode <code>LIST</code>"},{"location":"nodes/mask/#returns_2","title":"Returns","text":"Name Type mask <code>MASK</code> Source code in mask.py <pre><code>class MaskBitwise:\n    \"\"\"Performs bitwise logical operations between two binary masks.\n\n    Converts masks to 8-bit format and applies various bitwise operations, useful for combining\n    or comparing mask regions.\n\n    Args:\n        mask_1 (torch.Tensor): First input mask in BWHC format\n        mask_2 (torch.Tensor): Second input mask in BWHC format\n        mode (str): Bitwise operation to apply. Options:\n            - \"and\": Intersection of masks\n            - \"or\": Union of masks\n            - \"xor\": Exclusive OR of masks\n            - \"left_shift\": Left bit shift using mask_2 as shift amount\n            - \"right_shift\": Right bit shift using mask_2 as shift amount\n\n    Returns:\n        tuple[torch.Tensor]: A single-element tuple containing the resulting mask in BWHC format\n\n    Raises:\n        ValueError: If mode is not one of the supported operations\n\n    Notes:\n        - Masks are converted to 8-bit (0-255) before operations and back to float (0-1) after\n        - Shift operations use the second mask values as the number of bits to shift\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"mask_1\": (\"MASK\",),\n                \"mask_2\": (\"MASK\",),\n                \"mode\": ([\"and\", \"or\", \"xor\", \"left_shift\", \"right_shift\"],),\n            },\n        }\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, mask_1: torch.Tensor, mask_2: torch.Tensor, mode: str):\n        input_mask_1 = TensorImage.from_BWHC(mask_1)\n        input_mask_2 = TensorImage.from_BWHC(mask_2)\n        eight_bit_mask_1 = torch.tensor(input_mask_1 * 255, dtype=torch.uint8)\n        eight_bit_mask_2 = torch.tensor(input_mask_2 * 255, dtype=torch.uint8)\n\n        if mode == \"and\":\n            result = torch.bitwise_and(eight_bit_mask_1, eight_bit_mask_2)\n        elif mode == \"or\":\n            result = torch.bitwise_or(eight_bit_mask_1, eight_bit_mask_2)\n        elif mode == \"xor\":\n            result = torch.bitwise_xor(eight_bit_mask_1, eight_bit_mask_2)\n        elif mode == \"left_shift\":\n            result = torch.bitwise_left_shift(eight_bit_mask_1, eight_bit_mask_2)\n        elif mode == \"right_shift\":\n            result = torch.bitwise_right_shift(eight_bit_mask_1, eight_bit_mask_2)\n        else:\n            raise ValueError(\"Invalid mode\")\n\n        float_result = result.float() / 255\n        output_mask = TensorImage(float_result).get_BWHC()\n        return (output_mask,)\n</code></pre>"},{"location":"nodes/mask/#maskdistance","title":"MaskDistance","text":"<p>Calculates the Euclidean distance between two binary masks.</p> <p>Computes the average pixel-wise Euclidean distance between two masks, useful for comparing mask similarity or differences.</p>"},{"location":"nodes/mask/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required mask_0 <code>MASK</code> required mask_1 <code>MASK</code>"},{"location":"nodes/mask/#returns_3","title":"Returns","text":"Name Type float <code>FLOAT</code> Source code in mask.py <pre><code>class MaskDistance:\n    \"\"\"Calculates the Euclidean distance between two binary masks.\n\n    Computes the average pixel-wise Euclidean distance between two masks, useful for comparing\n    mask similarity or differences.\n\n    Args:\n        mask_0 (torch.Tensor): First input mask in BWHC format\n        mask_1 (torch.Tensor): Second input mask in BWHC format\n\n    Returns:\n        tuple[float]: A single-element tuple containing the computed distance value\n\n    Raises:\n        ValueError: If either mask_0 or mask_1 is not a valid torch.Tensor\n\n    Notes:\n        - Distance is calculated as the root mean square difference between mask pixels\n        - Output is normalized and returned as a single float value\n        - Smaller values indicate more similar masks\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\"required\": {\"mask_0\": (\"MASK\",), \"mask_1\": (\"MASK\",)}}\n\n    RETURN_TYPES = (\"FLOAT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, **kwargs):\n        mask_0 = kwargs.get(\"mask_0\")\n        mask_1 = kwargs.get(\"mask_1\")\n        if not isinstance(mask_0, torch.Tensor) or not isinstance(mask_1, torch.Tensor):\n            raise ValueError(\"Mask must be a tensor\")\n        tensor1 = TensorImage.from_BWHC(mask_0)\n        tensor2 = TensorImage.from_BWHC(mask_1)\n        dist = torch.Tensor((tensor1 - tensor2).pow(2).sum(3).sqrt().mean())\n        return (dist,)\n</code></pre>"},{"location":"nodes/mask/#mask2trimap","title":"Mask2Trimap","text":"<p>Converts a binary mask into a trimap representation with three distinct regions.</p> <p>Creates a trimap by identifying definite foreground, definite background, and uncertain regions using threshold values and morphological operations.</p>"},{"location":"nodes/mask/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required mask <code>MASK</code> required inner_min_threshold <code>INT</code> 200 min=0, max=255 required inner_max_threshold <code>INT</code> 255 min=0, max=255 required outer_min_threshold <code>INT</code> 15 min=0, max=255 required outer_max_threshold <code>INT</code> 240 min=0, max=255 required kernel_size <code>INT</code> 10 min=1, max=100"},{"location":"nodes/mask/#returns_4","title":"Returns","text":"Name Type mask <code>MASK</code> trimap <code>TRIMAP</code> Source code in mask.py <pre><code>class Mask2Trimap:\n    \"\"\"Converts a binary mask into a trimap representation with three distinct regions.\n\n    Creates a trimap by identifying definite foreground, definite background, and uncertain regions\n    using threshold values and morphological operations.\n\n    Args:\n        mask (torch.Tensor): Input binary mask in BWHC format\n        inner_min_threshold (int): Minimum threshold for inner/foreground region. Default: 200\n        inner_max_threshold (int): Maximum threshold for inner/foreground region. Default: 255\n        outer_min_threshold (int): Minimum threshold for outer/background region. Default: 15\n        outer_max_threshold (int): Maximum threshold for outer/background region. Default: 240\n        kernel_size (int): Size of morphological kernel for region processing. Default: 10\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor]: Tuple containing:\n            - Processed mask in BWHC format\n            - Trimap tensor with foreground, background, and uncertain regions\n\n    Raises:\n        ValueError: If mask is not a valid torch.Tensor\n\n    Notes:\n        - Output trimap has values: 0 (background), 0.5 (uncertain), 1 (foreground)\n        - Kernel size affects the smoothness of region boundaries\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"mask\": (\"MASK\",),\n                \"inner_min_threshold\": (\"INT\", {\"default\": 200, \"min\": 0, \"max\": 255}),\n                \"inner_max_threshold\": (\"INT\", {\"default\": 255, \"min\": 0, \"max\": 255}),\n                \"outer_min_threshold\": (\"INT\", {\"default\": 15, \"min\": 0, \"max\": 255}),\n                \"outer_max_threshold\": (\"INT\", {\"default\": 240, \"min\": 0, \"max\": 255}),\n                \"kernel_size\": (\"INT\", {\"default\": 10, \"min\": 1, \"max\": 100}),\n            }\n        }\n\n    RETURN_TYPES = (\"MASK\", \"TRIMAP\")\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n    CLASS_ID = \"mask_trimap\"\n\n    def execute(self, **kwargs):\n        mask = kwargs.get(\"mask\")\n        inner_min_threshold = kwargs.get(\"inner_min_threshold\") or 200\n        inner_max_threshold = kwargs.get(\"inner_max_threshold\") or 255\n        outer_min_threshold = kwargs.get(\"outer_min_threshold\") or 15\n        outer_max_threshold = kwargs.get(\"outer_max_threshold\") or 240\n        kernel_size = kwargs.get(\"kernel_size\")\n\n        if not isinstance(mask, torch.Tensor):\n            raise ValueError(\"Mask must be a tensor\")\n\n        step = TensorImage.from_BWHC(mask)\n        inner_mask = TensorImage(step.clone())\n        inner_mask[inner_mask &gt; (inner_max_threshold / 255.0)] = 1.0\n        inner_mask[inner_mask &lt;= (inner_min_threshold / 255.0)] = 0.0\n\n        step = TensorImage.from_BWHC(mask)\n        inner_mask = erosion(image=inner_mask, kernel_size=kernel_size, iterations=1)\n\n        inner_mask[inner_mask != 0.0] = 1.0\n\n        outter_mask = step.clone()\n        outter_mask[outter_mask &gt; (outer_max_threshold / 255.0)] = 1.0\n        outter_mask[outter_mask &lt;= (outer_min_threshold / 255.0)] = 0.0\n        outter_mask = dilation(image=inner_mask, kernel_size=kernel_size, iterations=5)\n\n        outter_mask[outter_mask != 0.0] = 1.0\n\n        trimap_im = torch.zeros_like(step)\n        trimap_im[outter_mask == 1.0] = 0.5\n        trimap_im[inner_mask == 1.0] = 1.0\n        batch_size = step.shape[0]\n\n        trimap = torch.zeros(\n            batch_size, 2, step.shape[2], step.shape[3], dtype=step.dtype, device=step.device\n        )\n        for i in range(batch_size):\n            tar_trimap = trimap_im[i][0]\n            trimap[i][1][tar_trimap == 1] = 1\n            trimap[i][0][tar_trimap == 0] = 1\n\n        output_0 = TensorImage(trimap_im).get_BWHC()\n        output_1 = trimap.permute(0, 2, 3, 1)\n\n        return (\n            output_0,\n            output_1,\n        )\n</code></pre>"},{"location":"nodes/mask/#maskbinaryfilter","title":"MaskBinaryFilter","text":"<p>Applies binary thresholding to convert a grayscale mask into a binary mask.</p> <p>Converts all values above threshold to 1 and below threshold to 0, creating a strict binary mask.</p>"},{"location":"nodes/mask/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required mask <code>MASK</code> required threshold <code>FLOAT</code> 0.01 min=0.0, max=1.0, step=0.01"},{"location":"nodes/mask/#returns_5","title":"Returns","text":"Name Type mask <code>MASK</code> Source code in mask.py <pre><code>class MaskBinaryFilter:\n    \"\"\"Applies binary thresholding to convert a grayscale mask into a binary mask.\n\n    Converts all values above threshold to 1 and below threshold to 0, creating a strict\n    binary mask.\n\n    Args:\n        mask (torch.Tensor): Input mask in BWHC format\n        threshold (float): Threshold value for binary conversion. Default: 0.01\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing the binary mask\n\n    Raises:\n        ValueError: If mask is not a valid torch.Tensor\n\n    Notes:\n        - Values &gt; threshold become 1.0\n        - Values \u2264 threshold become 0.0\n        - Useful for cleaning up masks with intermediate values\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"mask\": (\"MASK\",),\n                \"threshold\": (\"FLOAT\", {\"default\": 0.01, \"min\": 0.00, \"max\": 1.00, \"step\": 0.01}),\n            }\n        }\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, mask: torch.Tensor, threshold: float):\n        step = TensorImage.from_BWHC(mask)\n        step[step &gt; threshold] = 1.0\n        step[step &lt;= threshold] = 0.0\n        output = TensorImage(step).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/mask/#maskinvert","title":"MaskInvert","text":"<p>Inverts a binary mask by flipping all values.</p> <p>Creates a negative version of the input mask where white becomes black and vice versa.</p>"},{"location":"nodes/mask/#inputs_6","title":"Inputs","text":"Group Name Type Default Extras required mask <code>MASK</code>"},{"location":"nodes/mask/#returns_6","title":"Returns","text":"Name Type mask <code>MASK</code> Source code in mask.py <pre><code>class MaskInvert:\n    \"\"\"Inverts a binary mask by flipping all values.\n\n    Creates a negative version of the input mask where white becomes black and vice versa.\n\n    Args:\n        mask (torch.Tensor): Input mask in BWHC format\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing the inverted mask\n\n    Raises:\n        ValueError: If mask is not a valid torch.Tensor\n\n    Notes:\n        - Each pixel value is subtracted from 1.0\n        - Useful for creating negative space masks\n        - Preserves the mask's dimensions and format\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"mask\": (\"MASK\",),\n            }\n        }\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, mask: torch.Tensor):\n        step = TensorImage.from_BWHC(mask)\n        step = 1.0 - step\n        output = TensorImage(step).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/mask/#maskgaussianblur","title":"MaskGaussianBlur","text":"<p>Applies Gaussian blur to soften mask edges and create smooth transitions.</p> <p>Implements a configurable Gaussian blur with control over blur radius, strength, and iterations.</p>"},{"location":"nodes/mask/#inputs_7","title":"Inputs","text":"Group Name Type Default Extras required image <code>MASK</code> required radius <code>INT</code> 13 required sigma <code>FLOAT</code> 10.5 required interations <code>INT</code> 1 required only_outline <code>BOOLEAN</code> False"},{"location":"nodes/mask/#returns_7","title":"Returns","text":"Name Type mask <code>MASK</code> Source code in mask.py <pre><code>class MaskGaussianBlur:\n    \"\"\"Applies Gaussian blur to soften mask edges and create smooth transitions.\n\n    Implements a configurable Gaussian blur with control over blur radius, strength, and iterations.\n\n    Args:\n        image (torch.Tensor): Input mask in BWHC format\n        radius (int): Blur kernel radius. Default: 13\n        sigma (float): Blur strength/standard deviation. Default: 10.5\n        iterations (int): Number of blur passes to apply. Default: 1\n        only_outline (bool): Whether to blur only the mask edges. Default: False\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing the blurred mask\n\n    Raises:\n        ValueError: If image is not a valid torch.Tensor\n\n    Notes:\n        - Larger radius values create wider blur effects\n        - Multiple iterations can create stronger blur effects\n        - Sigma controls the falloff of the blur effect\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"MASK\",),\n                \"radius\": (\"INT\", {\"default\": 13}),\n                \"sigma\": (\"FLOAT\", {\"default\": 10.5}),\n                \"interations\": (\"INT\", {\"default\": 1}),\n                \"only_outline\": (\"BOOLEAN\", {\"default\": False}),\n            }\n        }\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, image: torch.Tensor, radius, sigma, interations):\n        tensor_image = TensorImage.from_BWHC(image)\n        output = gaussian_blur2d(tensor_image, radius, sigma, interations).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/mask/#maskgrowwithblur","title":"MaskGrowWithBlur","text":"<p>Expands or contracts a mask with controllable blur and tapering effects.</p> <p>Provides fine control over mask growth with options for smooth transitions and edge effects.</p>"},{"location":"nodes/mask/#inputs_8","title":"Inputs","text":"Group Name Type Default Extras required mask <code>MASK</code> required expand <code>INT</code> 0 step=1 required incremental_expandrate <code>FLOAT</code> 0.0 min=0.0, max=100.0, step=0.1 required tapered_corners <code>BOOLEAN</code> True required flip_input <code>BOOLEAN</code> False required blur_radius <code>FLOAT</code> 0.0 min=0.0, max=100, step=0.1 required lerp_alpha <code>FLOAT</code> 1.0 min=0.0, max=1.0, step=0.01 required decay_factor <code>FLOAT</code> 1.0 min=0.0, max=1.0, step=0.01"},{"location":"nodes/mask/#returns_8","title":"Returns","text":"Name Type mask <code>MASK</code> Source code in mask.py <pre><code>class MaskGrowWithBlur:\n    \"\"\"Expands or contracts a mask with controllable blur and tapering effects.\n\n    Provides fine control over mask growth with options for smooth transitions and edge effects.\n\n    Args:\n        mask (torch.Tensor): Input mask in BWHC format\n        expand (int): Pixels to grow (positive) or shrink (negative). Default: 0\n        incremental_expandrate (float): Growth rate per iteration. Default: 0.0\n        tapered_corners (bool): Enable corner softening. Default: True\n        flip_input (bool): Invert input before processing. Default: False\n        blur_radius (float): Final blur amount. Default: 0.0\n        lerp_alpha (float): Blend factor for transitions. Default: 1.0\n        decay_factor (float): Growth decay rate. Default: 1.0\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing the processed mask\n\n    Raises:\n        ValueError: If inputs are invalid types or values\n\n    Notes:\n        - Positive expand values grow the mask, negative values shrink it\n        - Decay factor controls how growth diminishes over iterations\n        - Blur radius affects the final edge smoothness\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"mask\": (\"MASK\",),\n                \"expand\": (\n                    \"INT\",\n                    {\n                        \"default\": 0,\n                        \"min\": -MAX_INT,\n                        \"max\": MAX_INT,\n                        \"step\": 1,\n                    },\n                ),\n                \"incremental_expandrate\": (\n                    \"FLOAT\",\n                    {\"default\": 0.0, \"min\": 0.0, \"max\": 100.0, \"step\": 0.1},\n                ),\n                \"tapered_corners\": (\"BOOLEAN\", {\"default\": True}),\n                \"flip_input\": (\"BOOLEAN\", {\"default\": False}),\n                \"blur_radius\": (\n                    \"FLOAT\",\n                    {\"default\": 0.0, \"min\": 0.0, \"max\": 100, \"step\": 0.1},\n                ),\n                \"lerp_alpha\": (\n                    \"FLOAT\",\n                    {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01},\n                ),\n                \"decay_factor\": (\n                    \"FLOAT\",\n                    {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01},\n                ),\n            },\n        }\n\n    CATEGORY = MASK_CAT\n    RETURN_TYPES = (\"MASK\",)\n    RETURN_NAMES = (\"mask\",)\n    FUNCTION = \"expand_mask\"\n\n    def expand_mask(self, **kwargs):\n        mask = kwargs.get(\"mask\")\n        if not isinstance(mask, torch.Tensor):\n            raise ValueError(\"Mask must be a tensor\")\n        expand = kwargs.get(\"expand\")\n        if not isinstance(expand, int):\n            raise ValueError(\"Expand must be an integer\")\n        incremental_expandrate = kwargs.get(\"incremental_expandrate\")\n        if not isinstance(incremental_expandrate, float):\n            raise ValueError(\"Incremental expandrate must be a float\")\n        tapered_corners = kwargs.get(\"tapered_corners\")\n        if not isinstance(tapered_corners, bool):\n            raise ValueError(\"Tapered corners must be a boolean\")\n        flip_input = kwargs.get(\"flip_input\")\n        if not isinstance(flip_input, bool):\n            raise ValueError(\"Flip input must be a boolean\")\n        blur_radius = kwargs.get(\"blur_radius\")\n        if not isinstance(blur_radius, float):\n            raise ValueError(\"Blur radius must be a float\")\n        lerp_alpha = kwargs.get(\"lerp_alpha\")\n        if not isinstance(lerp_alpha, float):\n            raise ValueError(\"Lerp alpha must be a float\")\n        decay_factor = kwargs.get(\"decay_factor\")\n        if not isinstance(decay_factor, float):\n            raise ValueError(\"Decay factor must be a float\")\n        mask = TensorImage.from_BWHC(mask)\n        alpha = lerp_alpha\n        decay = decay_factor\n        if flip_input:\n            mask = 1.0 - mask\n        c = 0 if tapered_corners else 1\n        kernel = torch.tensor([[c, 1, c], [1, 1, 1], [c, 1, c]], dtype=torch.float32)\n        growmask = mask.reshape((-1, mask.shape[-2], mask.shape[-1])).cpu()\n        out = []\n        previous_output = None\n        current_expand = expand\n        for m in growmask:\n            m = m.unsqueeze(0).unsqueeze(0)\n            output = m.clone()\n\n            for _ in range(abs(round(current_expand))):\n                if current_expand &lt; 0:\n                    output = morphology.erosion(output, kernel)\n                else:\n                    output = morphology.dilation(output, kernel)\n            if current_expand &lt; 0:\n                current_expand -= abs(incremental_expandrate)\n            else:\n                current_expand += abs(incremental_expandrate)\n\n            output = output.squeeze(0).squeeze(0)\n\n            if alpha &lt; 1.0 and previous_output is not None:\n                output = alpha * output + (1 - alpha) * previous_output\n            if decay &lt; 1.0 and previous_output is not None:\n                output += decay * previous_output\n                output = output / output.max()\n            previous_output = output\n            out.append(output)\n\n        if blur_radius != 0:\n            kernel_size = int(4 * round(blur_radius) + 1)\n            blurred = [\n                filters.gaussian_blur2d(\n                    tensor.unsqueeze(0).unsqueeze(0), (kernel_size, kernel_size), (blur_radius, blur_radius)\n                ).squeeze(0)\n                for tensor in out\n            ]\n            blurred = torch.cat(blurred, dim=0)\n\n            return (TensorImage(blurred).get_BWHC(),)\n\n        return (TensorImage(torch.stack(out, dim=0)).get_BWHC(),)\n</code></pre>"},{"location":"nodes/mask/#getmaskshape","title":"GetMaskShape","text":"<p>Analyzes and returns the dimensional information of a mask tensor.</p> <p>Extracts and returns the shape parameters of the input mask for analysis or debugging.</p>"},{"location":"nodes/mask/#inputs_9","title":"Inputs","text":"Group Name Type Default Extras required mask <code>MASK</code>"},{"location":"nodes/mask/#returns_9","title":"Returns","text":"Name Type int <code>INT</code> int <code>INT</code> int <code>INT</code> int <code>INT</code> string <code>STRING</code> Source code in mask.py <pre><code>class GetMaskShape:\n    \"\"\"Analyzes and returns the dimensional information of a mask tensor.\n\n    Extracts and returns the shape parameters of the input mask for analysis or debugging.\n\n    Args:\n        mask (torch.Tensor): Input mask in BWHC format\n\n    Returns:\n        tuple[int, int, int, int, str]: Tuple containing:\n            - Batch size\n            - Width\n            - Height\n            - Number of channels\n            - String representation of shape\n\n    Raises:\n        ValueError: If mask is not a valid torch.Tensor\n\n    Notes:\n        - Handles both 3D and 4D tensor inputs\n        - Useful for debugging and validation\n        - Returns dimensions in a consistent order regardless of input format\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"mask\": (\"MASK\",),\n            },\n        }\n\n    RETURN_TYPES = (\"INT\", \"INT\", \"INT\", \"INT\", \"STRING\")\n    RETURN_NAMES = (\"batch\", \"width\", \"height\", \"channels\", \"debug\")\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, mask):\n        if len(mask.shape) == 3:\n            return (mask.shape[0], mask.shape[2], mask.shape[1], 1, str(mask.shape))\n        return (mask.shape[0], mask.shape[2], mask.shape[1], mask.shape[3], str(mask.shape))\n</code></pre>"},{"location":"nodes/mask/#maskpreview","title":"MaskPreview","text":"<p>Generates and saves a visual preview of a mask as an image file.</p> <p>Converts mask data to a viewable image format and saves it with optional metadata.</p>"},{"location":"nodes/mask/#inputs_10","title":"Inputs","text":"Group Name Type Default Extras required mask <code>MASK</code> Source code in mask.py <pre><code>class MaskPreview(SaveImage):\n    \"\"\"Generates and saves a visual preview of a mask as an image file.\n\n    Converts mask data to a viewable image format and saves it with optional metadata.\n\n    Args:\n        mask (torch.Tensor): Input mask in BWHC format\n        filename_prefix (str): Prefix for the output filename. Default: \"Signature\"\n        prompt (Optional[str]): Optional prompt text to include in metadata\n        extra_pnginfo (Optional[dict]): Additional PNG metadata to include\n\n    Returns:\n        tuple[str, str]: Tuple containing paths to the saved preview images\n\n    Raises:\n        ValueError: If mask is not a valid torch.Tensor\n        IOError: If unable to save the preview image\n\n    Notes:\n        - Saves to temporary directory with random suffix\n        - Converts mask to RGB/RGBA format for viewing\n        - Includes compression level 4 for storage efficiency\n    \"\"\"\n\n    def __init__(self):\n        self.output_dir = folder_paths.get_temp_directory()\n        self.type = \"temp\"\n        self.prefix_append = \"_temp_\" + \"\".join(random.choice(\"abcdefghijklmnopqrstupvxyz\") for _ in range(5))\n        self.compress_level = 4\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"mask\": (\"MASK\",),\n            },\n            \"hidden\": {\"prompt\": \"PROMPT\", \"extra_pnginfo\": \"EXTRA_PNGINFO\"},\n        }\n\n    FUNCTION = \"execute\"\n    CATEGORY = MASK_CAT\n\n    def execute(self, mask, filename_prefix=\"Signature\", prompt=None, extra_pnginfo=None):\n        preview = TensorImage.from_BWHC(mask).get_rgb_or_rgba().get_BWHC()\n        return self.save_images(preview, filename_prefix, prompt, extra_pnginfo)\n</code></pre>"},{"location":"nodes/models/","title":"Models Nodes","text":""},{"location":"nodes/models/#magiceraser","title":"MagicEraser","text":"<p>Removes unwanted content from images using the Lama inpainting model.</p> <p>This class provides functionality to erase and reconstruct image regions based on a provided mask. The Lama model intelligently fills in the masked areas with contextually appropriate content.</p>"},{"location":"nodes/models/#inputs","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required mask <code>MASK</code> required preview <code>LIST</code>"},{"location":"nodes/models/#returns","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in models.py <pre><code>class MagicEraser(SaveImage):\n    \"\"\"Removes unwanted content from images using the Lama inpainting model.\n\n    This class provides functionality to erase and reconstruct image regions based on a provided mask.\n    The Lama model intelligently fills in the masked areas with contextually appropriate content.\n\n    Args:\n        image (torch.Tensor): Input image tensor in BWHC (Batch, Width, Height, Channel) format.\n        mask (torch.Tensor): Binary mask tensor in BWHC format where 1 indicates areas to erase.\n        preview (str): Controls preview image generation. Options:\n            - \"on\": Saves preview images\n            - \"off\": No preview images\n        filename_prefix (str, optional): Prefix to use for saved output files. Defaults to \"Signature\".\n        prompt (str, optional): Text prompt for metadata. Defaults to None.\n        extra_pnginfo (dict, optional): Additional metadata to save with output images. Defaults to None.\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing the processed image in BWHC format.\n\n    Notes:\n        - The model automatically handles memory cleanup after processing\n        - Temporary files are saved with random suffixes to prevent naming conflicts\n        - Preview images are saved at compression level 4 for balance of quality and size\n    \"\"\"\n\n    def __init__(self):\n        self.output_dir = folder_paths.get_temp_directory()\n        self.type = \"temp\"\n        self.prefix_append = \"_temp_\" + \"\".join(random.choice(\"abcdefghijklmnopqrstupvxyz\") for x in range(5))\n        self.compress_level = 4\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"mask\": (\"MASK\",),\n                \"preview\": ([\"on\", \"off\"],),\n            },\n            \"hidden\": {\"prompt\": \"PROMPT\", \"extra_pnginfo\": \"EXTRA_PNGINFO\"},\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MODELS_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n\n        mask = kwargs.get(\"mask\")\n        if not isinstance(mask, torch.Tensor):\n            raise ValueError(\"Mask must be a torch.Tensor\")\n\n        preview = kwargs.get(\"preview\", \"off\")\n        if preview not in [\"on\", \"off\"]:\n            raise ValueError(\"Preview must be 'on' or 'off'\")\n\n        filename_prefix = kwargs.get(\"filename_prefix\", \"Signature\")\n        prompt = kwargs.get(\"prompt\") or \"\"\n        extra_pnginfo = kwargs.get(\"extra_pnginfo\")\n        model = Lama()\n        input_image = TensorImage.from_BWHC(image)\n        input_mask = TensorImage.from_BWHC(mask)\n        result = TensorImage(model.forward(input_image, input_mask), device=input_mask.device)\n\n        output_images = TensorImage(result * (input_mask) + input_image * (1 - input_mask)).get_BWHC()\n        if preview == \"off\":\n            return (output_images,)\n        result = self.save_images(output_images, filename_prefix, prompt, extra_pnginfo)\n        result.update({\"result\": (output_images,)})\n        del model\n        model = None\n        return result\n</code></pre>"},{"location":"nodes/models/#unblur","title":"Unblur","text":"<p>Enhances image clarity by reducing blur using the SeeMore model.</p> <p>This class implements image deblurring functionality using the SeeMore neural network model. It's effective for correcting motion blur, out-of-focus areas, and general image softness.</p>"},{"location":"nodes/models/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code> required preview <code>LIST</code>"},{"location":"nodes/models/#returns_1","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in models.py <pre><code>class Unblur(SaveImage):\n    \"\"\"Enhances image clarity by reducing blur using the SeeMore model.\n\n    This class implements image deblurring functionality using the SeeMore neural network model.\n    It's effective for correcting motion blur, out-of-focus areas, and general image softness.\n\n    Args:\n        image (torch.Tensor): Input image tensor in BWHC (Batch, Width, Height, Channel) format.\n        preview (str): Controls preview image generation. Options:\n            - \"on\": Saves preview images\n            - \"off\": No preview images\n        filename_prefix (str, optional): Prefix to use for saved output files. Defaults to \"Signature\".\n        prompt (str, optional): Text prompt for metadata. Defaults to None.\n        extra_pnginfo (dict, optional): Additional metadata to save with output images. Defaults to None.\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing the unblurred image in BWHC format.\n\n    Notes:\n        - The model automatically handles memory cleanup after processing\n        - Temporary files are saved with random suffixes to prevent naming conflicts\n        - Preview images are saved at compression level 4 for balance of quality and size\n    \"\"\"\n\n    def __init__(self):\n        self.output_dir = folder_paths.get_temp_directory()\n        self.type = \"temp\"\n        self.prefix_append = \"_temp_\" + \"\".join(random.choice(\"abcdefghijklmnopqrstupvxyz\") for x in range(5))\n        self.compress_level = 4\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"preview\": ([\"on\", \"off\"],),\n            },\n            \"hidden\": {\"prompt\": \"PROMPT\", \"extra_pnginfo\": \"EXTRA_PNGINFO\"},\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = MODELS_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n\n        preview = kwargs.get(\"preview\")\n        if preview not in [\"on\", \"off\"]:\n            raise ValueError(\"Preview must be either 'on' or 'off'\")\n\n        filename_prefix = kwargs.get(\"filename_prefix\", \"Signature\")\n        prompt = kwargs.get(\"prompt\")\n        extra_pnginfo = kwargs.get(\"extra_pnginfo\")\n        model = SeeMore()\n        input_image = TensorImage.from_BWHC(image)\n        output_image = model.forward(input_image)\n        output_images = TensorImage(output_image).get_BWHC()\n\n        if preview == \"off\":\n            return (output_images,)\n        result = self.save_images(output_images, filename_prefix, prompt, extra_pnginfo)\n        result.update({\"result\": (output_images,)})\n        del model\n        model = None\n        return result\n</code></pre>"},{"location":"nodes/models/#backgroundremoval","title":"BackgroundRemoval","text":"<p>Separates foreground subjects from image backgrounds using AI segmentation models.</p> <p>This class provides multiple AI models for background removal, offering different approaches and quality levels for various use cases. It can output both masked and RGBA versions of the results.</p>"},{"location":"nodes/models/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required model_name <code>LIST</code> required preview <code>LIST</code> required image <code>IMAGE</code>"},{"location":"nodes/models/#returns_2","title":"Returns","text":"Name Type image <code>IMAGE</code> image <code>IMAGE</code> mask <code>MASK</code> Source code in models.py <pre><code>class BackgroundRemoval(SaveImage):\n    \"\"\"Separates foreground subjects from image backgrounds using AI segmentation models.\n\n    This class provides multiple AI models for background removal, offering different approaches and\n    quality levels for various use cases. It can output both masked and RGBA versions of the results.\n\n    Args:\n        image (torch.Tensor): Input image tensor in BWHC (Batch, Width, Height, Channel) format.\n        model_name (str): The AI model to use for segmentation. Options:\n            - \"inspyrenet\": General-purpose segmentation\n            - \"rmbg14\": Optimized for human subjects\n            - \"isnet_general\": Balanced approach for various subjects\n            - \"fakepng\": Fast but lower quality option\n        preview (str): Controls preview output type. Options:\n            - \"mask\": Shows the segmentation mask\n            - \"rgba\": Shows the transparent background result\n            - \"none\": No preview\n        filename_prefix (str, optional): Prefix to use for saved output files. Defaults to \"Signature\".\n        prompt (str, optional): Text prompt for metadata. Defaults to None.\n        extra_pnginfo (dict, optional): Additional metadata to save with output images. Defaults to None.\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing:\n            - rgba: Image with transparent background in BWHC format\n            - rgb: Original image with background in BWHC format\n            - mask: Binary segmentation mask in BWHC format\n\n    Notes:\n        - The model automatically handles memory cleanup after processing\n        - Temporary files are saved with random suffixes to prevent naming conflicts\n        - Preview images are saved at compression level 4 for balance of quality and size\n        - Different models may perform better on different types of images\n    \"\"\"\n\n    def __init__(self):\n        self.output_dir = folder_paths.get_temp_directory()\n        self.type = \"temp\"\n        self.prefix_append = \"_temp_\" + \"\".join(random.choice(\"abcdefghijklmnopqrstupvxyz\") for _ in range(5))\n        self.compress_level = 4\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"model_name\": ([\"inspyrenet\", \"rmbg14\", \"isnet_general\", \"fakepng\"],),\n                \"preview\": ([\"mask\", \"rgba\", \"none\"],),\n                \"image\": (\"IMAGE\",),\n            },\n            \"hidden\": {\"prompt\": \"PROMPT\", \"extra_pnginfo\": \"EXTRA_PNGINFO\"},\n        }\n\n    RETURN_TYPES = (\"IMAGE\", \"IMAGE\", \"MASK\")\n    RETURN_NAMES = (\"rgba\", \"rgb\", \"mask\")\n    FUNCTION = \"execute\"\n    CATEGORY = MODELS_CAT\n\n    def execute(self, **kwargs):\n        image = kwargs.get(\"image\")\n        if not isinstance(image, torch.Tensor):\n            raise ValueError(\"Image must be a torch.Tensor\")\n\n        model_name = kwargs.get(\"model_name\")\n        if not isinstance(model_name, str):\n            raise ValueError(\"Model name must be a string\")\n        if model_name not in [\"inspyrenet\", \"rmbg14\", \"isnet_general\", \"fakepng\"]:\n            raise ValueError(\"Invalid model name\")\n\n        preview = kwargs.get(\"preview\")\n        if not isinstance(preview, str):\n            raise ValueError(\"Preview must be a string\")\n        if preview not in [\"mask\", \"rgba\", \"none\"]:\n            raise ValueError(\"Invalid preview type\")\n\n        filename_prefix = kwargs.get(\"filename_prefix\", \"Signature\")\n        if not isinstance(filename_prefix, str):\n            raise ValueError(\"Filename prefix must be a string\")\n\n        prompt = kwargs.get(\"prompt\")\n        extra_pnginfo = kwargs.get(\"extra_pnginfo\")\n\n        model = SalientObjectDetection(model_name=model_name)\n        input_image = TensorImage.from_BWHC(image)\n        masks = model.forward(input_image)\n\n        output_masks = TensorImage(masks)\n        rgb, rgba = cutout(input_image, output_masks)\n        rgb_output = TensorImage(rgb).get_BWHC()\n        rgba_output = TensorImage(rgba).get_BWHC()\n        mask_output = output_masks.get_BWHC()\n        if preview == \"none\":\n            return (\n                rgba_output,\n                rgb_output,\n                mask_output,\n            )\n        preview_images = output_masks.get_rgb_or_rgba().get_BWHC() if preview == \"mask\" else rgba_output\n        result = self.save_images(preview_images, filename_prefix, prompt, extra_pnginfo)\n        result.update(\n            {\n                \"result\": (\n                    rgba_output,\n                    rgb_output,\n                    mask_output,\n                )\n            }\n        )\n        del model\n        model = None\n        return result\n</code></pre>"},{"location":"nodes/numbers/","title":"Numbers Nodes","text":""},{"location":"nodes/numbers/#intclamp","title":"IntClamp","text":"<p>Clamps an integer value between specified minimum and maximum bounds.</p> <p>This class provides functionality to constrain an integer input within a defined range. If the input number is less than the minimum value, it returns the minimum value. If it's greater than the maximum value, it returns the maximum value.</p>"},{"location":"nodes/numbers/#inputs","title":"Inputs","text":"Group Name Type Default Extras required number <code>INT</code> 0 forceInput=True required min_value <code>INT</code> 0 step=1 required max_value <code>INT</code> 0 step=1"},{"location":"nodes/numbers/#returns","title":"Returns","text":"Name Type int <code>INT</code> Source code in numbers.py <pre><code>class IntClamp:\n    \"\"\"Clamps an integer value between specified minimum and maximum bounds.\n\n    This class provides functionality to constrain an integer input within a defined range. If the input\n    number is less than the minimum value, it returns the minimum value. If it's greater than the\n    maximum value, it returns the maximum value.\n\n    Args:\n        number (int): The input integer to be clamped.\n        min_value (int): The minimum allowed value.\n        max_value (int): The maximum allowed value.\n\n    Returns:\n        tuple[int]: A single-element tuple containing the clamped integer value.\n\n    Raises:\n        ValueError: If any of the inputs (number, min_value, max_value) are not integers.\n\n    Notes:\n        - The input range is limited by MAX_INT constant\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"number\": (\n                    \"INT\",\n                    {\n                        \"default\": 0,\n                        \"forceInput\": True,\n                        \"min\": -MAX_INT,\n                        \"max\": MAX_INT,\n                    },\n                ),\n                \"min_value\": (\n                    \"INT\",\n                    {\"default\": 0, \"min\": -MAX_INT, \"max\": MAX_INT, \"step\": 1},\n                ),\n                \"max_value\": (\n                    \"INT\",\n                    {\"default\": 0, \"min\": -MAX_INT, \"max\": MAX_INT, \"step\": 1},\n                ),\n            }\n        }\n\n    RETURN_TYPES = (\"INT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n\n    def execute(self, **kwargs):\n        number = kwargs.get(\"number\")\n        if not isinstance(number, int):\n            raise ValueError(\"Number must be an integer\")\n        min_value = kwargs.get(\"min_value\")\n        if not isinstance(min_value, int):\n            raise ValueError(\"Min value must be an integer\")\n        max_value = kwargs.get(\"max_value\")\n        if not isinstance(max_value, int):\n            raise ValueError(\"Max value must be an integer\")\n        if number &lt; min_value:\n            return (min_value,)\n        if number &gt; max_value:\n            return (max_value,)\n        return (number,)\n</code></pre>"},{"location":"nodes/numbers/#floatclamp","title":"FloatClamp","text":"<p>Clamps a floating-point value between specified minimum and maximum bounds.</p> <p>This class provides functionality to constrain a float input within a defined range. If the input number is less than the minimum value, it returns the minimum value. If it's greater than the maximum value, it returns the maximum value.</p>"},{"location":"nodes/numbers/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required number <code>FLOAT</code> 0 forceInput=True required min_value <code>FLOAT</code> 0 step=0.01 required max_value <code>FLOAT</code> 0 step=0.01"},{"location":"nodes/numbers/#returns_1","title":"Returns","text":"Name Type float <code>FLOAT</code> Source code in numbers.py <pre><code>class FloatClamp:\n    \"\"\"Clamps a floating-point value between specified minimum and maximum bounds.\n\n    This class provides functionality to constrain a float input within a defined range. If the input\n    number is less than the minimum value, it returns the minimum value. If it's greater than the\n    maximum value, it returns the maximum value.\n\n    Args:\n        number (float): The input float to be clamped.\n        min_value (float): The minimum allowed value.\n        max_value (float): The maximum allowed value.\n\n    Returns:\n        tuple[float]: A single-element tuple containing the clamped float value.\n\n    Raises:\n        ValueError: If any of the inputs (number, min_value, max_value) are not floats.\n\n    Notes:\n        - The input range is limited by MAX_FLOAT constant\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"number\": (\n                    \"FLOAT\",\n                    {\n                        \"default\": 0,\n                        \"forceInput\": True,\n                        \"min\": -MAX_FLOAT,\n                        \"max\": MAX_FLOAT,\n                    },\n                ),\n                \"min_value\": (\n                    \"FLOAT\",\n                    {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01},\n                ),\n                \"max_value\": (\n                    \"FLOAT\",\n                    {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01},\n                ),\n            }\n        }\n\n    RETURN_TYPES = (\"FLOAT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n\n    def execute(self, **kwargs):\n        number = kwargs.get(\"number\")\n        if not isinstance(number, float) and not isinstance(number, int):\n            raise ValueError(\"Number must be a float\")\n        min_value = kwargs.get(\"min_value\")\n        if not isinstance(min_value, float) and not isinstance(min_value, int):\n            raise ValueError(\"Min value must be a float\")\n        max_value = float(kwargs.get(\"max_value\") or 0.0)\n        if not isinstance(max_value, float) and not isinstance(max_value, int):\n            raise ValueError(\"Max value must be a float\")\n\n        if number &lt; min_value:\n            return (min_value,)\n        if number &gt; max_value:\n            return (max_value,)\n        return (number,)\n</code></pre>"},{"location":"nodes/numbers/#float2int","title":"Float2Int","text":"<p>Converts a floating-point number to an integer through truncation.</p> <p>This class handles the conversion of float values to integers by removing the decimal portion. The conversion is performed using Python's built-in int() function, which truncates towards zero.</p>"},{"location":"nodes/numbers/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required number <code>FLOAT</code> 0 forceInput=True"},{"location":"nodes/numbers/#returns_2","title":"Returns","text":"Name Type int <code>INT</code> Source code in numbers.py <pre><code>class Float2Int:\n    \"\"\"Converts a floating-point number to an integer through truncation.\n\n    This class handles the conversion of float values to integers by removing the decimal portion.\n    The conversion is performed using Python's built-in int() function, which truncates towards zero.\n\n    Args:\n        number (float): The floating-point number to convert to an integer.\n\n    Returns:\n        tuple[int]: A single-element tuple containing the converted integer value.\n\n    Raises:\n        ValueError: If the input value is not a float.\n\n    Notes:\n        - Decimal portions are truncated, not rounded\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"number\": (\"FLOAT\", {\"default\": 0, \"forceInput\": True}),\n            }\n        }\n\n    RETURN_TYPES = (\"INT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n    CLASS_ID = \"float2int\"\n\n    def execute(self, **kwargs):\n        try:\n            number = float(kwargs.get(\"number\", 0.0))\n            return (int(number),)\n        except (TypeError, ValueError):\n            raise ValueError(\"Number must be convertible to float\")\n</code></pre>"},{"location":"nodes/numbers/#int2float","title":"Int2Float","text":"<p>Converts an integer to a floating-point number.</p> <p>This class handles the conversion of integer values to floating-point numbers using Python's built-in float() function.</p>"},{"location":"nodes/numbers/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required number <code>INT</code> 0 forceInput=True"},{"location":"nodes/numbers/#returns_3","title":"Returns","text":"Name Type float <code>FLOAT</code> Source code in numbers.py <pre><code>class Int2Float:\n    \"\"\"Converts an integer to a floating-point number.\n\n    This class handles the conversion of integer values to floating-point numbers using Python's\n    built-in float() function.\n\n    Args:\n        number (int): The integer to convert to a float.\n\n    Returns:\n        tuple[float]: A single-element tuple containing the converted float value.\n\n    Raises:\n        ValueError: If the input value is not an integer.\n\n    Notes:\n        - The conversion is exact as all integers can be represented precisely as floats\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"number\": (\"INT\", {\"default\": 0, \"forceInput\": True}),\n            }\n        }\n\n    RETURN_TYPES = (\"FLOAT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n    CLASS_ID = \"int2float\"\n\n    def execute(self, **kwargs):\n        try:\n            number = int(kwargs.get(\"number\", 0))\n            return (float(number),)\n        except (TypeError, ValueError):\n            raise ValueError(\"Number must be convertible to integer\")\n</code></pre>"},{"location":"nodes/numbers/#intoperator","title":"IntOperator","text":"<p>Performs arithmetic operations on two floats and returns an integer result.</p> <p>This class supports basic arithmetic operations between two floating-point numbers and returns the result as an integer. The supported operations are addition, subtraction, multiplication, and division.</p>"},{"location":"nodes/numbers/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required left <code>FLOAT</code> 0 step=0.01 required right <code>FLOAT</code> 0 step=0.01 required operator <code>LIST</code>"},{"location":"nodes/numbers/#returns_4","title":"Returns","text":"Name Type int <code>INT</code> Source code in numbers.py <pre><code>class IntOperator:\n    \"\"\"Performs arithmetic operations on two floats and returns an integer result.\n\n    This class supports basic arithmetic operations between two floating-point numbers and returns\n    the result as an integer. The supported operations are addition, subtraction, multiplication,\n    and division.\n\n    Args:\n        left (float): The left operand for the arithmetic operation.\n        right (float): The right operand for the arithmetic operation.\n        operator (str): The arithmetic operator to use ('+', '-', '*', or '/').\n\n    Returns:\n        tuple[int]: A single-element tuple containing the result of the operation as an integer.\n\n    Raises:\n        ValueError: If either operand is not a float or if the operator is not supported.\n\n    Notes:\n        - Division results are converted to integers\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n        - Input values are limited by MAX_FLOAT constant\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"left\": (\n                    \"FLOAT\",\n                    {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01},\n                ),\n                \"right\": (\n                    \"FLOAT\",\n                    {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01},\n                ),\n                \"operator\": ([\"+\", \"-\", \"*\", \"/\"],),\n            }\n        }\n\n    RETURN_TYPES = (\"INT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n\n    def execute(self, **kwargs):\n        try:\n            left = float(kwargs.get(\"left\", 0.0))\n            right = float(kwargs.get(\"right\", 0.0))\n            operator = str(kwargs.get(\"operator\", \"+\"))\n        except (TypeError, ValueError):\n            raise ValueError(\"Values must be convertible to floats\")\n\n        if operator == \"+\":\n            return (int(left + right),)\n        if operator == \"-\":\n            return (int(left - right),)\n        if operator == \"*\":\n            return (int(left * right),)\n        if operator == \"/\":\n            return (int(left / right),)\n\n        raise ValueError(f\"Unsupported operator: {operator}\")\n</code></pre>"},{"location":"nodes/numbers/#floatoperator","title":"FloatOperator","text":"<p>Performs arithmetic operations on two floating-point numbers.</p> <p>This class supports basic arithmetic operations between two floating-point numbers. The supported operations are addition, subtraction, multiplication, and division.</p>"},{"location":"nodes/numbers/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required left <code>FLOAT</code> 0 step=0.01 required right <code>FLOAT</code> 0 step=0.01 required operator <code>LIST</code>"},{"location":"nodes/numbers/#returns_5","title":"Returns","text":"Name Type float <code>FLOAT</code> Source code in numbers.py <pre><code>class FloatOperator:\n    \"\"\"Performs arithmetic operations on two floating-point numbers.\n\n    This class supports basic arithmetic operations between two floating-point numbers. The supported\n    operations are addition, subtraction, multiplication, and division.\n\n    Args:\n        left (float): The left operand for the arithmetic operation.\n        right (float): The right operand for the arithmetic operation.\n        operator (str): The arithmetic operator to use ('+', '-', '*', or '/').\n\n    Returns:\n        tuple[float]: A single-element tuple containing the result of the operation.\n\n    Raises:\n        ValueError: If either operand is not a float or if the operator is not supported.\n\n    Notes:\n        - Division by zero will raise a Python exception\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n        - Input values are limited by MAX_FLOAT constant\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"left\": (\n                    \"FLOAT\",\n                    {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01},\n                ),\n                \"right\": (\n                    \"FLOAT\",\n                    {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01},\n                ),\n                \"operator\": ([\"+\", \"-\", \"*\", \"/\"],),\n            }\n        }\n\n    RETURN_TYPES = (\"FLOAT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n\n    def execute(self, **kwargs):\n        left = kwargs.get(\"left\")\n        if not isinstance(left, float):\n            raise ValueError(\"Left must be a float\")\n        right = kwargs.get(\"right\")\n        if not isinstance(right, float):\n            raise ValueError(\"Right must be a float\")\n        operator = kwargs.get(\"operator\")\n        if not isinstance(operator, str):\n            raise ValueError(\"Operator must be a string\")\n        if operator == \"+\":\n            return (left + right,)\n        if operator == \"-\":\n            return (left - right,)\n        if operator == \"*\":\n            return (left * right,)\n        if operator == \"/\":\n            return (left / right,)\n\n        raise ValueError(f\"Unsupported operator: {operator}\")\n</code></pre>"},{"location":"nodes/numbers/#intminmax","title":"IntMinMax","text":"<p>Determines the minimum or maximum value between two integers.</p> <p>This class compares two integer inputs and returns either the smaller or larger value based on the specified mode of operation.</p>"},{"location":"nodes/numbers/#inputs_6","title":"Inputs","text":"Group Name Type Default Extras required a <code>INT</code> 0 forceInput=True required b <code>INT</code> 0 forceInput=True required mode <code>LIST</code>"},{"location":"nodes/numbers/#returns_6","title":"Returns","text":"Name Type int <code>INT</code> Source code in numbers.py <pre><code>class IntMinMax:\n    \"\"\"Determines the minimum or maximum value between two integers.\n\n    This class compares two integer inputs and returns either the smaller or larger value based on\n    the specified mode of operation.\n\n    Args:\n        a (int): The first integer to compare.\n        b (int): The second integer to compare.\n        mode (str): The comparison mode ('min' or 'max').\n\n    Returns:\n        tuple[int]: A single-element tuple containing either the minimum or maximum value.\n\n    Raises:\n        ValueError: If either input is not an integer or if the mode is not supported.\n\n    Notes:\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"a\": (\"INT\", {\"default\": 0, \"forceInput\": True}),\n                \"b\": (\"INT\", {\"default\": 0, \"forceInput\": True}),\n                \"mode\": ([\"min\", \"max\"],),\n            }\n        }\n\n    RETURN_TYPES = (\"INT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n    CLASS_ID = \"int_minmax\"\n\n    def execute(self, **kwargs):\n        try:\n            a = int(kwargs.get(\"a\", 0))\n            b = int(kwargs.get(\"b\", 0))\n            mode = str(kwargs.get(\"mode\", \"min\"))\n        except (TypeError, ValueError):\n            raise ValueError(\"Values must be convertible to integers\")\n\n        if mode == \"min\":\n            return (min(a, b),)\n        if mode == \"max\":\n            return (max(a, b),)\n        raise ValueError(f\"Unsupported mode: {mode}\")\n</code></pre>"},{"location":"nodes/numbers/#floatminmax","title":"FloatMinMax","text":"<p>Determines the minimum or maximum value between two floating-point numbers.</p> <p>This class compares two float inputs and returns either the smaller or larger value based on the specified mode of operation.</p>"},{"location":"nodes/numbers/#inputs_7","title":"Inputs","text":"Group Name Type Default Extras required a <code>FLOAT</code> 0 forceInput=True required b <code>FLOAT</code> 0 forceInput=True required mode <code>LIST</code>"},{"location":"nodes/numbers/#returns_7","title":"Returns","text":"Name Type float <code>FLOAT</code> Source code in numbers.py <pre><code>class FloatMinMax:\n    \"\"\"Determines the minimum or maximum value between two floating-point numbers.\n\n    This class compares two float inputs and returns either the smaller or larger value based on\n    the specified mode of operation.\n\n    Args:\n        a (float): The first float to compare.\n        b (float): The second float to compare.\n        mode (str): The comparison mode ('min' or 'max').\n\n    Returns:\n        tuple[float]: A single-element tuple containing either the minimum or maximum value.\n\n    Raises:\n        ValueError: If either input is not a float or if the mode is not supported.\n\n    Notes:\n        - The returned value is always wrapped in a tuple to maintain consistency with the node system\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"a\": (\"FLOAT\", {\"default\": 0, \"forceInput\": True}),\n                \"b\": (\"FLOAT\", {\"default\": 0, \"forceInput\": True}),\n                \"mode\": ([\"min\", \"max\"],),\n            }\n        }\n\n    RETURN_TYPES = (\"FLOAT\",)\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n    CLASS_ID = \"float_minmax\"\n\n    def execute(self, **kwargs):\n        try:\n            a = float(kwargs.get(\"a\", 0.0))\n            b = float(kwargs.get(\"b\", 0.0))\n            mode = str(kwargs.get(\"mode\", \"min\"))\n        except (TypeError, ValueError):\n            raise ValueError(\"Values must be convertible to floats\")\n\n        if mode == \"min\":\n            return (min(a, b),)\n        if mode == \"max\":\n            return (max(a, b),)\n        raise ValueError(f\"Unsupported mode: {mode}\")\n</code></pre>"},{"location":"nodes/numbers/#randomnumber","title":"RandomNumber","text":"<p>Generates a random integer and its floating-point representation.</p> <p>This class produces a random integer between 0 and MAX_INT and provides both the integer value and its floating-point equivalent.</p>"},{"location":"nodes/numbers/#inputs_8","title":"Inputs","text":"Group Name Type Default Extras"},{"location":"nodes/numbers/#returns_8","title":"Returns","text":"Name Type int <code>INT</code> float <code>FLOAT</code> Source code in numbers.py <pre><code>class RandomNumber:\n    \"\"\"Generates a random integer and its floating-point representation.\n\n    This class produces a random integer between 0 and MAX_INT and provides both the integer value\n    and its floating-point equivalent.\n\n    Returns:\n        tuple[int, float]: A tuple containing the random integer and its float representation.\n\n    Notes:\n        - The random value is regenerated each time IS_CHANGED is called\n        - The maximum value is limited by MAX_INT constant\n        - No parameters are required for this operation\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\"required\": {}}\n\n    RETURN_TYPES = (\n        \"INT\",\n        \"FLOAT\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n\n    @staticmethod\n    def get_random():\n        result = random.randint(0, MAX_INT)\n        return (\n            result,\n            float(result),\n        )\n\n    def execute(self):\n        return RandomNumber.get_random()\n\n    @classmethod\n    def IS_CHANGED(cls):  # type: ignore\n        return RandomNumber.get_random()\n</code></pre>"},{"location":"nodes/numbers/#mathoperator","title":"MathOperator","text":"<p>Evaluates mathematical expressions with support for variables and multiple operators.</p> <p>This class provides a powerful expression evaluator that supports variables (a, b, c, d) and various mathematical operations. It can handle arithmetic, comparison, and logical operations.</p>"},{"location":"nodes/numbers/#inputs_9","title":"Inputs","text":"Group Name Type Default Extras optional a <code>FLOAT</code> 0 step=0.01 optional b <code>FLOAT</code> 0 step=0.01 optional c <code>FLOAT</code> 0 step=0.01 optional d <code>FLOAT</code> 0 step=0.01 required value <code>STRING</code> multiline=True"},{"location":"nodes/numbers/#returns_9","title":"Returns","text":"Name Type int <code>INT</code> float <code>FLOAT</code> Source code in numbers.py <pre><code>class MathOperator:\n    \"\"\"Evaluates mathematical expressions with support for variables and multiple operators.\n\n    This class provides a powerful expression evaluator that supports variables (a, b, c, d) and\n    various mathematical operations. It can handle arithmetic, comparison, and logical operations.\n\n    Args:\n        a (float, optional): Value for variable 'a'. Defaults to 0.0.\n        b (float, optional): Value for variable 'b'. Defaults to 0.0.\n        c (float, optional): Value for variable 'c'. Defaults to 0.0.\n        d (float, optional): Value for variable 'd'. Defaults to 0.0.\n        value (str): The mathematical expression to evaluate.\n\n    Returns:\n        tuple[int, float]: A tuple containing both integer and float representations of the result.\n\n    Raises:\n        ValueError: If the expression contains unsupported operations or invalid syntax.\n\n    Notes:\n        - Supports standard arithmetic operators: +, -, *, /, //, %, **\n        - Supports comparison operators: ==, !=, &lt;, &lt;=, &gt;, &gt;=\n        - Supports logical operators: and, or, not\n        - Supports bitwise XOR operator: ^\n        - Includes functions: min(), max(), round(), sum(), len()\n        - Variables are limited by MAX_FLOAT constant\n        - NaN results are converted to 0.0\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"optional\": {\n                \"a\": (\"FLOAT\", {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01}),\n                \"b\": (\"FLOAT\", {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01}),\n                \"c\": (\"FLOAT\", {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01}),\n                \"d\": (\"FLOAT\", {\"default\": 0, \"min\": -MAX_FLOAT, \"max\": MAX_FLOAT, \"step\": 0.01}),\n            },\n            \"required\": {\n                \"value\": (\"STRING\", {\"multiline\": True, \"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\n        \"INT\",\n        \"FLOAT\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = NUMBERS_CAT\n\n    def execute(self, **kwargs):\n        try:\n            a = float(kwargs.get(\"a\", 0.0))\n            b = float(kwargs.get(\"b\", 0.0))\n            c = float(kwargs.get(\"c\", 0.0))\n            d = float(kwargs.get(\"d\", 0.0))\n            value = str(kwargs.get(\"value\", \"\")).strip()\n        except (TypeError, ValueError):\n            raise ValueError(\"Values must be convertible to floats\")\n\n        def safe_xor(x, y):\n            if isinstance(x, float) or isinstance(y, float):\n                # Convert to integers if either operand is a float\n                return float(int(x) ^ int(y))\n            return op.xor(x, y)\n\n        operators = {\n            ast.Add: op.add,\n            ast.Sub: op.sub,\n            ast.Mult: op.mul,\n            ast.Div: op.truediv,\n            ast.FloorDiv: op.floordiv,\n            ast.Pow: op.pow,\n            ast.USub: op.neg,\n            ast.Mod: op.mod,\n            ast.Eq: op.eq,\n            ast.NotEq: op.ne,\n            ast.Lt: op.lt,\n            ast.LtE: op.le,\n            ast.Gt: op.gt,\n            ast.GtE: op.ge,\n            ast.And: lambda x, y: x and y,\n            ast.Or: lambda x, y: x or y,\n            ast.Not: op.not_,\n            ast.BitXor: safe_xor,  # Use the safe_xor function\n        }\n\n        op_functions = {\n            \"min\": min,\n            \"max\": max,\n            \"round\": round,\n            \"sum\": sum,\n            \"len\": len,\n        }\n\n        def eval_(node):\n            if isinstance(node, ast.Num):  # number\n                return node.n\n            if isinstance(node, ast.Name):  # variable\n                if node.id == \"a\":\n                    return a\n                if node.id == \"b\":\n                    return b\n                if node.id == \"c\":\n                    return c\n                if node.id == \"d\":\n                    return d\n            if isinstance(node, ast.BinOp):  # &lt;left&gt; &lt;operator&gt; &lt;right&gt;\n                return operators[type(node.op)](eval_(node.left), eval_(node.right))  # type: ignore\n            if isinstance(node, ast.UnaryOp):  # &lt;operator&gt; &lt;operand&gt; e.g., -1\n                return operators[type(node.op)](eval_(node.operand))  # type: ignore\n            if isinstance(node, ast.Compare):  # comparison operators\n                left = eval_(node.left)\n                for operator, comparator in zip(node.ops, node.comparators):\n                    if not operators[type(operator)](left, eval_(comparator)):  # type: ignore\n                        return 0\n                return 1\n            if isinstance(node, ast.BoolOp):  # boolean operators (And, Or)\n                values = [eval_(value) for value in node.values]\n                return operators[type(node.op)](*values)  # type: ignore\n            if isinstance(node, ast.Call):  # custom function\n                if node.func.id in op_functions:  # type: ignore\n                    args = [eval_(arg) for arg in node.args]\n                    return op_functions[node.func.id](*args)  # type: ignore\n            if isinstance(node, ast.Subscript):  # indexing or slicing\n                value = eval_(node.value)\n                if isinstance(node.slice, ast.Constant):\n                    return value[node.slice.value]\n                return 0\n            return 0\n\n        result = eval_(ast.parse(value, mode=\"eval\").body)\n\n        if math.isnan(result):  # type: ignore\n            result = 0.0\n\n        return (\n            round(result),  # type: ignore\n            result,\n        )  # type: ignore\n</code></pre>"},{"location":"nodes/platform_io/","title":"Platform Io Nodes","text":""},{"location":"nodes/platform_io/#inputimage","title":"InputImage","text":"<p>Processes and validates image inputs from various sources for the platform.</p> <p>This class handles image input processing, supporting both single and multiple images from URLs or base64 strings. It includes functionality for alpha channel management and mask generation.</p>"},{"location":"nodes/platform_io/#inputs","title":"Inputs","text":"Group Name Type Default Extras required title <code>STRING</code> Input Image required subtype <code>LIST</code> required required <code>BOOLEAN</code> True required include_alpha <code>BOOLEAN</code> False required multiple <code>BOOLEAN</code> False required value <code>STRING</code> required metadata <code>STRING</code> {} multiline=True optional fallback <code>&lt;ast.Name object at 0x7f1c090936d0&gt;</code> Source code in platform_io.py <pre><code>class InputImage:\n    \"\"\"Processes and validates image inputs from various sources for the platform.\n\n    This class handles image input processing, supporting both single and multiple images from URLs or\n    base64 strings. It includes functionality for alpha channel management and mask generation.\n\n    Args:\n        title (str): Display title for the input node. Defaults to \"Input Image\".\n        subtype (str): Type of input - either \"image\" or \"mask\".\n        required (bool): Whether the input is required. Defaults to True.\n        include_alpha (bool): Whether to preserve alpha channel. Defaults to False.\n        multiple (bool): Allow multiple image inputs. Defaults to False.\n        value (str): Image data as URL or base64 string.\n        metadata (str): JSON string containing additional metadata. Defaults to \"{}\".\n        fallback (any): Optional fallback value if no input is provided.\n\n    Returns:\n        tuple[list]: A tuple containing a list of processed images as torch tensors in BWHC format.\n\n    Raises:\n        ValueError: If value is not a string, subtype is invalid, or no valid input is found.\n\n    Notes:\n        - URLs must start with \"http\" to be recognized\n        - Multiple images can be provided as comma-separated values\n        - Alpha channels are removed by default unless include_alpha is True\n        - Mask inputs are automatically converted to grayscale\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"title\": (\"STRING\", {\"default\": \"Input Image\"}),\n                \"subtype\": ([\"image\", \"mask\"],),\n                \"required\": (\"BOOLEAN\", {\"default\": True}),\n                \"include_alpha\": (\"BOOLEAN\", {\"default\": False}),\n                \"multiple\": (\"BOOLEAN\", {\"default\": False}),\n                \"value\": (\"STRING\", {\"default\": \"\"}),\n                \"metadata\": (\"STRING\", {\"default\": \"{}\", \"multiline\": True}),\n            },\n            \"optional\": {\n                \"fallback\": (any_type,),\n            },\n        }\n\n    RETURN_TYPES = (any_type,)\n    FUNCTION = \"execute\"\n    CATEGORY = PLATFORM_IO_CAT\n    OUTPUT_IS_LIST = (True,)\n\n    def execute(\n        self,\n        **kwargs,\n    ) -&gt; tuple[list[torch.Tensor]]:\n        def post_process(output: TensorImage, include_alpha: bool) -&gt; TensorImage:\n            if output.shape[1] not in [3, 4]:\n                if len(output.shape) == 2:  # (H,W)\n                    output = TensorImage(output.unsqueeze(0).unsqueeze(0).expand(-1, 3, -1, -1))\n                elif len(output.shape) == 3:  # (B,H,W)\n                    output = TensorImage(output.unsqueeze(1).expand(-1, 3, -1, -1))\n                elif len(output.shape) == 4 and output.shape[1] == 1:  # (B,1,H,W)\n                    output = TensorImage(output.expand(-1, 3, -1, -1))\n                else:\n                    raise ValueError(f\"Unsupported shape: {output.shape}\")\n            else:\n                if not include_alpha and output.shape[1] == 4:\n                    rgb = TensorImage(output[:, :3, :, :])\n                    alpha = TensorImage(output[:, -1, :, :])\n                    output, _ = cutout(rgb, alpha)\n            return output\n\n        def validate_inputs() -&gt; tuple[str, str, bool, bool, TensorImage | None]:\n            value = kwargs.get(\"value\", \"\")\n            if not isinstance(value, str):\n                raise ValueError(\"Value must be a string\")\n\n            subtype = kwargs.get(\"subtype\", \"image\")\n            if not isinstance(subtype, str):\n                raise ValueError(\"Subtype must be a string\")\n\n            include_alpha = bool(kwargs.get(\"include_alpha\", False))\n            multiple = bool(kwargs.get(\"multiple\", False))\n            fallback = kwargs.get(\"fallback\")\n\n            return value, subtype, include_alpha, multiple, fallback\n\n        def process_value(value: str, multiple: bool) -&gt; list[str]:\n            if not value:\n                return []\n            if \",\" in value:\n                items = value.split(\",\")\n                return items if multiple else [items[0]]\n            return [value]\n\n        def load_image(url_or_base64: str) -&gt; TensorImage:\n            if not url_or_base64:\n                raise ValueError(\"Empty input string\")\n\n            if url_or_base64.startswith(\"http\"):\n                return TensorImage.from_web(url_or_base64)\n            try:\n                return TensorImage.from_base64(url_or_base64)\n            except Exception as e:\n                raise ValueError(f\"Unsupported input format: {url_or_base64}\") from e\n\n        value, subtype, include_alpha, multiple, fallback = validate_inputs()\n        value_list = process_value(value, multiple)\n        outputs: list[torch.Tensor] = []\n\n        # Process each input value\n        for item in value_list:\n            if isinstance(item, str):\n                try:\n                    output = load_image(item)\n                    outputs.append(output)\n                except ValueError as e:\n                    if not outputs:\n                        raise e\n\n        if len(outputs) == 0:\n            if fallback is None:\n                raise ValueError(\"No input found and no fallback provided\")\n            outputs.append(TensorImage.from_BWHC(fallback))\n\n        for i, output in enumerate(outputs):\n            if not isinstance(output, TensorImage):\n                raise ValueError(f\"Output {i} must be a TensorImage\")\n\n            if subtype == \"mask\":\n                outputs[i] = output.get_grayscale().get_BWHC()\n            else:\n                outputs[i] = post_process(output, include_alpha).get_BWHC()\n        clean_memory()\n        return (outputs,)\n</code></pre>"},{"location":"nodes/platform_io/#inputconnector","title":"InputConnector","text":"<p>Manages file downloads from external services using authentication tokens.</p> <p>Handles connections to external services (currently Google Drive) to download files using provided authentication tokens and file identifiers.</p>"},{"location":"nodes/platform_io/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required title <code>STRING</code> Input Connector required subtype <code>LIST</code> required required <code>BOOLEAN</code> True required override <code>BOOLEAN</code> False required token <code>STRING</code> required mime_type <code>STRING</code> image/png required value <code>STRING</code> required metadata <code>STRING</code> {} multiline=True"},{"location":"nodes/platform_io/#returns","title":"Returns","text":"Name Type file <code>FILE</code> Source code in platform_io.py <pre><code>class InputConnector:\n    \"\"\"Manages file downloads from external services using authentication tokens.\n\n    Handles connections to external services (currently Google Drive) to download files using provided\n    authentication tokens and file identifiers.\n\n    Args:\n        title (str): Display title for the connector. Defaults to \"Input Connector\".\n        subtype (str): Service type, currently only supports \"google_drive\".\n        required (bool): Whether the input is required. Defaults to True.\n        override (bool): Whether to override existing files. Defaults to False.\n        token (str): Authentication token for the service.\n        mime_type (str): Expected MIME type of the file. Defaults to \"image/png\".\n        value (str): File identifier for the service.\n        metadata (str): JSON string containing additional metadata. Defaults to \"{}\".\n\n    Returns:\n        tuple[str]: A tuple containing the path to the downloaded file.\n\n    Raises:\n        ValueError: If token, value, mime_type are not strings or override is not boolean.\n\n    Notes:\n        - Files are downloaded to the ComfyUI input directory\n        - Supports Google Drive integration with proper authentication\n        - Can be extended to support other services in the future\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"title\": (\"STRING\", {\"default\": \"Input Connector\"}),\n                \"subtype\": ([\"google_drive\"],),\n                \"required\": (\"BOOLEAN\", {\"default\": True}),\n                \"override\": (\"BOOLEAN\", {\"default\": False}),\n                \"token\": (\"STRING\", {\"default\": \"\"}),\n                \"mime_type\": (\"STRING\", {\"default\": \"image/png\"}),\n                \"value\": (\"STRING\", {\"default\": \"\"}),\n                \"metadata\": (\"STRING\", {\"default\": \"{}\", \"multiline\": True}),\n            },\n        }\n\n    RETURN_TYPES = (\"FILE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PLATFORM_IO_CAT\n\n    def execute(\n        self,\n        **kwargs,\n    ):\n        value = kwargs.get(\"value\")\n        if not isinstance(value, str):\n            raise ValueError(\"Value must be a string\")\n        token = kwargs.get(\"token\")\n        if not isinstance(token, str):\n            raise ValueError(\"Token must be a string\")\n        mime_type = kwargs.get(\"mime_type\")\n        if not isinstance(mime_type, str):\n            raise ValueError(\"Mime type must be a string\")\n        override = kwargs.get(\"override\")\n        if not isinstance(override, bool):\n            raise ValueError(\"Override must be a boolean\")\n        connector = GoogleConnector(token=token)\n        input_folder = os.path.join(BASE_COMFY_DIR, \"input\")\n        data = connector.download(\n            file_id=value, mime_type=mime_type, output_path=input_folder, override=override\n        )\n        clean_memory()\n        return (data,)\n</code></pre>"},{"location":"nodes/platform_io/#inputtext","title":"InputText","text":"<p>Processes text input with fallback support.</p> <p>Handles text input processing with support for different subtypes and optional fallback values when input is empty.</p>"},{"location":"nodes/platform_io/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required title <code>STRING</code> Input Text required subtype <code>LIST</code> required required <code>BOOLEAN</code> True required value <code>STRING</code> multiline=True required metadata <code>STRING</code> {} multiline=True optional fallback <code>STRING</code> forceInput=True"},{"location":"nodes/platform_io/#returns_1","title":"Returns","text":"Name Type string <code>STRING</code> Source code in platform_io.py <pre><code>class InputText:\n    \"\"\"Processes text input with fallback support.\n\n    Handles text input processing with support for different subtypes and optional fallback values\n    when input is empty.\n\n    Args:\n        title (str): Display title for the text input. Defaults to \"Input Text\".\n        subtype (str): Type of text - \"string\", \"positive_prompt\", or \"negative_prompt\".\n        required (bool): Whether the input is required. Defaults to True.\n        value (str): The input text value.\n        metadata (str): JSON string containing additional metadata. Defaults to \"{}\".\n        fallback (str): Optional fallback text if input is empty.\n\n    Returns:\n        tuple[str]: A tuple containing the processed text value.\n\n    Raises:\n        ValueError: If value or fallback are not strings.\n\n    Notes:\n        - Empty inputs will use the fallback value if provided\n        - Supports multiline text input\n        - Special handling for prompt-type inputs\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"title\": (\"STRING\", {\"default\": \"Input Text\"}),\n                \"subtype\": ([\"string\", \"positive_prompt\", \"negative_prompt\"],),\n                \"required\": (\"BOOLEAN\", {\"default\": True}),\n                \"value\": (\"STRING\", {\"multiline\": True, \"default\": \"\"}),\n                \"metadata\": (\"STRING\", {\"default\": \"{}\", \"multiline\": True}),\n            },\n            \"optional\": {\n                \"fallback\": (\"STRING\", {\"forceInput\": True}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PLATFORM_IO_CAT\n\n    def execute(self, **kwargs):\n        value = kwargs.get(\"value\")\n        if not isinstance(value, str):\n            raise ValueError(\"Value must be a string\")\n        fallback = kwargs.get(\"fallback\")\n        if value == \"\":\n            value = fallback or \"\"\n        clean_memory()\n        return (value,)\n</code></pre>"},{"location":"nodes/platform_io/#inputnumber","title":"InputNumber","text":"<p>Processes numeric inputs with type conversion.</p> <p>Handles numeric input processing with support for both integer and float values, including automatic type conversion based on the specified subtype.</p>"},{"location":"nodes/platform_io/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required title <code>STRING</code> Input Number required subtype <code>LIST</code> required required <code>BOOLEAN</code> True required value <code>FLOAT</code> 0 max=18446744073709551615 required metadata <code>STRING</code> {} multiline=True Source code in platform_io.py <pre><code>class InputNumber:\n    \"\"\"Processes numeric inputs with type conversion.\n\n    Handles numeric input processing with support for both integer and float values, including\n    automatic type conversion based on the specified subtype.\n\n    Args:\n        title (str): Display title for the number input. Defaults to \"Input Number\".\n        subtype (str): Type of number - either \"float\" or \"int\".\n        required (bool): Whether the input is required. Defaults to True.\n        value (float): The input numeric value. Defaults to 0.\n        metadata (str): JSON string containing additional metadata. Defaults to \"{}\".\n\n    Returns:\n        tuple[Union[int, float]]: A tuple containing the processed numeric value.\n\n    Raises:\n        ValueError: If value is not numeric or subtype is invalid.\n\n    Notes:\n        - Automatically converts between float and int based on subtype\n        - Maintains numeric precision during conversion\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"title\": (\"STRING\", {\"default\": \"Input Number\"}),\n                \"subtype\": ([\"float\", \"int\"],),\n                \"required\": (\"BOOLEAN\", {\"default\": True}),\n                \"value\": (\"FLOAT\", {\"default\": 0, \"min\": -18446744073709551615, \"max\": 18446744073709551615}),\n                \"metadata\": (\"STRING\", {\"default\": \"{}\", \"multiline\": True}),\n            },\n        }\n\n    RETURN_TYPES = (any_type,)\n    FUNCTION = \"execute\"\n    CATEGORY = PLATFORM_IO_CAT\n\n    def execute(self, **kwargs):\n        value = kwargs.get(\"value\")\n        if not isinstance(value, int) and not isinstance(value, float):\n            raise ValueError(\"Value must be a string\")\n        subtype = kwargs.get(\"subtype\")\n        if not isinstance(subtype, str):\n            raise ValueError(\"Subtype must be a string\")\n        if subtype == \"int\":\n            value = int(value)\n        else:\n            value = float(value)\n        clean_memory()\n        return (value,)\n</code></pre>"},{"location":"nodes/platform_io/#inputboolean","title":"InputBoolean","text":"<p>Processes boolean inputs for the platform.</p> <p>Handles boolean input processing with validation and type checking.</p>"},{"location":"nodes/platform_io/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required title <code>STRING</code> Input Boolean required subtype <code>LIST</code> required required <code>BOOLEAN</code> True required value <code>BOOLEAN</code> False required metadata <code>STRING</code> {} multiline=True"},{"location":"nodes/platform_io/#returns_2","title":"Returns","text":"Name Type boolean <code>BOOLEAN</code> Source code in platform_io.py <pre><code>class InputBoolean:\n    \"\"\"Processes boolean inputs for the platform.\n\n    Handles boolean input processing with validation and type checking.\n\n    Args:\n        title (str): Display title for the boolean input. Defaults to \"Input Boolean\".\n        subtype (str): Must be \"boolean\".\n        required (bool): Whether the input is required. Defaults to True.\n        value (bool): The input boolean value. Defaults to False.\n        metadata (str): JSON string containing additional metadata. Defaults to \"{}\".\n\n    Returns:\n        tuple[bool]: A tuple containing the boolean value.\n\n    Raises:\n        ValueError: If value is not a boolean.\n\n    Notes:\n        - Simple boolean validation and processing\n        - Returns original boolean value without modification\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"title\": (\"STRING\", {\"default\": \"Input Boolean\"}),\n                \"subtype\": ([\"boolean\"],),\n                \"required\": (\"BOOLEAN\", {\"default\": True}),\n                \"value\": (\"BOOLEAN\", {\"default\": False}),\n                \"metadata\": (\"STRING\", {\"default\": \"{}\", \"multiline\": True}),\n            }\n        }\n\n    RETURN_TYPES = (\"BOOLEAN\",)\n    RETURN_NAMES = (\"boolean\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PLATFORM_IO_CAT\n\n    def execute(self, **kwargs):\n        value = kwargs.get(\"value\")\n        if not isinstance(value, bool):\n            raise ValueError(\"Value must be a boolean\")\n        clean_memory()\n        return (value,)\n</code></pre>"},{"location":"nodes/platform_io/#output","title":"Output","text":"<p>Manages output processing and file saving for various data types.</p> <p>Handles the processing and saving of different output types including images, masks, numbers, and strings. Includes support for thumbnail generation and metadata management.</p>"},{"location":"nodes/platform_io/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required title <code>STRING</code> Output Image required subtype <code>LIST</code> required metadata <code>STRING</code> {} multiline=True required value <code>&lt;ast.Name object at 0x7f1c0908e590&gt;</code> hidden output_path <code>STRING</code> output Source code in platform_io.py <pre><code>class Output:\n    \"\"\"Manages output processing and file saving for various data types.\n\n    Handles the processing and saving of different output types including images, masks, numbers, and\n    strings. Includes support for thumbnail generation and metadata management.\n\n    Args:\n        title (str): Display title for the output. Defaults to \"Output Image\".\n        subtype (str): Type of output - \"image\", \"mask\", \"int\", \"float\", \"string\", or \"dict\".\n        metadata (str): JSON string containing additional metadata.\n        value (any): The value to output.\n        output_path (str): Path for saving outputs. Defaults to \"output\".\n\n    Returns:\n        dict: UI configuration with signature_output containing processed results.\n\n    Raises:\n        ValueError: If inputs are invalid or output type is unsupported.\n\n    Notes:\n        - Automatically generates thumbnails for image outputs\n        - Saves images with unique filenames including timestamps\n        - Supports batch processing of multiple outputs\n        - Creates both full-size PNG and compressed JPEG thumbnails\n        - Handles various data types with appropriate serialization\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"title\": (\"STRING\", {\"default\": \"Output Image\"}),\n                \"subtype\": ([\"image\", \"mask\", \"int\", \"float\", \"string\", \"dict\"],),\n                \"metadata\": (\"STRING\", {\"default\": \"{}\", \"multiline\": True}),\n                \"value\": (any_type,),\n            },\n            \"hidden\": {\n                \"output_path\": (\"STRING\", {\"default\": \"output\"}),\n            },\n        }\n\n    RETURN_TYPES = ()\n    OUTPUT_NODE = True\n    INPUT_IS_LIST = True\n    FUNCTION = \"execute\"\n    CATEGORY = PLATFORM_IO_CAT\n\n    @classmethod\n    def IS_CHANGED(cls, **kwargs):  # type: ignore\n        return time.time()\n\n    def __save_outputs(self, **kwargs) -&gt; dict | None:\n        img = kwargs.get(\"img\")\n        if not isinstance(img, (torch.Tensor, TensorImage)):\n            raise ValueError(\"Image must be a tensor or TensorImage\")\n\n        title = kwargs.get(\"title\", \"\")\n        if not isinstance(title, str):\n            title = str(title)\n\n        subtype = kwargs.get(\"subtype\", \"image\")\n        if not isinstance(subtype, str):\n            subtype = str(subtype)\n\n        thumbnail_size = kwargs.get(\"thumbnail_size\", 1024)\n        if not isinstance(thumbnail_size, int):\n            try:\n                thumbnail_size = int(thumbnail_size)\n            except (ValueError, TypeError):\n                thumbnail_size = 1024\n\n        output_dir = kwargs.get(\"output_dir\", \"output\")\n        if not isinstance(output_dir, str):\n            output_dir = str(output_dir)\n\n        metadata = kwargs.get(\"metadata\", \"\")\n        if not isinstance(metadata, str):\n            metadata = str(metadata)\n\n        current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        file_name = f\"signature_{current_time_str}_{uuid7str()}.png\"\n        save_path = os.path.join(output_dir, file_name)\n        if os.path.exists(save_path):\n            file_name = f\"signature_{current_time_str}_{uuid7str()}_{uuid7str()}.png\"\n            save_path = os.path.join(output_dir, file_name)\n\n        output_img = img if isinstance(img, TensorImage) else TensorImage(img)\n\n        thumbnail_img = output_img.get_resized(thumbnail_size)\n        thumbnail_path = save_path.replace(\".png\", \"_thumbnail.jpeg\")\n        thumbnail_file_name = file_name.replace(\".png\", \"_thumbnail.jpeg\")\n        thumbnail_saved = thumbnail_img.save(thumbnail_path)\n\n        image_saved = output_img.save(save_path)\n\n        if image_saved and thumbnail_saved:\n            return {\n                \"title\": title,\n                \"type\": subtype,\n                \"metadata\": metadata,\n                \"value\": file_name,\n                \"thumbnail\": thumbnail_file_name if thumbnail_saved else None,\n            }\n\n        return None\n\n    def execute(self, **kwargs):\n        title_list = kwargs.get(\"title\")\n        if not isinstance(title_list, list):\n            raise ValueError(\"Title must be a list\")\n        metadata_list = kwargs.get(\"metadata\")\n        if not isinstance(metadata_list, list):\n            raise ValueError(\"Metadata must be a list\")\n        subtype_list = kwargs.get(\"subtype\")\n        if not isinstance(subtype_list, list):\n            raise ValueError(\"Subtype must be a list\")\n        output_path_list = kwargs.get(\"output_path\")\n        if not isinstance(output_path_list, list):\n            output_path_list = [\"output\"] * len(title_list)\n        value_list = kwargs.get(\"value\")\n        if not isinstance(value_list, list):\n            raise ValueError(\"Value must be a list\")\n        main_subtype = subtype_list[0]\n        supported_types = [\"image\", \"mask\", \"int\", \"float\", \"string\", \"dict\"]\n        if main_subtype not in supported_types:\n            raise ValueError(f\"Unsupported output type: {main_subtype}\")\n\n        results = []\n        thumbnail_size = 1024\n        for idx, item in enumerate(value_list):\n            title = title_list[idx]\n            metadata = metadata_list[idx]\n            output_dir = os.path.join(BASE_COMFY_DIR, output_path_list[idx])\n            if isinstance(item, torch.Tensor):\n                if main_subtype in [\"image\", \"mask\"]:\n                    tensor_images = TensorImage.from_BWHC(item.to(\"cpu\"))\n                    for img in tensor_images:\n                        result = self.__save_outputs(\n                            img=img,\n                            title=title,\n                            subtype=main_subtype,\n                            thumbnail_size=thumbnail_size,\n                            output_dir=output_dir,\n                            metadata=metadata,\n                        )\n                        if result:\n                            results.append(result)\n                else:\n                    raise ValueError(f\"Unsupported output type: {type(item)}\")\n            else:\n                value_json = json.dumps(item) if main_subtype == \"dict\" else item\n                results.append(\n                    {\"title\": title, \"type\": main_subtype, \"metadata\": metadata, \"value\": value_json}\n                )\n        clean_memory()\n        return {\"ui\": {\"signature_output\": results}}\n</code></pre>"},{"location":"nodes/primitives/","title":"Primitives Nodes","text":""},{"location":"nodes/primitives/#float","title":"Float","text":"<p>A node that handles floating-point number inputs with configurable parameters.</p> <p>This node provides functionality for processing floating-point numbers within a specified range and step size. It can be used as a basic input node in computational graphs where decimal number precision is required.</p>"},{"location":"nodes/primitives/#inputs","title":"Inputs","text":"Group Name Type Default Extras required value <code>FLOAT</code> 0 max=18446744073709551615, step=0.01"},{"location":"nodes/primitives/#returns","title":"Returns","text":"Name Type float <code>FLOAT</code> Source code in primitives.py <pre><code>class Float:\n    \"\"\"A node that handles floating-point number inputs with configurable parameters.\n\n    This node provides functionality for processing floating-point numbers within a specified range\n    and step size. It can be used as a basic input node in computational graphs where decimal\n    number precision is required.\n\n    Args:\n        value (float): The input floating-point number to process.\n                      Default: 0\n                      Min: -18446744073709551615\n                      Max: 18446744073709551615\n                      Step: 0.01\n\n    Returns:\n        tuple[float]: A single-element tuple containing the processed float value.\n\n    Notes:\n        - The node maintains the exact input value without any transformation\n        - The step value of 0.01 provides two decimal places of precision by default\n        - The min/max values correspond to the 64-bit integer limits\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\n                    \"FLOAT\",\n                    {\"default\": 0, \"min\": -18446744073709551615, \"max\": 18446744073709551615, \"step\": 0.01},\n                ),\n            },\n        }\n\n    RETURN_TYPES = (\"FLOAT\",)\n    RETURN_NAMES = (\"float\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PRIMITIVES_CAT\n\n    def execute(self, value):\n        return (value,)\n</code></pre>"},{"location":"nodes/primitives/#int","title":"Int","text":"<p>A node that handles integer number inputs with configurable parameters.</p> <p>This node provides functionality for processing integer numbers within a specified range and step size. It can be used as a basic input node in computational graphs where whole number values are required.</p>"},{"location":"nodes/primitives/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required value <code>INT</code> 0 max=18446744073709551615, step=1"},{"location":"nodes/primitives/#returns_1","title":"Returns","text":"Name Type int <code>INT</code> Source code in primitives.py <pre><code>class Int:\n    \"\"\"A node that handles integer number inputs with configurable parameters.\n\n    This node provides functionality for processing integer numbers within a specified range\n    and step size. It can be used as a basic input node in computational graphs where whole\n    number values are required.\n\n    Args:\n        value (int): The input integer number to process.\n                    Default: 0\n                    Min: -18446744073709551615\n                    Max: 18446744073709551615\n                    Step: 1\n\n    Returns:\n        tuple[int]: A single-element tuple containing the processed integer value.\n\n    Notes:\n        - The node maintains the exact input value without any transformation\n        - The step value of 1 ensures whole number increments\n        - The min/max values correspond to the 64-bit integer limits\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\n                    \"INT\",\n                    {\"default\": 0, \"min\": -18446744073709551615, \"max\": 18446744073709551615, \"step\": 1},\n                ),\n            },\n        }\n\n    RETURN_TYPES = (\"INT\",)\n    RETURN_NAMES = (\"int\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PRIMITIVES_CAT\n\n    def execute(self, value):\n        return (value,)\n</code></pre>"},{"location":"nodes/primitives/#string","title":"String","text":"<p>A node that handles single-line string inputs.</p> <p>This node provides functionality for processing single-line text input. It can be used as a basic input node in computational graphs where text processing is required.</p>"},{"location":"nodes/primitives/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required value <code>STRING</code>"},{"location":"nodes/primitives/#returns_2","title":"Returns","text":"Name Type string <code>STRING</code> Source code in primitives.py <pre><code>class String:\n    \"\"\"A node that handles single-line string inputs.\n\n    This node provides functionality for processing single-line text input. It can be used as a\n    basic input node in computational graphs where text processing is required.\n\n    Args:\n        value (str): The input string to process.\n                    Default: \"\" (empty string)\n\n    Returns:\n        tuple[str]: A single-element tuple containing the processed string value.\n\n    Notes:\n        - The node maintains the exact input value without any transformation\n        - Newline characters are not preserved in the input field\n        - Suitable for short text inputs or commands\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"string\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PRIMITIVES_CAT\n\n    def execute(self, value):\n        return (value,)\n\n\nclass StringMultiline:\n    \"\"\"A node that handles multi-line string inputs.\n\n    This node provides functionality for processing multi-line text input. It can be used as a\n    basic input node in computational graphs where larger text blocks or formatted text\n    processing is required.\n\n    Args:\n        value (str): The input multi-line string to process.\n                    Default: \"\" (empty string)\n\n    Returns:\n        tuple[str]: A single-element tuple containing the processed multi-line string value.\n\n    Notes:\n        - The node maintains the exact input value without any transformation\n        - Newline characters are preserved in the input\n        - Suitable for longer text inputs, code blocks, or formatted text\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\"STRING\", {\"default\": \"\", \"multiline\": True}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"string\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PRIMITIVES_CAT\n\n    def execute(self, value):\n        return (value,)\n</code></pre>"},{"location":"nodes/primitives/#stringmultiline","title":"StringMultiline","text":"<p>A node that handles multi-line string inputs.</p> <p>This node provides functionality for processing multi-line text input. It can be used as a basic input node in computational graphs where larger text blocks or formatted text processing is required.</p>"},{"location":"nodes/primitives/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required value <code>STRING</code> multiline=True"},{"location":"nodes/primitives/#returns_3","title":"Returns","text":"Name Type string <code>STRING</code> Source code in primitives.py <pre><code>class StringMultiline:\n    \"\"\"A node that handles multi-line string inputs.\n\n    This node provides functionality for processing multi-line text input. It can be used as a\n    basic input node in computational graphs where larger text blocks or formatted text\n    processing is required.\n\n    Args:\n        value (str): The input multi-line string to process.\n                    Default: \"\" (empty string)\n\n    Returns:\n        tuple[str]: A single-element tuple containing the processed multi-line string value.\n\n    Notes:\n        - The node maintains the exact input value without any transformation\n        - Newline characters are preserved in the input\n        - Suitable for longer text inputs, code blocks, or formatted text\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\"STRING\", {\"default\": \"\", \"multiline\": True}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"string\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PRIMITIVES_CAT\n\n    def execute(self, value):\n        return (value,)\n</code></pre>"},{"location":"nodes/primitives/#boolean","title":"Boolean","text":"<p>A node that handles boolean inputs.</p> <p>This node provides functionality for processing boolean (True/False) values. It can be used as a basic input node in computational graphs where conditional logic is required.</p>"},{"location":"nodes/primitives/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required value <code>BOOLEAN</code> False"},{"location":"nodes/primitives/#returns_4","title":"Returns","text":"Name Type boolean <code>BOOLEAN</code> Source code in primitives.py <pre><code>class Boolean:\n    \"\"\"A node that handles boolean inputs.\n\n    This node provides functionality for processing boolean (True/False) values. It can be used\n    as a basic input node in computational graphs where conditional logic is required.\n\n    Args:\n        value (bool): The input boolean value to process.\n                     Default: False\n\n    Returns:\n        tuple[bool]: A single-element tuple containing the processed boolean value.\n\n    Notes:\n        - The node maintains the exact input value without any transformation\n        - Typically displayed as a checkbox in user interfaces\n        - Useful for conditional branching in node graphs\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (\"BOOLEAN\", {\"default\": False}),\n            },\n        }\n\n    RETURN_TYPES = (\"BOOLEAN\",)\n    RETURN_NAMES = (\"boolean\",)\n    FUNCTION = \"execute\"\n    CATEGORY = PRIMITIVES_CAT\n\n    def execute(self, value):\n        return (value,)\n</code></pre>"},{"location":"nodes/text/","title":"Text Nodes","text":""},{"location":"nodes/text/#textpreview","title":"TextPreview","text":"<p>Processes and generates a preview of text inputs, supporting both strings and tensors.</p> <p>This node takes a list of text inputs and generates a formatted preview string. For tensor inputs, it includes shape information in the preview. The node is designed to handle multiple input types and provide a consistent preview format.</p>"},{"location":"nodes/text/#inputs","title":"Inputs","text":"Group Name Type Default Extras required value <code>&lt;ast.Name object at 0x7f1c090bd7b0&gt;</code> Source code in text.py <pre><code>class TextPreview:\n    \"\"\"Processes and generates a preview of text inputs, supporting both strings and tensors.\n\n    This node takes a list of text inputs and generates a formatted preview string. For tensor inputs,\n    it includes shape information in the preview. The node is designed to handle multiple input types\n    and provide a consistent preview format.\n\n    Args:\n        text (Any): A list of text inputs that can be strings, tensors, or other objects that can be\n            converted to strings.\n\n    Returns:\n        dict: A dictionary containing:\n            - ui (dict): UI-specific data with the preview text under the 'text' key\n            - result (tuple): A tuple containing the generated preview string\n\n    Notes:\n        - Tensor inputs are displayed with their shape information\n        - Multiple inputs are separated by newlines\n        - None values are skipped in the preview generation\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (any_type,),\n            },\n        }\n\n    INPUT_IS_LIST = True\n    RETURN_TYPES = ()\n    FUNCTION = \"execute\"\n    OUTPUT_NODE = True\n\n    CATEGORY = TEXT_CAT\n\n    def execute(self, **kwargs):\n        text = kwargs.get(\"value\", [])\n        text_string = \"\"\n        for t in text:\n            if t is None:\n                continue\n            if text_string != \"\":\n                text_string += \"\\n\"\n            text_string += str(t.shape) if isinstance(t, torch.Tensor) else str(t)\n        return {\"ui\": {\"text\": [text_string]}}\n</code></pre>"},{"location":"nodes/text/#textcase","title":"TextCase","text":"<p>Transforms text case according to specified formatting rules.</p> <p>A utility node that provides various case transformation options for input text, including lowercase, uppercase, capitalization, and title case conversion.</p>"},{"location":"nodes/text/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required text <code>STRING</code> forceInput=True required case <code>LIST</code>"},{"location":"nodes/text/#returns","title":"Returns","text":"Name Type string <code>STRING</code> Source code in text.py <pre><code>class TextCase:\n    \"\"\"Transforms text case according to specified formatting rules.\n\n    A utility node that provides various case transformation options for input text, including\n    lowercase, uppercase, capitalization, and title case conversion.\n\n    Args:\n        text (str): The input text to be transformed. Required.\n        case (str): The case transformation to apply. Must be one of:\n            - 'lower': Convert text to lowercase\n            - 'upper': Convert text to uppercase\n            - 'capitalize': Capitalize the first character\n            - 'title': Convert text to title case\n\n    Returns:\n        tuple[str]: A single-element tuple containing the transformed text.\n\n    Notes:\n        - Empty input text will result in an empty string output\n        - The transformation preserves any existing spacing and special characters\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"text\": (\"STRING\", {\"forceInput\": True}),\n                \"case\": ([\"lower\", \"upper\", \"capitalize\", \"title\"],),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = TEXT_CAT\n\n    def execute(self, **kwargs):\n        text = kwargs.get(\"text\") or \"\"\n        case = kwargs.get(\"case\") or \"lower\"\n        result = text\n        if case == \"lower\":\n            result = text.lower()\n        if case == \"upper\":\n            result = text.upper()\n        if case == \"capitalize\":\n            result = text.capitalize()\n        if case == \"title\":\n            result = text.title()\n        return (result,)\n</code></pre>"},{"location":"nodes/text/#texttrim","title":"TextTrim","text":"<p>Removes whitespace from text according to specified trimming rules.</p> <p>A utility node that trims whitespace from text input, offering options to remove whitespace from the beginning, end, or both sides of the text.</p>"},{"location":"nodes/text/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required text <code>STRING</code> forceInput=True required trim_type <code>LIST</code>"},{"location":"nodes/text/#returns_1","title":"Returns","text":"Name Type string <code>STRING</code> Source code in text.py <pre><code>class TextTrim:\n    \"\"\"Removes whitespace from text according to specified trimming rules.\n\n    A utility node that trims whitespace from text input, offering options to remove whitespace\n    from the beginning, end, or both sides of the text.\n\n    Args:\n        text (str): The input text to be trimmed. Required.\n        trim_type (str): The type of trimming to apply. Must be one of:\n            - 'both': Trim whitespace from both ends\n            - 'left': Trim whitespace from the start\n            - 'right': Trim whitespace from the end\n\n    Returns:\n        tuple[str]: A single-element tuple containing the trimmed text.\n\n    Notes:\n        - Whitespace includes spaces, tabs, and newlines\n        - Empty input text will result in an empty string output\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"text\": (\"STRING\", {\"forceInput\": True}),\n                \"trim_type\": ([\"both\", \"left\", \"right\"],),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = TEXT_CAT\n\n    def execute(self, **kwargs):\n        text = kwargs.get(\"text\") or \"\"\n        trim_type = kwargs.get(\"trim_type\") or \"both\"\n        if trim_type == \"both\":\n            return (text.strip(),)\n        if trim_type == \"left\":\n            return (text.lstrip(),)\n        if trim_type == \"right\":\n            return (text.rstrip(),)\n        return (text,)\n</code></pre>"},{"location":"nodes/text/#textsplit","title":"TextSplit","text":"<p>Splits text into a list of segments using a specified delimiter.</p> <p>A utility node that divides input text into multiple segments based on a delimiter, creating a list of substrings.</p>"},{"location":"nodes/text/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required text <code>STRING</code> forceInput=True required delimiter <code>STRING</code>"},{"location":"nodes/text/#returns_2","title":"Returns","text":"Name Type string <code>STRING</code> Source code in text.py <pre><code>class TextSplit:\n    \"\"\"Splits text into a list of segments using a specified delimiter.\n\n    A utility node that divides input text into multiple segments based on a delimiter,\n    creating a list of substrings.\n\n    Args:\n        text (str): The input text to be split. Required.\n        delimiter (str): The character or string to use as the splitting point. Defaults to space.\n\n    Returns:\n        tuple[list[str]]: A single-element tuple containing a list of split text segments.\n\n    Notes:\n        - Empty input text will result in a list with one empty string\n        - If the delimiter is not found, the result will be a single-element list\n        - Consecutive delimiters will result in empty strings in the output list\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"text\": (\"STRING\", {\"forceInput\": True}),\n                \"delimiter\": (\"STRING\", {\"default\": \" \"}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = TEXT_CAT\n    OUTPUT_IS_LIST = (True,)\n\n    def execute(self, **kwargs):\n        text = kwargs.get(\"text\", \"\")\n        delimiter = kwargs.get(\"delimiter\", \" \")\n        return (text.split(delimiter),)\n</code></pre>"},{"location":"nodes/text/#textregexreplace","title":"TextRegexReplace","text":"<p>Performs pattern-based text replacement using regular expressions.</p> <p>A powerful text processing node that uses regex patterns to find and replace text patterns, supporting complex pattern matching and replacement operations.</p>"},{"location":"nodes/text/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required text <code>STRING</code> forceInput=True required pattern <code>STRING</code> required replacement <code>STRING</code>"},{"location":"nodes/text/#returns_3","title":"Returns","text":"Name Type string <code>STRING</code> Source code in text.py <pre><code>class TextRegexReplace:\n    \"\"\"Performs pattern-based text replacement using regular expressions.\n\n    A powerful text processing node that uses regex patterns to find and replace text patterns,\n    supporting complex pattern matching and replacement operations.\n\n    Args:\n        text (str): The input text to process. Required.\n        pattern (str): The regular expression pattern to match. Required.\n        replacement (str): The string to use as replacement for matched patterns. Required.\n\n    Returns:\n        tuple[str]: A single-element tuple containing the processed text.\n\n    Notes:\n        - Invalid regex patterns will cause errors\n        - Empty pattern or replacement strings are allowed\n        - Supports all Python regex syntax including groups and backreferences\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"text\": (\"STRING\", {\"forceInput\": True}),\n                \"pattern\": (\"STRING\", {\"default\": \"\"}),\n                \"replacement\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = TEXT_CAT\n\n    def execute(self, **kwargs):\n        text = kwargs.get(\"text\", \"\")\n        pattern = kwargs.get(\"pattern\", \"\")\n        replacement = kwargs.get(\"replacement\", \"\")\n        return (re.sub(pattern, replacement, text),)\n</code></pre>"},{"location":"nodes/text/#textfindreplace","title":"TextFindReplace","text":"<p>Performs simple text replacement without regex support.</p> <p>A straightforward text processing node that replaces all occurrences of a substring with another substring, using exact matching.</p>"},{"location":"nodes/text/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required text <code>STRING</code> required find <code>STRING</code> required replace <code>STRING</code>"},{"location":"nodes/text/#returns_4","title":"Returns","text":"Name Type string <code>STRING</code> Source code in text.py <pre><code>class TextFindReplace:\n    \"\"\"Performs simple text replacement without regex support.\n\n    A straightforward text processing node that replaces all occurrences of a substring with\n    another substring, using exact matching.\n\n    Args:\n        text (str): The input text to process. Defaults to empty string.\n        find (str): The substring to search for. Defaults to empty string.\n        replace (str): The substring to replace matches with. Defaults to empty string.\n\n    Returns:\n        tuple[str]: A single-element tuple containing the processed text.\n\n    Notes:\n        - Case-sensitive matching\n        - All occurrences of the 'find' string will be replaced\n        - Empty strings for any parameter are handled safely\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"text\": (\"STRING\", {\"default\": \"\"}),\n                \"find\": (\"STRING\", {\"default\": \"\"}),\n                \"replace\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = TEXT_CAT\n\n    def execute(self, **kwargs):\n        text = kwargs.get(\"text\") or \"\"\n        find = kwargs.get(\"find\") or \"\"\n        replace = kwargs.get(\"replace\") or \"\"\n        return (text.replace(find, replace),)\n</code></pre>"},{"location":"nodes/text/#textconcatenate","title":"TextConcatenate","text":"<p>Combines two text strings into a single string.</p> <p>A basic text manipulation node that joins two input strings together in sequence, without any separator between them.</p>"},{"location":"nodes/text/#inputs_6","title":"Inputs","text":"Group Name Type Default Extras required text1 <code>STRING</code> required text2 <code>STRING</code>"},{"location":"nodes/text/#returns_5","title":"Returns","text":"Name Type string <code>STRING</code> Source code in text.py <pre><code>class TextConcatenate:\n    \"\"\"Combines two text strings into a single string.\n\n    A basic text manipulation node that joins two input strings together in sequence,\n    without any separator between them.\n\n    Args:\n        text1 (str): The first text string to concatenate. Defaults to empty string.\n        text2 (str): The second text string to concatenate. Defaults to empty string.\n\n    Returns:\n        tuple[str]: A single-element tuple containing the concatenated text.\n\n    Notes:\n        - No separator is added between the strings\n        - Empty strings are handled safely\n        - The result will be the direct combination of text1 followed by text2\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"text1\": (\"STRING\", {\"default\": \"\"}),\n                \"text2\": (\"STRING\", {\"default\": \"\"}),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"execute\"\n    CATEGORY = TEXT_CAT\n\n    def execute(self, **kwargs):\n        text1 = kwargs.get(\"text1\", \"\")\n        text2 = kwargs.get(\"text2\", \"\")\n        return (text1 + text2,)\n</code></pre>"},{"location":"nodes/utils/","title":"Utils Nodes","text":""},{"location":"nodes/utils/#any2string","title":"Any2String","text":"<p>Converts any input value to its string representation.</p> <p>This utility node provides a simple way to convert any input value into a string format using Python's built-in str() function. Useful for debugging, logging, or text-based operations.</p>"},{"location":"nodes/utils/#inputs","title":"Inputs","text":"Group Name Type Default Extras required value <code>&lt;ast.Name object at 0x7f1c090b3040&gt;</code>"},{"location":"nodes/utils/#returns","title":"Returns","text":"Name Type string <code>STRING</code> Source code in utils.py <pre><code>class Any2String:\n    \"\"\"Converts any input value to its string representation.\n\n    This utility node provides a simple way to convert any input value into a string format using\n    Python's built-in str() function. Useful for debugging, logging, or text-based operations.\n\n    Args:\n        value (Any): The input value to be converted to a string.\n\n    Returns:\n        tuple[str]: A single-element tuple containing the string representation of the input value.\n\n    Notes:\n        - The conversion is done using Python's native str() function\n        - All Python types are supported as they all implement __str__\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (any_type,),\n            }\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"string\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    CLASS_ID = \"any_string\"\n\n    def execute(self, value):\n        return (str(value),)\n</code></pre>"},{"location":"nodes/utils/#string2any","title":"String2Any","text":"<p>Safely converts a string representation to its Python object.</p> <p>Uses Python's ast.literal_eval for secure string evaluation, which only allows literal expressions (strings, numbers, tuples, lists, dicts, booleans, None).</p>"},{"location":"nodes/utils/#inputs_1","title":"Inputs","text":"Group Name Type Default Extras required string <code>STRING</code> Source code in utils.py <pre><code>class String2Any:\n    \"\"\"Safely converts a string representation to its Python object.\n\n    Uses Python's ast.literal_eval for secure string evaluation, which only allows\n    literal expressions (strings, numbers, tuples, lists, dicts, booleans, None).\n\n    Args:\n        string (str): String representation of a Python literal.\n\n    Returns:\n        tuple[Any]: A single-element tuple containing the evaluated Python object.\n\n    Notes:\n        - Only evaluates literal expressions, preventing code execution\n        - Supports: strings, numbers, tuples, lists, dicts, booleans, None\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"string\": (\"STRING\",),\n            }\n        }\n\n    RETURN_TYPES = (any_type,)\n    RETURN_NAMES = (\"value\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n\n    def execute(self, string):\n        try:\n            return (ast.literal_eval(string),)\n        except (ValueError, SyntaxError) as e:\n            raise ValueError(f\"Invalid literal expression: {str(e)}\")\n</code></pre>"},{"location":"nodes/utils/#any2int","title":"Any2Int","text":"<p>Converts any input value to its int representation.</p> <p>This utility node provides a simple way to convert any input value into a int format using Python's built-in int() function. Useful for debugging, logging, or text-based operations.</p>"},{"location":"nodes/utils/#inputs_2","title":"Inputs","text":"Group Name Type Default Extras required value <code>&lt;ast.Name object at 0x7f1c090b1db0&gt;</code>"},{"location":"nodes/utils/#returns_1","title":"Returns","text":"Name Type int <code>INT</code> Source code in utils.py <pre><code>class Any2Int:\n    \"\"\"Converts any input value to its int representation.\n\n    This utility node provides a simple way to convert any input value into a int format using\n    Python's built-in int() function. Useful for debugging, logging, or text-based operations.\n\n    Args:\n        value (Any): The input value to be converted to a int.\n\n    Returns:\n        tuple[int]: A single-element tuple containing the int representation of the input value.\n\n    Notes:\n        - The conversion is done using Python's native int() function\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (any_type,),\n            }\n        }\n\n    RETURN_TYPES = (\"INT\",)\n    RETURN_NAMES = (\"int\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n\n    def execute(self, value):\n        return (int(value),)\n</code></pre>"},{"location":"nodes/utils/#any2float","title":"Any2Float","text":"<p>Converts any input value to its float representation.</p> <p>This utility node provides a simple way to convert any input value into a float format using Python's built-in float() function. Useful for debugging, logging, or text-based operations.</p>"},{"location":"nodes/utils/#inputs_3","title":"Inputs","text":"Group Name Type Default Extras required value <code>&lt;ast.Name object at 0x7f1c090b1630&gt;</code>"},{"location":"nodes/utils/#returns_2","title":"Returns","text":"Name Type float <code>FLOAT</code> Source code in utils.py <pre><code>class Any2Float:\n    \"\"\"Converts any input value to its float representation.\n\n    This utility node provides a simple way to convert any input value into a float format using\n    Python's built-in float() function. Useful for debugging, logging, or text-based operations.\n\n    Args:\n        value (Any): The input value to be converted to a float.\n\n    Returns:\n        tuple[float]: A single-element tuple containing the float representation of the input value.\n\n    Notes:\n        - The conversion is done using Python's native float() function\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (any_type,),\n            }\n        }\n\n    RETURN_TYPES = (\"FLOAT\",)\n    RETURN_NAMES = (\"float\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n\n    def execute(self, value):\n        return (float(value),)\n</code></pre>"},{"location":"nodes/utils/#any2image","title":"Any2Image","text":"<p>Converts any inputs value to image format.</p> <p>A utility node that handles conversion of tensor inputs to a compatible image format for use in image processing workflows.</p>"},{"location":"nodes/utils/#inputs_4","title":"Inputs","text":"Group Name Type Default Extras required value <code>&lt;ast.Name object at 0x7f1c090b0eb0&gt;</code>"},{"location":"nodes/utils/#returns_3","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in utils.py <pre><code>class Any2Image:\n    \"\"\"Converts any inputs value to image format.\n\n    A utility node that handles conversion of tensor inputs to a compatible image format for use in\n    image processing workflows.\n\n    Args:\n        value (Any): The input value to be converted to image format.\n\n    Returns:\n        tuple[torch.Tensor]: A single-element tuple containing the image tensor.\n\n    Raises:\n        ValueError: If the input value is not a torch.Tensor or cannot be converted to image format.\n\n    Notes:\n        - Currently only supports torch.Tensor inputs\n        - Input tensors should be in a format compatible with image processing (BWHC format)\n        - Future versions may support additional input types and automatic conversion\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (any_type,),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    RETURN_NAMES = (\"image\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    CLASS_ID = \"any_image\"\n\n    def execute(self, value):\n        if isinstance(value, torch.Tensor):\n            return (value,)\n        raise ValueError(f\"Unsupported type: {type(value)}\")\n</code></pre>"},{"location":"nodes/utils/#any2any","title":"Any2Any","text":"<p>Passes through any input value unchanged.</p> <p>A utility node that acts as a pass-through or identity function, returning the input value without any modifications. Useful for workflow organization or debugging.</p>"},{"location":"nodes/utils/#inputs_5","title":"Inputs","text":"Group Name Type Default Extras required value <code>&lt;ast.Name object at 0x7f1c090b0400&gt;</code> Source code in utils.py <pre><code>class Any2Any:\n    \"\"\"Passes through any input value unchanged.\n\n    A utility node that acts as a pass-through or identity function, returning the input value\n    without any modifications. Useful for workflow organization or debugging.\n\n    Args:\n        value (Any): Any input value to be passed through.\n\n    Returns:\n        tuple[Any]: A single-element tuple containing the unchanged input value.\n\n    Notes:\n        - No validation or transformation is performed on the input\n        - Useful as a placeholder or for debugging workflow connections\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (any_type,),\n            }\n        }\n\n    RETURN_TYPES = (any_type,)\n    RETURN_NAMES = (\"value\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    CLASS_ID = \"any2any\"\n\n    def execute(self, value):\n        return (value,)\n</code></pre>"},{"location":"nodes/utils/#rgb2hsv","title":"RGB2HSV","text":"<p>Converts RGB images to HSV color space.</p> <p>Transforms images from RGB (Red, Green, Blue) color space to HSV (Hue, Saturation, Value) color space while preserving the image structure and dimensions.</p>"},{"location":"nodes/utils/#inputs_6","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/utils/#returns_4","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in utils.py <pre><code>class RGB2HSV:\n    \"\"\"Converts RGB images to HSV color space.\n\n    Transforms images from RGB (Red, Green, Blue) color space to HSV (Hue, Saturation, Value)\n    color space while preserving the image structure and dimensions.\n\n    Args:\n        image (torch.Tensor): Input RGB image tensor in BWHC format.\n\n    Returns:\n        tuple[torch.Tensor]: A single-element tuple containing the HSV image tensor in BWHC format.\n\n    Notes:\n        - Input must be in BWHC (Batch, Width, Height, Channels) format\n        - RGB values should be normalized to [0, 1] range\n        - Output HSV values are in ranges: H[0,360], S[0,1], V[0,1]\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    CLASS_ID = \"rgb_hsv\"\n\n    def execute(self, image: torch.Tensor):\n        image_tensor = TensorImage.from_BWHC(image)\n        output = rgb_to_hsv(image_tensor).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/utils/#rgb2hls","title":"RGB2HLS","text":"<p>Converts RGB images to HLS color space.</p> <p>Transforms images from RGB (Red, Green, Blue) color space to HLS (Hue, Lightness, Saturation) color space while preserving the image structure and dimensions.</p>"},{"location":"nodes/utils/#inputs_7","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/utils/#returns_5","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in utils.py <pre><code>class RGB2HLS:\n    \"\"\"Converts RGB images to HLS color space.\n\n    Transforms images from RGB (Red, Green, Blue) color space to HLS (Hue, Lightness, Saturation)\n    color space while preserving the image structure and dimensions.\n\n    Args:\n        image (torch.Tensor): Input RGB image tensor in BWHC format.\n\n    Returns:\n        tuple[torch.Tensor]: A single-element tuple containing the HLS image tensor in BWHC format.\n\n    Notes:\n        - Input must be in BWHC (Batch, Width, Height, Channels) format\n        - RGB values should be normalized to [0, 1] range\n        - Output HLS values are in ranges: H[0,360], L[0,1], S[0,1]\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    CLASS_ID = \"rgb_hls\"\n\n    def execute(self, image: torch.Tensor):\n        image_tensor = TensorImage.from_BWHC(image)\n        output = rgb_to_hls(image_tensor).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/utils/#rgba2rgb","title":"RGBA2RGB","text":"<p>Converts RGBA images to RGB format.</p> <p>Transforms images from RGBA (Red, Green, Blue, Alpha) format to RGB format by removing the alpha channel. Passes through RGB images unchanged.</p>"},{"location":"nodes/utils/#inputs_8","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/utils/#returns_6","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in utils.py <pre><code>class RGBA2RGB:\n    \"\"\"Converts RGBA images to RGB format.\n\n    Transforms images from RGBA (Red, Green, Blue, Alpha) format to RGB format by removing the\n    alpha channel. Passes through RGB images unchanged.\n\n    Args:\n        image (torch.Tensor): Input image tensor in BWHC format (either RGBA or RGB).\n\n    Returns:\n        tuple[torch.Tensor]: A single-element tuple containing the RGB image tensor in BWHC format.\n\n    Notes:\n        - Input must be in BWHC (Batch, Width, Height, Channels) format\n        - Handles both 3-channel (RGB) and 4-channel (RGBA) inputs\n        - RGB images are passed through unchanged\n        - Alpha channel is removed from RGBA images using rgba_to_rgb conversion\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    CLASS_ID = \"rgba2rgb\"\n\n    def execute(self, image: torch.Tensor):\n        image_tensor = TensorImage.from_BWHC(image)\n        if image_tensor.shape[1] == 4:\n            image_tensor = rgba_to_rgb(image_tensor)\n        output = image_tensor.get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/utils/#rgb2gray","title":"RGB2GRAY","text":"<p>Converts RGB images to grayscale format.</p> <p>This node transforms RGB color images to single-channel grayscale images using standard luminance conversion factors.</p>"},{"location":"nodes/utils/#inputs_9","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/utils/#returns_7","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in utils.py <pre><code>class RGB2GRAY:\n    \"\"\"Converts RGB images to grayscale format.\n\n    This node transforms RGB color images to single-channel grayscale images using\n    standard luminance conversion factors.\n\n    Args:\n        image (torch.Tensor): Input RGB image in BWHC format\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing grayscale image in BWHC format\n\n    Notes:\n        - Uses standard RGB to grayscale conversion weights\n        - Output is single-channel\n        - Preserves image dimensions\n        - Values remain in [0,1] range\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n\n    def execute(self, image: torch.Tensor):\n        image_tensor = TensorImage.from_BWHC(image)\n        output = rgb_to_grayscale(image_tensor).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/utils/#gray2rgb","title":"GRAY2RGB","text":"<p>Converts grayscale images to RGB format.</p> <p>This node transforms single-channel grayscale images to three-channel RGB images by replicating the grayscale values across channels.</p>"},{"location":"nodes/utils/#inputs_10","title":"Inputs","text":"Group Name Type Default Extras required image <code>IMAGE</code>"},{"location":"nodes/utils/#returns_8","title":"Returns","text":"Name Type image <code>IMAGE</code> Source code in utils.py <pre><code>class GRAY2RGB:\n    \"\"\"Converts grayscale images to RGB format.\n\n    This node transforms single-channel grayscale images to three-channel RGB images\n    by replicating the grayscale values across channels.\n\n    Args:\n        image (torch.Tensor): Input grayscale image in BWHC format\n\n    Returns:\n        tuple[torch.Tensor]: Single-element tuple containing RGB image in BWHC format\n\n    Notes:\n        - Replicates grayscale values to all RGB channels\n        - Output has three identical channels\n        - Preserves image dimensions\n        - Values remain in [0,1] range\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n\n    def execute(self, image: torch.Tensor):\n        image_tensor = TensorImage.from_BWHC(image)\n        output = grayscale_to_rgb(image_tensor).get_BWHC()\n        return (output,)\n</code></pre>"},{"location":"nodes/utils/#purgevram","title":"PurgeVRAM","text":"<p>Cleans up VRAM by forcing memory deallocation and cache clearing.</p> <p>A utility node that performs comprehensive VRAM cleanup by collecting garbage, emptying CUDA cache, and unloading models. Useful for managing memory usage in complex workflows.</p>"},{"location":"nodes/utils/#inputs_11","title":"Inputs","text":"Group Name Type Default Extras required anything <code>&lt;ast.Name object at 0x7f1c090bf040&gt;</code> Source code in utils.py <pre><code>class PurgeVRAM:\n    \"\"\"Cleans up VRAM by forcing memory deallocation and cache clearing.\n\n    A utility node that performs comprehensive VRAM cleanup by collecting garbage, emptying CUDA cache,\n    and unloading models. Useful for managing memory usage in complex workflows.\n\n    Args:\n        anything (Any): Any input value that will be passed through unchanged.\n\n    Returns:\n        tuple[Any]: A single-element tuple containing the unchanged input value.\n\n    Notes:\n        - Calls Python's garbage collector\n        - Clears CUDA cache if available\n        - Unloads and cleans up ComfyUI models\n        - Performs soft cache emptying\n        - Input value is passed through unchanged\n        - Useful for preventing out-of-memory errors\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"anything\": (any_type, {}),\n            },\n            \"optional\": {},\n        }\n\n    RETURN_TYPES = (any_type,)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    OUTPUT_NODE = True\n    # DEPRECATED = True\n    CLASS_ID = \"purge_vram\"\n\n    def execute(self, anything):\n        clean_memory()\n        return (anything,)\n</code></pre>"},{"location":"nodes/utils/#waitseconds","title":"WaitSeconds","text":"<p>Pauses execution for a specified number of seconds.</p> <p>A utility node that introduces a delay in the workflow by sleeping for a given duration. This can be useful for timing control, pacing operations, or waiting for external processes to complete.</p>"},{"location":"nodes/utils/#inputs_12","title":"Inputs","text":"Group Name Type Default Extras required value <code>&lt;ast.Name object at 0x7f1c090bc190&gt;</code> required seconds <code>FLOAT</code> 1.0 Source code in utils.py <pre><code>class WaitSeconds:\n    \"\"\"Pauses execution for a specified number of seconds.\n\n    A utility node that introduces a delay in the workflow by sleeping for a given duration. This can\n    be useful for timing control, pacing operations, or waiting for external processes to complete.\n\n    Args:\n        value (Any): Any input value to be returned after the wait period.\n        seconds (float): The duration to wait in seconds. Defaults to 1.0 seconds.\n\n    Returns:\n        tuple[Any]: A single-element tuple containing the unchanged input value after the wait.\n\n    Notes:\n        - The wait time can be adjusted by changing the `seconds` argument.\n        - The function uses Python's time.sleep() to implement the delay.\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        return {\n            \"required\": {\n                \"value\": (any_type,),\n                \"seconds\": (\n                    \"FLOAT\",\n                    {\n                        \"default\": 1.0,\n                    },\n                ),\n            }\n        }\n\n    RETURN_TYPES = (any_type,)\n    RETURN_NAMES = (\"value\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n\n    def execute(self, **kwargs):\n        value = kwargs.get(\"value\")\n        seconds = kwargs.get(\"seconds\") or 1.0\n        time.sleep(seconds)\n        return (value,)\n</code></pre>"},{"location":"nodes/utils/#listbuilder","title":"ListBuilder","text":"<p>Builds a list from input elements.</p> <p>A node that constructs a list from provided input elements. Used in node-based workflows to combine multiple elements into a single list output.</p> Source code in utils.py <pre><code>class ListBuilder:\n    \"\"\"Builds a list from input elements.\n\n    A node that constructs a list from provided input elements. Used in node-based\n    workflows to combine multiple elements into a single list output.\n\n    Args:\n        elements (Any): Input elements to combine into a list. The specific types\n            accepted are defined in INPUT_TYPES.\n\n    Returns:\n        tuple: A tuple containing:\n            - list: The constructed list containing all input elements\n\n    Notes:\n        - The actual input types and number of elements that can be added to the list\n          are defined in the INPUT_TYPES class method\n        - This node is typically used in node graph systems to aggregate multiple\n          inputs into a single list output\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n\n        inputs = {\n            \"required\": {\n                \"num_slots\": ([str(i) for i in range(1, 11)], {\"default\": \"1\"}),\n            },\n            \"optional\": {},\n        }\n\n        for i in range(1, 11):\n            inputs[\"optional\"].update(\n                {\n                    f\"value_{i}\": (any_type, {\"forceInput\": True}),\n                }\n            )\n        return inputs\n\n    RETURN_TYPES = (\n        any_type,\n        \"LIST\",\n    )\n    RETURN_NAMES = (\n        \"ANY\",\n        \"LIST\",\n    )\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    CLASS_ID = \"list_builder\"\n    OUTPUT_IS_LIST = (\n        True,\n        False,\n    )\n\n    def execute(self, **kwargs):\n        num_slots = int(kwargs.get(\"num_slots\", 1))\n        list_stack = []\n        for i in range(1, num_slots + 1):\n            list_value = kwargs.get(f\"value_{i}\")\n            if list_value is not None:\n                list_stack.append(list_value)\n        return (\n            list_stack,\n            list_stack,\n        )\n</code></pre>"},{"location":"nodes/utils/#latent2dict","title":"Latent2Dict","text":"<p>Converts a latent tensor representation to a dictionary format.</p> <p>Transforms a LATENT input (containing tensor data) into a structured dictionary that includes type information, shape, and tensor values.</p>"},{"location":"nodes/utils/#inputs_13","title":"Inputs","text":"Group Name Type Default Extras required latent <code>LATENT</code>"},{"location":"nodes/utils/#returns_9","title":"Returns","text":"Name Type dict <code>DICT</code> Source code in utils.py <pre><code>class Latent2Dict:\n    \"\"\"Converts a latent tensor representation to a dictionary format.\n\n    Transforms a LATENT input (containing tensor data) into a structured dictionary\n    that includes type information, shape, and tensor values.\n\n    Args:\n        latent (LATENT): A latent tensor input.\n\n    Returns:\n        tuple[dict]: A single-element tuple containing a dictionary with the structure:\n            {\n                \"type\": \"LATENT\",\n                \"data\": {\n                    \"samples\": {\n                        \"type\": str,  # Tensor type name\n                        \"shape\": tuple,  # Tensor dimensions\n                        \"values\": list  # Tensor data as nested lists\n                    }\n                }\n            }\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"latent\": (\"LATENT\",),\n            }\n        }\n\n    RETURN_TYPES = (\"DICT\",)\n    RETURN_NAMES = (\"dict\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    OUTPUT_NODE = True\n\n    def execute(self, **kwargs):\n        latent = kwargs.get(\"latent\") or {}\n\n        latent_dict = {\n            \"type\": \"LATENT\",\n            \"data\": {\n                \"samples\": {\n                    \"type\": str(type(latent[\"samples\"]).__name__),\n                    \"shape\": latent[\"samples\"].shape,\n                    \"values\": latent[\"samples\"].tolist(),\n                }\n            },\n        }\n\n        return (latent_dict,)\n</code></pre>"},{"location":"nodes/utils/#dict2latent","title":"Dict2Latent","text":"<p>Converts a dictionary representation back to a latent tensor format.</p> <p>Transforms a structured dictionary containing tensor data back into the LATENT format used by the system.</p>"},{"location":"nodes/utils/#inputs_14","title":"Inputs","text":"Group Name Type Default Extras required dict <code>DICT</code>"},{"location":"nodes/utils/#returns_10","title":"Returns","text":"Name Type latent <code>LATENT</code> Source code in utils.py <pre><code>class Dict2Latent:\n    \"\"\"Converts a dictionary representation back to a latent tensor format.\n\n    Transforms a structured dictionary containing tensor data back into the LATENT\n    format used by the system.\n\n    Args:\n        dict (DICT): A dictionary containing tensor data in the format:\n            {\n                \"type\": \"LATENT\",\n                \"data\": {\n                    \"samples\": {\n                        \"type\": str,  # Tensor type name\n                        \"shape\": tuple,  # Tensor dimensions\n                        \"values\": list  # Tensor data as nested lists\n                    }\n                }\n            }\n\n    Returns:\n        tuple[LATENT]: A single-element tuple containing the reconstructed latent\n            tensor in the format: {\"samples\": tensor}\n\n    Raises:\n        ValueError: If the input dictionary is not of type \"LATENT\" or contains an\n            unsupported tensor type.\n    \"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"dict\": (\"DICT\",),\n            }\n        }\n\n    RETURN_TYPES = (\"LATENT\",)\n    RETURN_NAMES = (\"latent\",)\n    FUNCTION = \"execute\"\n    CATEGORY = UTILS_CAT\n    OUTPUT_NODE = True\n\n    def execute(self, **kwargs):\n        input_dict = kwargs.get(\"dict\") or {}\n        if input_dict.get(\"type\") != \"LATENT\":\n            raise ValueError(\"Input dictionary is not a LATENT type\")\n\n        samples_data = input_dict[\"data\"][\"samples\"]\n        tensor_type = samples_data[\"type\"]\n        if \"Tensor\" in tensor_type or \"GGMLTensor\" in tensor_type or \"TensorImage\" in tensor_type:\n            tensor_data = torch.tensor(samples_data[\"values\"])\n            tensor_data = tensor_data.reshape(samples_data[\"shape\"])\n        else:\n            raise ValueError(f\"Unsupported tensor type: {tensor_type}\")\n\n        latent = {\"samples\": tensor_data}\n\n        return (latent,)\n</code></pre>"},{"location":"nodes/wrapper/","title":"Wrapper Nodes","text":""},{"location":"nodes/wrapper/#wrapper","title":"Wrapper","text":"<p>A wrapper class for handling workflow execution and communication with a remote server.</p> <p>This class provides functionality to execute workflows, process inputs/outputs, and handle communication with a remote server. It supports uploading files, running workflow jobs, and processing various types of data including images, masks, and primitive types.</p> Source code in wrapper.py <pre><code>class Wrapper:\n    \"\"\"A wrapper class for handling workflow execution and communication with a remote server.\n\n    This class provides functionality to execute workflows, process inputs/outputs, and handle\n    communication with a remote server. It supports uploading files, running workflow jobs, and\n    processing various types of data including images, masks, and primitive types.\n\n    Args:\n        data (str, optional): JSON string containing workflow configuration and execution parameters.\n            Default is an empty string.\n\n    Returns:\n        tuple: A tuple of length 20 containing processed outputs from the workflow execution.\n            Each element can be of any type (images, numbers, strings, etc.) or None.\n\n    Raises:\n        Exception:\n            - If communication with the server fails after multiple retries\n            - If the workflow execution encounters an error\n            - If required parameters (base_url, workflow_api, token) are missing or invalid\n\n    Notes:\n        The class provides several key features:\n        - Uses a placeholder server for local execution\n        - Supports various input types including IMAGE, MASK, INT, FLOAT, BOOLEAN, and STRING\n        - Handles tensor image conversions and S3 uploads\n        - Manages memory by cleaning up models and cache after execution\n        - Uses progress bars to track workflow execution\n        - Implements retry logic for handling communication issues\n    \"\"\"\n\n    def __init__(self):\n        self.total_steps = 0\n        self.remaining_ids = []\n        self.server = None\n        self.executor = None\n\n    def get_workflow(self, base_url: str, workflow_id: str, token: str) -&gt; dict:\n        url = f\"{base_url}/workflows/{workflow_id}\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Authorization\": \"Bearer \" + token,\n        }\n        output = {}\n        with httpx.Client() as client:\n            try:\n                response = client.get(url, headers=headers, timeout=3)\n                if response.status_code == 200:\n                    buffer = response.content\n                    output = json.loads(buffer)\n            except Exception as e:\n                console.log(e)\n        return output\n\n    def process_outputs(self, job_outputs, node_outputs):\n\n        def process_data(node_output: dict, job_output: dict):\n\n            node_type = node_output.get(\"type\")\n            value = job_output.get(\"value\")\n            if value is None or not isinstance(node_type, str):\n                return []\n            if node_type in (\"IMAGE\", \"MASK\"):\n                if not isinstance(value, str):\n                    return None\n                image_path = os.path.join(BASE_COMFY_DIR, \"output\", value)\n                output_image = TensorImage.from_local(image_path)\n                return output_image.get_BWHC()\n            if node_type == \"INT\":\n                return int(value)\n            if node_type == \"FLOAT\":\n                return float(value)\n            if node_type == \"BOOLEAN\":\n                return bool(value)\n            return str(value)\n\n        outputs = []\n        for node_output in node_outputs:\n            for job_output in job_outputs:\n                if not isinstance(job_output, dict) or not isinstance(node_output, dict):\n                    continue\n                node_name = node_output.get(\"title\") or []\n                job_name = job_output.get(\"title\") or []\n                if isinstance(node_name, str):\n                    node_name = [node_name]\n                if isinstance(job_name, str):\n                    job_name = [job_name]\n                # console.log(f\"Node name: {node_name}, Job name: {job_name}\")\n                for node_name_part in node_name:\n                    for job_name_part in job_name:\n                        if node_name_part != job_name_part:\n                            continue\n                        data = process_data(node_output, job_output)\n                        if data is None:\n                            continue\n                        outputs.append(data)\n                        break\n                # console.log(f\"Added {node_name} {node_type}\")\n        # console.log(f\"=====================&gt;&gt;&gt; Node outputs: {len(outputs)}\")\n        return tuple(outputs)\n\n    @classmethod\n    def INPUT_TYPES(cls):  # type: ignore\n        inputs = {\n            \"required\": {\n                \"data\": (\"STRING\", {\"default\": \"\"}),\n            },\n            \"optional\": {},\n        }\n\n        return inputs\n\n    RETURN_TYPES = (any_type,) * 20\n    FUNCTION = \"execute\"\n    CATEGORY = LABS_CAT\n\n    def execute(self, **kwargs):\n\n        data = kwargs.get(\"data\")\n        # console.log(f\"kwargs: {kwargs}\")\n\n        fallback = (None,) * 20\n        if data is None:\n            return fallback\n        json_data = json.loads(data)\n        if not isinstance(json_data, dict):\n            return fallback\n        base_url = json_data.get(\"origin\") or None\n        workflow_api = json_data.get(\"workflow_api\") or None\n        token = json_data.get(\"token\") or None\n        inference_host = json_data.get(\"inference_host\") or None\n        widget_inputs = json_data.get(\"widget_inputs\") or []\n        # console.log(f\"Widget inputs: {widget_inputs}\")\n\n        if inference_host is None or inference_host == \"\":\n            inference_host = base_url\n        # console.log(f\"Origin: {base_url}, Inference host: {inference_host}\")\n        if not isinstance(base_url, str):\n            return fallback\n        if not isinstance(workflow_api, dict):\n            return fallback\n        if not isinstance(token, str):\n            return fallback\n\n        workflow = Workflow(workflow_api)\n        node_inputs = workflow.get_inputs()\n        # console.log(f\"Node inputs: {node_inputs}\")\n        workflow_outputs = workflow.get_outputs()\n        output_ids = workflow_outputs.keys()\n        node_outputs = workflow_outputs.values()\n        # console.log(f\"Node outputs: {node_outputs}\")\n\n        for key, value in node_inputs.items():\n            if not isinstance(value, dict):\n                continue\n            node_title = value.get(\"title\")\n            node_type = value.get(\"type\")\n            if not isinstance(node_type, str) or not isinstance(node_title, str):\n                continue\n            comfy_value = kwargs.get(node_title)\n            if comfy_value is None:\n                for widget_input in widget_inputs:\n                    if widget_input.get(\"title\") == node_title:\n                        widget_value = widget_input.get(\"value\")\n                        if widget_value is None:\n                            continue\n                        comfy_value = widget_input.get(\"value\")\n                        break\n            if comfy_value is None:\n                continue\n            if node_type in (\"IMAGE\", \"MASK\"):\n                if isinstance(comfy_value, torch.Tensor):\n                    tensor_image = TensorImage.from_BWHC(comfy_value).get_base64()\n                    value.update({\"value\": tensor_image})\n                    node_inputs[key] = value\n            else:\n                value.update({\"value\": comfy_value})\n                node_inputs[key] = value\n\n        workflow.set_inputs(node_inputs)\n        workflow_api = workflow.data\n\n        if not isinstance(workflow_api, dict):\n            return fallback\n\n        total_nodes = list(workflow_api.keys())\n        self.total_steps = len(total_nodes)\n        self.remaining_ids = total_nodes\n        pbar = ProgressBar(self.total_steps)  # type: ignore\n\n        def report_handler(event, data, _):\n            if event == \"execution_start\":\n                prompt_id = data.get(\"prompt_id\")\n                console.log(f\"Wrapper Execution started, prompt {prompt_id}\")\n            elif event == \"execution_cached\":\n                cached_nodes_ids = data.get(\"nodes\", []) or []\n                self.remaining_ids = list(set(self.remaining_ids) - set(cached_nodes_ids))\n            elif event == \"executing\":\n                node_id = data.get(\"node\")\n                self.remaining_ids = list(set(self.remaining_ids) - {node_id})\n            elif event == \"execution_error\":\n                console.log(f\"Execution error: {data}\")\n                raise Exception(data.get(\"error\"))\n            elif event == \"execution_interrupted\":\n                raise Exception(\"Execution was interrupted\")\n            elif event == \"executed\":\n                prompt_id = data.get(\"prompt_id\")\n                self.remaining_ids = []\n                console.log(f\"Wrapper Execution finished, prompt {prompt_id}\")\n            pbar.update_absolute(self.total_steps - len(self.remaining_ids), self.total_steps)\n            percentage = 100 * round((self.total_steps - len(self.remaining_ids)) / self.total_steps, 2)\n            console.log(f\"Wrapper Execution: {percentage}%\")\n\n        self.server = PlaceholderServer(report_handler)\n        self.executor = execution.PromptExecutor(self.server)  # type: ignore\n        self.executor.execute(workflow_api, uuid.uuid4(), {\"client_id\": self.server.client_id}, output_ids)\n        self.executor.reset()\n        gc.collect()\n        comfy.model_management.unload_all_models()\n        comfy.model_management.cleanup_models()\n        comfy.model_management.soft_empty_cache()\n\n        if self.executor.success:\n            console.log(\"Success wrapper inference\")\n        else:\n            console.log(\"Failed wrapper inference\")\n            final_status = self.executor.status_messages[-1]\n            console.log(f\"Final status: {final_status}\")\n            if isinstance(final_status, dict):\n                final_error = final_status.get(\"execution_error\") or None\n                if final_error is not None:\n                    raise Exception(final_error)\n        outputs = self.executor.history_result[\"outputs\"].values()\n        job_outputs = []\n        for job_output in outputs:\n            for key, value in job_output.items():\n                if key == \"signature_output\":\n                    job_outputs.extend(value)\n\n        return self.process_outputs(job_outputs, node_outputs)\n</code></pre>"}]}